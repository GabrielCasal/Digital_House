{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celdas generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "% matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_right</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>price</th>\n",
       "      <th>price_aprox_local_currency</th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>...</th>\n",
       "      <th>laundry</th>\n",
       "      <th>lavadero</th>\n",
       "      <th>balcon</th>\n",
       "      <th>terraza</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>parrilla</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3.734000e+03</td>\n",
       "      <td>3.734000e+03</td>\n",
       "      <td>3.734000e+03</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "      <td>3734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18425.850295</td>\n",
       "      <td>55623.979111</td>\n",
       "      <td>55623.979111</td>\n",
       "      <td>-34.579204</td>\n",
       "      <td>-58.424537</td>\n",
       "      <td>3.638428e+05</td>\n",
       "      <td>5.911092e+06</td>\n",
       "      <td>3.350105e+05</td>\n",
       "      <td>110.372523</td>\n",
       "      <td>97.555704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115158</td>\n",
       "      <td>0.367702</td>\n",
       "      <td>0.544724</td>\n",
       "      <td>0.243974</td>\n",
       "      <td>0.140332</td>\n",
       "      <td>0.108463</td>\n",
       "      <td>0.186931</td>\n",
       "      <td>0.096144</td>\n",
       "      <td>0.177825</td>\n",
       "      <td>0.403321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11724.056931</td>\n",
       "      <td>33102.289060</td>\n",
       "      <td>33102.289060</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>4.593530e+05</td>\n",
       "      <td>5.494591e+06</td>\n",
       "      <td>3.114053e+05</td>\n",
       "      <td>96.395894</td>\n",
       "      <td>84.401262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319255</td>\n",
       "      <td>0.482244</td>\n",
       "      <td>0.498062</td>\n",
       "      <td>0.429535</td>\n",
       "      <td>0.347378</td>\n",
       "      <td>0.311006</td>\n",
       "      <td>0.389908</td>\n",
       "      <td>0.294827</td>\n",
       "      <td>0.382417</td>\n",
       "      <td>0.490630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>-58.472364</td>\n",
       "      <td>4.900000e+04</td>\n",
       "      <td>5.898837e+05</td>\n",
       "      <td>3.343159e+04</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8637.250000</td>\n",
       "      <td>28827.250000</td>\n",
       "      <td>28827.250000</td>\n",
       "      <td>-34.589971</td>\n",
       "      <td>-58.440293</td>\n",
       "      <td>1.490000e+05</td>\n",
       "      <td>2.558452e+06</td>\n",
       "      <td>1.450000e+05</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16845.500000</td>\n",
       "      <td>52038.500000</td>\n",
       "      <td>52038.500000</td>\n",
       "      <td>-34.581968</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>2.464000e+05</td>\n",
       "      <td>4.234680e+06</td>\n",
       "      <td>2.400000e+05</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26667.250000</td>\n",
       "      <td>77586.250000</td>\n",
       "      <td>77586.250000</td>\n",
       "      <td>-34.567127</td>\n",
       "      <td>-58.404554</td>\n",
       "      <td>4.150000e+05</td>\n",
       "      <td>7.046772e+06</td>\n",
       "      <td>3.993750e+05</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40670.000000</td>\n",
       "      <td>121158.000000</td>\n",
       "      <td>121158.000000</td>\n",
       "      <td>-34.546880</td>\n",
       "      <td>-58.384171</td>\n",
       "      <td>9.435376e+06</td>\n",
       "      <td>5.646240e+07</td>\n",
       "      <td>3.200000e+06</td>\n",
       "      <td>967.000000</td>\n",
       "      <td>967.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index_right     Unnamed: 0             ID      latitud     longitud  \\\n",
       "count   3734.000000    3734.000000    3734.000000  3734.000000  3734.000000   \n",
       "mean   18425.850295   55623.979111   55623.979111   -34.579204   -58.424537   \n",
       "std    11724.056931   33102.289060   33102.289060     0.013009     0.022621   \n",
       "min        4.000000       7.000000       7.000000   -34.599730   -58.472364   \n",
       "25%     8637.250000   28827.250000   28827.250000   -34.589971   -58.440293   \n",
       "50%    16845.500000   52038.500000   52038.500000   -34.581968   -58.423297   \n",
       "75%    26667.250000   77586.250000   77586.250000   -34.567127   -58.404554   \n",
       "max    40670.000000  121158.000000  121158.000000   -34.546880   -58.384171   \n",
       "\n",
       "              price  price_aprox_local_currency  price_aprox_usd  \\\n",
       "count  3.734000e+03                3.734000e+03     3.734000e+03   \n",
       "mean   3.638428e+05                5.911092e+06     3.350105e+05   \n",
       "std    4.593530e+05                5.494591e+06     3.114053e+05   \n",
       "min    4.900000e+04                5.898837e+05     3.343159e+04   \n",
       "25%    1.490000e+05                2.558452e+06     1.450000e+05   \n",
       "50%    2.464000e+05                4.234680e+06     2.400000e+05   \n",
       "75%    4.150000e+05                7.046772e+06     3.993750e+05   \n",
       "max    9.435376e+06                5.646240e+07     3.200000e+06   \n",
       "\n",
       "       surface_total_in_m2  surface_covered_in_m2     ...           laundry  \\\n",
       "count          3734.000000            3734.000000     ...       3734.000000   \n",
       "mean            110.372523              97.555704     ...          0.115158   \n",
       "std              96.395894              84.401262     ...          0.319255   \n",
       "min              21.000000               4.000000     ...          0.000000   \n",
       "25%              48.000000              42.000000     ...          0.000000   \n",
       "50%              80.000000              71.000000     ...          0.000000   \n",
       "75%             137.000000             122.000000     ...          0.000000   \n",
       "max             967.000000             967.000000     ...          1.000000   \n",
       "\n",
       "          lavadero       balcon      terraza          sum     solarium  \\\n",
       "count  3734.000000  3734.000000  3734.000000  3734.000000  3734.000000   \n",
       "mean      0.367702     0.544724     0.243974     0.140332     0.108463   \n",
       "std       0.482244     0.498062     0.429535     0.347378     0.311006   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          parrilla   a estrenar        subte      cochera  \n",
       "count  3734.000000  3734.000000  3734.000000  3734.000000  \n",
       "mean      0.186931     0.096144     0.177825     0.403321  \n",
       "std       0.389908     0.294827     0.382417     0.490630  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./DATA/pal-bel-rec.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_right</th>\n",
       "      <th>BARRIO</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>TIPO_PROPIEDAD</th>\n",
       "      <th>lat-lon</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>...</th>\n",
       "      <th>terraza</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>parrilla</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "      <th>geometry</th>\n",
       "      <th>BARRIO_PALERMO</th>\n",
       "      <th>BARRIO_RECOLETA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1915</td>\n",
       "      <td>PALERMO</td>\n",
       "      <td>8196</td>\n",
       "      <td>8196</td>\n",
       "      <td>apartment</td>\n",
       "      <td>-34.5699834561,-58.4346691662</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>790000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-58.4346691662 -34.5699834561)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17594</td>\n",
       "      <td>PALERMO</td>\n",
       "      <td>54303</td>\n",
       "      <td>54303</td>\n",
       "      <td>apartment</td>\n",
       "      <td>-34.5711496,-58.4232966</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-58.4232966 -34.57114960000001)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16545</td>\n",
       "      <td>PALERMO</td>\n",
       "      <td>51178</td>\n",
       "      <td>51178</td>\n",
       "      <td>apartment</td>\n",
       "      <td>-34.5693554857,-58.4333625453</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>245000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-58.4333625453 -34.5693554857)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16566</td>\n",
       "      <td>PALERMO</td>\n",
       "      <td>51215</td>\n",
       "      <td>51215</td>\n",
       "      <td>apartment</td>\n",
       "      <td>-34.580572,-58.4400316</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>330000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-58.4400316 -34.580572)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16586</td>\n",
       "      <td>PALERMO</td>\n",
       "      <td>51315</td>\n",
       "      <td>51315</td>\n",
       "      <td>apartment</td>\n",
       "      <td>-34.5809781,-58.4289623</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-58.4289623 -34.5809781)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_right   BARRIO  Unnamed: 0     ID TIPO_PROPIEDAD  \\\n",
       "0         1915  PALERMO        8196   8196      apartment   \n",
       "1        17594  PALERMO       54303  54303      apartment   \n",
       "2        16545  PALERMO       51178  51178      apartment   \n",
       "3        16566  PALERMO       51215  51215      apartment   \n",
       "4        16586  PALERMO       51315  51315      apartment   \n",
       "\n",
       "                         lat-lon    latitud   longitud     price currency  \\\n",
       "0  -34.5699834561,-58.4346691662 -34.569983 -58.434669  790000.0      USD   \n",
       "1        -34.5711496,-58.4232966 -34.571150 -58.423297  780000.0      USD   \n",
       "2  -34.5693554857,-58.4333625453 -34.569355 -58.433363  245000.0      USD   \n",
       "3         -34.580572,-58.4400316 -34.580572 -58.440032  330000.0      USD   \n",
       "4        -34.5809781,-58.4289623 -34.580978 -58.428962  125000.0      USD   \n",
       "\n",
       "        ...        terraza  sum  solarium  parrilla  a estrenar  subte  \\\n",
       "0       ...              1    1         1         1           0      0   \n",
       "1       ...              0    0         0         0           0      0   \n",
       "2       ...              1    0         0         1           1      0   \n",
       "3       ...              0    1         1         1           0      0   \n",
       "4       ...              0    0         0         0           0      1   \n",
       "\n",
       "   cochera                                geometry  BARRIO_PALERMO  \\\n",
       "0        1   POINT (-58.4346691662 -34.5699834561)               1   \n",
       "1        0  POINT (-58.4232966 -34.57114960000001)               1   \n",
       "2        0   POINT (-58.4333625453 -34.5693554857)               1   \n",
       "3        1          POINT (-58.4400316 -34.580572)               1   \n",
       "4        0         POINT (-58.4289623 -34.5809781)               1   \n",
       "\n",
       "  BARRIO_RECOLETA  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummies con los 3 barrios\n",
    "series = data['BARRIO']\n",
    "dummies = pd.get_dummies(series, prefix='BARRIO',drop_first=True)\n",
    "data = pd.concat([data, dummies], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_right</th>\n",
       "      <th>BARRIO</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>TIPO_PROPIEDAD</th>\n",
       "      <th>lat-lon</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>...</th>\n",
       "      <th>terraza</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>parrilla</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "      <th>geometry</th>\n",
       "      <th>BARRIO_PALERMO</th>\n",
       "      <th>BARRIO_RECOLETA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBBARRIO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abasto</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Almagro</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balvanera</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barrio Norte</th>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>...</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgrano</th>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Centro / Microcentro</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chacarita</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coghlan</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colegiales</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congreso</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Las CaÃƒÂ±itas</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuÃƒÂ±ez</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Once</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palermo</th>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>...</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palermo Chico</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palermo Hollywood</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palermo Soho</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palermo Viejo</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paternal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recoleta</th>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>...</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retiro</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIN DATO</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Telmo</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tribunales</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Villa Crespo</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Villa Ortuzar</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Villa Urquiza</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index_right  BARRIO  Unnamed: 0    ID  TIPO_PROPIEDAD  \\\n",
       "SUBBARRIO                                                                     \n",
       "Abasto                          1       1           1     1               1   \n",
       "Almagro                         8       8           8     8               8   \n",
       "Balvanera                       1       1           1     1               1   \n",
       "Barrio Norte                  498     498         498   498             498   \n",
       "Belgrano                      953     953         953   953             953   \n",
       "Centro / Microcentro            1       1           1     1               1   \n",
       "Chacarita                       2       2           2     2               2   \n",
       "Coghlan                        30      30          30    30              30   \n",
       "Colegiales                     17      17          17    17              17   \n",
       "Congreso                        1       1           1     1               1   \n",
       "Las CaÃƒÂ±itas                   98      98          98    98              98   \n",
       "NuÃƒÂ±ez                         26      26          26    26              26   \n",
       "Once                            1       1           1     1               1   \n",
       "Palermo                      1063    1063        1063  1063            1063   \n",
       "Palermo Chico                 108     108         108   108             108   \n",
       "Palermo Hollywood             144     144         144   144             144   \n",
       "Palermo Soho                   82      82          82    82              82   \n",
       "Palermo Viejo                   8       8           8     8               8   \n",
       "Paternal                        1       1           1     1               1   \n",
       "Recoleta                      645     645         645   645             645   \n",
       "Retiro                          3       3           3     3               3   \n",
       "SIN DATO                       12      12          12    12              12   \n",
       "San Telmo                       4       4           4     4               4   \n",
       "Tribunales                      2       2           2     2               2   \n",
       "Villa Crespo                   18      18          18    18              18   \n",
       "Villa Ortuzar                   4       4           4     4               4   \n",
       "Villa Urquiza                   3       3           3     3               3   \n",
       "\n",
       "                      lat-lon  latitud  longitud  price  currency  \\\n",
       "SUBBARRIO                                                           \n",
       "Abasto                      1        1         1      1         1   \n",
       "Almagro                     8        8         8      8         8   \n",
       "Balvanera                   1        1         1      1         1   \n",
       "Barrio Norte              498      498       498    498       498   \n",
       "Belgrano                  953      953       953    953       953   \n",
       "Centro / Microcentro        1        1         1      1         1   \n",
       "Chacarita                   2        2         2      2         2   \n",
       "Coghlan                    30       30        30     30        30   \n",
       "Colegiales                 17       17        17     17        17   \n",
       "Congreso                    1        1         1      1         1   \n",
       "Las CaÃƒÂ±itas               98       98        98     98        98   \n",
       "NuÃƒÂ±ez                     26       26        26     26        26   \n",
       "Once                        1        1         1      1         1   \n",
       "Palermo                  1063     1063      1063   1063      1063   \n",
       "Palermo Chico             108      108       108    108       108   \n",
       "Palermo Hollywood         144      144       144    144       144   \n",
       "Palermo Soho               82       82        82     82        82   \n",
       "Palermo Viejo               8        8         8      8         8   \n",
       "Paternal                    1        1         1      1         1   \n",
       "Recoleta                  645      645       645    645       645   \n",
       "Retiro                      3        3         3      3         3   \n",
       "SIN DATO                   12       12        12     12        12   \n",
       "San Telmo                   4        4         4      4         4   \n",
       "Tribunales                  2        2         2      2         2   \n",
       "Villa Crespo               18       18        18     18        18   \n",
       "Villa Ortuzar               4        4         4      4         4   \n",
       "Villa Urquiza               3        3         3      3         3   \n",
       "\n",
       "                           ...         terraza   sum  solarium  parrilla  \\\n",
       "SUBBARRIO                  ...                                             \n",
       "Abasto                     ...               1     1         1         1   \n",
       "Almagro                    ...               8     8         8         8   \n",
       "Balvanera                  ...               1     1         1         1   \n",
       "Barrio Norte               ...             498   498       498       498   \n",
       "Belgrano                   ...             953   953       953       953   \n",
       "Centro / Microcentro       ...               1     1         1         1   \n",
       "Chacarita                  ...               2     2         2         2   \n",
       "Coghlan                    ...              30    30        30        30   \n",
       "Colegiales                 ...              17    17        17        17   \n",
       "Congreso                   ...               1     1         1         1   \n",
       "Las CaÃƒÂ±itas               ...              98    98        98        98   \n",
       "NuÃƒÂ±ez                     ...              26    26        26        26   \n",
       "Once                       ...               1     1         1         1   \n",
       "Palermo                    ...            1063  1063      1063      1063   \n",
       "Palermo Chico              ...             108   108       108       108   \n",
       "Palermo Hollywood          ...             144   144       144       144   \n",
       "Palermo Soho               ...              82    82        82        82   \n",
       "Palermo Viejo              ...               8     8         8         8   \n",
       "Paternal                   ...               1     1         1         1   \n",
       "Recoleta                   ...             645   645       645       645   \n",
       "Retiro                     ...               3     3         3         3   \n",
       "SIN DATO                   ...              12    12        12        12   \n",
       "San Telmo                  ...               4     4         4         4   \n",
       "Tribunales                 ...               2     2         2         2   \n",
       "Villa Crespo               ...              18    18        18        18   \n",
       "Villa Ortuzar              ...               4     4         4         4   \n",
       "Villa Urquiza              ...               3     3         3         3   \n",
       "\n",
       "                      a estrenar  subte  cochera  geometry  BARRIO_PALERMO  \\\n",
       "SUBBARRIO                                                                    \n",
       "Abasto                         1      1        1         1               1   \n",
       "Almagro                        8      8        8         8               8   \n",
       "Balvanera                      1      1        1         1               1   \n",
       "Barrio Norte                 498    498      498       498             498   \n",
       "Belgrano                     953    953      953       953             953   \n",
       "Centro / Microcentro           1      1        1         1               1   \n",
       "Chacarita                      2      2        2         2               2   \n",
       "Coghlan                       30     30       30        30              30   \n",
       "Colegiales                    17     17       17        17              17   \n",
       "Congreso                       1      1        1         1               1   \n",
       "Las CaÃƒÂ±itas                  98     98       98        98              98   \n",
       "NuÃƒÂ±ez                        26     26       26        26              26   \n",
       "Once                           1      1        1         1               1   \n",
       "Palermo                     1063   1063     1063      1063            1063   \n",
       "Palermo Chico                108    108      108       108             108   \n",
       "Palermo Hollywood            144    144      144       144             144   \n",
       "Palermo Soho                  82     82       82        82              82   \n",
       "Palermo Viejo                  8      8        8         8               8   \n",
       "Paternal                       1      1        1         1               1   \n",
       "Recoleta                     645    645      645       645             645   \n",
       "Retiro                         3      3        3         3               3   \n",
       "SIN DATO                      12     12       12        12              12   \n",
       "San Telmo                      4      4        4         4               4   \n",
       "Tribunales                     2      2        2         2               2   \n",
       "Villa Crespo                  18     18       18        18              18   \n",
       "Villa Ortuzar                  4      4        4         4               4   \n",
       "Villa Urquiza                  3      3        3         3               3   \n",
       "\n",
       "                      BARRIO_RECOLETA  \n",
       "SUBBARRIO                              \n",
       "Abasto                              1  \n",
       "Almagro                             8  \n",
       "Balvanera                           1  \n",
       "Barrio Norte                      498  \n",
       "Belgrano                          953  \n",
       "Centro / Microcentro                1  \n",
       "Chacarita                           2  \n",
       "Coghlan                            30  \n",
       "Colegiales                         17  \n",
       "Congreso                            1  \n",
       "Las CaÃƒÂ±itas                       98  \n",
       "NuÃƒÂ±ez                             26  \n",
       "Once                                1  \n",
       "Palermo                          1063  \n",
       "Palermo Chico                     108  \n",
       "Palermo Hollywood                 144  \n",
       "Palermo Soho                       82  \n",
       "Palermo Viejo                       8  \n",
       "Paternal                            1  \n",
       "Recoleta                          645  \n",
       "Retiro                              3  \n",
       "SIN DATO                           12  \n",
       "San Telmo                           4  \n",
       "Tribunales                          2  \n",
       "Villa Crespo                       18  \n",
       "Villa Ortuzar                       4  \n",
       "Villa Urquiza                       3  \n",
       "\n",
       "[27 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by = 'SUBBARRIO').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index_right', 'BARRIO', 'Unnamed: 0', 'ID', 'TIPO_PROPIEDAD',\n",
       "       'lat-lon', 'latitud', 'longitud', 'price', 'currency',\n",
       "       'price_aprox_local_currency', 'price_aprox_usd', 'surface_total_in_m2',\n",
       "       'surface_covered_in_m2', 'price_usd_per_m2', 'price_per_m2', 'floor',\n",
       "       'rooms', 'expenses', 'properati_url', 'description', 'title',\n",
       "       'image_thumbnail', 'PAIS', 'PROVINCIA', 'CIUDAD-PARTIDO', 'SUBBARRIO',\n",
       "       'Ambientes', 'pileta', 'amenities', 'gimnasio', 'laundry', 'lavadero',\n",
       "       'balcon', 'terraza', 'sum', 'solarium', 'parrilla', 'a estrenar',\n",
       "       'subte', 'cochera', 'geometry', 'BARRIO_PALERMO', 'BARRIO_RECOLETA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['TIPO_PROPIEDAD'] == 'apartment')]\n",
    "if data.surface_covered_in_m2.isnull:\n",
    "    data.surface_covered_in_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_right</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>price</th>\n",
       "      <th>price_aprox_local_currency</th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <th>price_per_m2</th>\n",
       "      <th>floor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>expenses</th>\n",
       "      <th>Ambientes</th>\n",
       "      <th>pileta</th>\n",
       "      <th>amenities</th>\n",
       "      <th>gimnasio</th>\n",
       "      <th>laundry</th>\n",
       "      <th>lavadero</th>\n",
       "      <th>balcon</th>\n",
       "      <th>terraza</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>parrilla</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "      <th>BARRIO_PALERMO</th>\n",
       "      <th>BARRIO_RECOLETA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3.428000e+03</td>\n",
       "      <td>3.428000e+03</td>\n",
       "      <td>3.428000e+03</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>2175.000000</td>\n",
       "      <td>1142.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18483.925613</td>\n",
       "      <td>55786.995041</td>\n",
       "      <td>55786.995041</td>\n",
       "      <td>-34.579079</td>\n",
       "      <td>-58.424132</td>\n",
       "      <td>3.509480e+05</td>\n",
       "      <td>5.670030e+06</td>\n",
       "      <td>3.213483e+05</td>\n",
       "      <td>102.427655</td>\n",
       "      <td>91.193407</td>\n",
       "      <td>3121.637500</td>\n",
       "      <td>4202.365700</td>\n",
       "      <td>4.563559</td>\n",
       "      <td>3.105747</td>\n",
       "      <td>5077.954466</td>\n",
       "      <td>3.023337</td>\n",
       "      <td>0.219953</td>\n",
       "      <td>0.144107</td>\n",
       "      <td>0.127480</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>0.372229</td>\n",
       "      <td>0.574679</td>\n",
       "      <td>0.235414</td>\n",
       "      <td>0.149942</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>0.180572</td>\n",
       "      <td>0.101225</td>\n",
       "      <td>0.183781</td>\n",
       "      <td>0.417736</td>\n",
       "      <td>0.455659</td>\n",
       "      <td>0.321470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11750.319731</td>\n",
       "      <td>33171.549589</td>\n",
       "      <td>33171.549589</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>4.438573e+05</td>\n",
       "      <td>5.091397e+06</td>\n",
       "      <td>2.885544e+05</td>\n",
       "      <td>80.521537</td>\n",
       "      <td>71.742497</td>\n",
       "      <td>783.182386</td>\n",
       "      <td>6326.541385</td>\n",
       "      <td>3.928102</td>\n",
       "      <td>1.553356</td>\n",
       "      <td>4759.016145</td>\n",
       "      <td>1.493116</td>\n",
       "      <td>0.414275</td>\n",
       "      <td>0.351250</td>\n",
       "      <td>0.333558</td>\n",
       "      <td>0.329938</td>\n",
       "      <td>0.483469</td>\n",
       "      <td>0.494464</td>\n",
       "      <td>0.424319</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.320045</td>\n",
       "      <td>0.384719</td>\n",
       "      <td>0.301671</td>\n",
       "      <td>0.387362</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>0.498103</td>\n",
       "      <td>0.467109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>-58.472364</td>\n",
       "      <td>5.800000e+04</td>\n",
       "      <td>5.898837e+05</td>\n",
       "      <td>3.343159e+04</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1078.438387</td>\n",
       "      <td>1196.319018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8620.750000</td>\n",
       "      <td>28809.750000</td>\n",
       "      <td>28809.750000</td>\n",
       "      <td>-34.589880</td>\n",
       "      <td>-58.440371</td>\n",
       "      <td>1.450000e+05</td>\n",
       "      <td>2.523164e+06</td>\n",
       "      <td>1.430000e+05</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2590.503247</td>\n",
       "      <td>2857.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17028.500000</td>\n",
       "      <td>52790.000000</td>\n",
       "      <td>52790.000000</td>\n",
       "      <td>-34.581819</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>2.400000e+05</td>\n",
       "      <td>4.181746e+06</td>\n",
       "      <td>2.370000e+05</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3333.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26713.750000</td>\n",
       "      <td>77747.500000</td>\n",
       "      <td>77747.500000</td>\n",
       "      <td>-34.566966</td>\n",
       "      <td>-58.404062</td>\n",
       "      <td>3.990000e+05</td>\n",
       "      <td>6.881355e+06</td>\n",
       "      <td>3.900000e+05</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>3533.521341</td>\n",
       "      <td>4048.397234</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40670.000000</td>\n",
       "      <td>121158.000000</td>\n",
       "      <td>121158.000000</td>\n",
       "      <td>-34.549922</td>\n",
       "      <td>-58.384171</td>\n",
       "      <td>9.435376e+06</td>\n",
       "      <td>5.646240e+07</td>\n",
       "      <td>3.200000e+06</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>5487.804878</td>\n",
       "      <td>101851.557143</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>54240.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index_right     Unnamed: 0             ID      latitud     longitud  \\\n",
       "count   3428.000000    3428.000000    3428.000000  3428.000000  3428.000000   \n",
       "mean   18483.925613   55786.995041   55786.995041   -34.579079   -58.424132   \n",
       "std    11750.319731   33171.549589   33171.549589     0.012970     0.022738   \n",
       "min        4.000000       7.000000       7.000000   -34.599730   -58.472364   \n",
       "25%     8620.750000   28809.750000   28809.750000   -34.589880   -58.440371   \n",
       "50%    17028.500000   52790.000000   52790.000000   -34.581819   -58.423297   \n",
       "75%    26713.750000   77747.500000   77747.500000   -34.566966   -58.404062   \n",
       "max    40670.000000  121158.000000  121158.000000   -34.549922   -58.384171   \n",
       "\n",
       "              price  price_aprox_local_currency  price_aprox_usd  \\\n",
       "count  3.428000e+03                3.428000e+03     3.428000e+03   \n",
       "mean   3.509480e+05                5.670030e+06     3.213483e+05   \n",
       "std    4.438573e+05                5.091397e+06     2.885544e+05   \n",
       "min    5.800000e+04                5.898837e+05     3.343159e+04   \n",
       "25%    1.450000e+05                2.523164e+06     1.430000e+05   \n",
       "50%    2.400000e+05                4.181746e+06     2.370000e+05   \n",
       "75%    3.990000e+05                6.881355e+06     3.900000e+05   \n",
       "max    9.435376e+06                5.646240e+07     3.200000e+06   \n",
       "\n",
       "       surface_total_in_m2  surface_covered_in_m2  price_usd_per_m2  \\\n",
       "count          3428.000000            3428.000000       3428.000000   \n",
       "mean            102.427655              91.193407       3121.637500   \n",
       "std              80.521537              71.742497        783.182386   \n",
       "min              21.000000               4.000000       1078.438387   \n",
       "25%              46.000000              41.000000       2590.503247   \n",
       "50%              78.000000              69.000000       3000.000000   \n",
       "75%             130.000000             117.000000       3533.521341   \n",
       "max             789.000000             690.000000       5487.804878   \n",
       "\n",
       "        price_per_m2       floor        rooms      expenses    Ambientes  \\\n",
       "count    3428.000000  236.000000  2175.000000   1142.000000  3428.000000   \n",
       "mean     4202.365700    4.563559     3.105747   5077.954466     3.023337   \n",
       "std      6326.541385    3.928102     1.553356   4759.016145     1.493116   \n",
       "min      1196.319018    1.000000     1.000000      1.000000     1.000000   \n",
       "25%      2857.142857    2.000000     2.000000   2000.000000     2.000000   \n",
       "50%      3333.333333    4.000000     3.000000   3500.000000     3.000000   \n",
       "75%      4048.397234    6.000000     4.000000   6500.000000     4.000000   \n",
       "max    101851.557143   22.000000    15.000000  54240.000000     8.000000   \n",
       "\n",
       "            pileta    amenities     gimnasio      laundry     lavadero  \\\n",
       "count  3428.000000  3428.000000  3428.000000  3428.000000  3428.000000   \n",
       "mean      0.219953     0.144107     0.127480     0.124271     0.372229   \n",
       "std       0.414275     0.351250     0.333558     0.329938     0.483469   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            balcon      terraza          sum     solarium     parrilla  \\\n",
       "count  3428.000000  3428.000000  3428.000000  3428.000000  3428.000000   \n",
       "mean      0.574679     0.235414     0.149942     0.115811     0.180572   \n",
       "std       0.494464     0.424319     0.357066     0.320045     0.384719   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        a estrenar        subte      cochera  BARRIO_PALERMO  BARRIO_RECOLETA  \n",
       "count  3428.000000  3428.000000  3428.000000     3428.000000      3428.000000  \n",
       "mean      0.101225     0.183781     0.417736        0.455659         0.321470  \n",
       "std       0.301671     0.387362     0.493258        0.498103         0.467109  \n",
       "min       0.000000     0.000000     0.000000        0.000000         0.000000  \n",
       "25%       0.000000     0.000000     0.000000        0.000000         0.000000  \n",
       "50%       0.000000     0.000000     0.000000        0.000000         0.000000  \n",
       "75%       0.000000     0.000000     1.000000        1.000000         1.000000  \n",
       "max       1.000000     1.000000     1.000000        1.000000         1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Primer modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. PreparaciÃ³n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux = data[[ 'surface_total_in_m2', 'surface_covered_in_m2' ,'Ambientes', 'pileta', 'amenities',\n",
    "       'gimnasio', 'laundry', 'sum', 'solarium', 'parrilla', 'a estrenar',\n",
    "       'subte', 'cochera', 'latitud', 'longitud', 'BARRIO_PALERMO', 'BARRIO_RECOLETA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(data_aux.corr(),\n",
    "            xticklabels=data_aux.columns.values,\n",
    "            yticklabels=data_aux.columns.values, cmap=sns.diverging_palette(220, 10, as_cmap=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399, 17) (2399,)\n",
      "(1029, 17) (1029,)\n"
     ]
    }
   ],
   "source": [
    "#Split train y test \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_aux, data.price_usd_per_m2, test_size=0.3, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NormalizaciÃ³n (para Ridge y Lasso)\n",
    "se = StandardScaler()\n",
    "X_train_s = se.fit_transform(X_train)\n",
    "X_test_s = se.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1. RegresiÃ³n lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n MÃ­nimos Cuadrados Ordinarios\n",
      "Coeficientes: [-8.52272497e+00  8.49473940e+00  8.02429602e+00  3.72771525e+02\n",
      "  1.04794720e+02  4.59431041e+02  2.14957876e+02 -6.41119638e+01\n",
      "  2.48419816e+00 -4.07662319e+01  2.35257060e+02 -1.04952323e+02\n",
      "  3.03576801e+02  2.60320066e+04  2.07775126e+04  1.35559312e+02\n",
      " -1.42317223e+02]\n",
      "Residual sum of squares: 376435.69\n",
      "Varianza explicada: 0.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print ('RegresiÃ³n MÃ­nimos Cuadrados Ordinarios')\n",
    "#Coeficiente\n",
    "print('Coeficientes:',regr.coef_)\n",
    "# MSE \n",
    "print(\"Residual sum of squares: %.2f\"\n",
    " % np.mean((regr.predict(X_train) - y_train) ** 2))\n",
    "# Varianza explicada\n",
    "print('Varianza explicada: %.2f\\n' % regr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37885315 0.43133843 0.31893708 0.40931892 0.33661576]\n",
      "0.3750126674943426\n",
      "0.042386446941523256\n"
     ]
    }
   ],
   "source": [
    "# Un cross validation\n",
    "results = cross_val_score(regr,X_train,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr.predict(X_test)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2. RegresiÃ³n Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Lasso\n",
      "alpha: 0.72\n",
      "\n",
      "Coeficientes: [-6.77068782e+02  5.96542546e+02  8.54477439e+00  1.54106562e+02\n",
      "  3.63743506e+01  1.56305364e+02  7.21715767e+01 -2.17217500e+01\n",
      "  5.14720897e-01 -1.61038162e+01  7.05521619e+01 -4.11034148e+01\n",
      "  1.49183417e+02  3.34146864e+02  4.66339666e+02  6.95819404e+01\n",
      " -6.09509953e+01]\n",
      "\n",
      "Residual sum of squares: 376481.61\n",
      "\n",
      "Varianza explicada: 0.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr2=linear_model.LassoCV(cv=10).fit(X_train_s, y_train)\n",
    "\n",
    "print ('RegresiÃ³n Lasso' )\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr2.alpha_)\n",
    "# Coeficiente\n",
    "print ('Coeficientes:', regr2.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr2.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr2.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37895229 0.43039617 0.32013407 0.40866614 0.33907226]\n",
      "0.3754441851574894\n",
      "0.04127432852183314\n"
     ]
    }
   ],
   "source": [
    "# Un cross validation\n",
    "results = cross_val_score(regr2,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr2.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3. RegresiÃ³n Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Ridge\n",
      "alpha: 1.60\n",
      "\n",
      "Coeficientes: [-686.14359612  602.76911951   11.54549311  155.066795     37.11877215\n",
      "  156.46685338   72.98232203  -23.16524266    0.96827447  -16.7478364\n",
      "   71.68672847  -41.49327191  149.36496496  335.88425684  471.35586738\n",
      "   67.8286249   -65.47635107]\n",
      "\n",
      "Residual sum of squares: 376447.63\n",
      "\n",
      "Varianza explicada: 0.39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr3=linear_model.RidgeCV(alphas=[0.1,0.2,0.5,0.7,1.38,1.39,1.5,1.6,3.0,5.0,7.0,10.0])\n",
    "regr3.fit(X_train_s,y_train)\n",
    "\n",
    "print ('RegresiÃ³n Ridge')\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr3.alpha_)\n",
    "# Coeficientes\n",
    "print('Coeficientes:', regr3.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr3.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr3.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37860941 0.43036106 0.31964939 0.40767346 0.33776823]\n",
      "0.37481231106865687\n",
      "0.04146118307397456\n"
     ]
    }
   ],
   "source": [
    "# Un cross validation\n",
    "results = cross_val_score(regr3,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr3.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las 3 dieron lo mismo. Lasso no nos sacÃ³ features, podemos probar chequear la significatividad de las mismas y sacar quizÃ¡s alguna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Eliminar features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a ver quÃ© features tienen poca significatividad y correr el modelo sin ellas a ver quÃ© pasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMC: 376435.69180278224\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       price_usd_per_m2   R-squared:                       0.390\n",
      "Model:                            OLS   Adj. R-squared:                  0.386\n",
      "Method:                 Least Squares   F-statistic:                     89.52\n",
      "Date:                Sun, 30 Sep 2018   Prob (F-statistic):          2.28e-240\n",
      "Time:                        11:15:21   Log-Likelihood:                -18804.\n",
      "No. Observations:                2399   AIC:                         3.764e+04\n",
      "Df Residuals:                    2381   BIC:                         3.775e+04\n",
      "Df Model:                          17                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                  2.117e+06   1.32e+05     16.022      0.000    1.86e+06    2.38e+06\n",
      "surface_total_in_m2      -8.5227      0.617    -13.806      0.000      -9.733      -7.312\n",
      "surface_covered_in_m2     8.4947      0.690     12.307      0.000       7.141       9.848\n",
      "Ambientes                 8.0243     16.606      0.483      0.629     -24.538      40.587\n",
      "pileta                  372.7715     47.086      7.917      0.000     280.437     465.106\n",
      "amenities               104.7947     43.730      2.396      0.017      19.042     190.548\n",
      "gimnasio                459.4310     49.605      9.262      0.000     362.158     556.704\n",
      "laundry                 214.9579     46.842      4.589      0.000     123.102     306.813\n",
      "sum                     -64.1120     44.712     -1.434      0.152    -151.791      23.567\n",
      "solarium                  2.4842     47.437      0.052      0.958     -90.539      95.507\n",
      "parrilla                -40.7662     39.759     -1.025      0.305    -118.731      37.199\n",
      "a estrenar              235.2571     43.588      5.397      0.000     149.783     320.731\n",
      "subte                  -104.9523     32.887     -3.191      0.001    -169.442     -40.463\n",
      "cochera                 303.5768     29.200     10.397      0.000     246.317     360.836\n",
      "latitud                2.603e+04   2109.532     12.340      0.000    2.19e+04    3.02e+04\n",
      "longitud               2.078e+04   1537.964     13.510      0.000    1.78e+04    2.38e+04\n",
      "BARRIO_PALERMO          135.5593     60.234      2.251      0.025      17.443     253.676\n",
      "BARRIO_RECOLETA        -142.3172     97.441     -1.461      0.144    -333.395      48.761\n",
      "==============================================================================\n",
      "Omnibus:                      185.837   Durbin-Watson:                   2.074\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              282.393\n",
      "Skew:                           0.606   Prob(JB):                     4.78e-62\n",
      "Kurtosis:                       4.164   Cond. No.                     1.92e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.92e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Agregar constante\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.plot(y_train,y_train, '-.', c='grey')\n",
    "plt.scatter(predictions, y_train, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos el MSE y un resumen del modelo\n",
    "print (\"EMC:\", mean_squared_error(y_train, predictions))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'parrilla' y 'BARRIO_RECOLETA' parecen ser las menos significativas. Nueva prueba sacÃ¡ndolas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux2 = data[[ 'surface_total_in_m2', 'surface_covered_in_m2' ,'Ambientes', 'pileta',\n",
    "       'gimnasio', 'laundry', 'sum', 'solarium', 'a estrenar',\n",
    "       'subte', 'cochera', 'latitud', 'longitud', 'BARRIO_PALERMO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399, 14) (2399,)\n",
      "(1029, 14) (1029,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_aux2, data.price_usd_per_m2, test_size=0.3, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMC: 377807.0720594601\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       price_usd_per_m2   R-squared:                       0.388\n",
      "Model:                            OLS   Adj. R-squared:                  0.384\n",
      "Method:                 Least Squares   F-statistic:                     107.8\n",
      "Date:                Sun, 30 Sep 2018   Prob (F-statistic):          1.55e-241\n",
      "Time:                        11:15:29   Log-Likelihood:                -18808.\n",
      "No. Observations:                2399   AIC:                         3.765e+04\n",
      "Df Residuals:                    2384   BIC:                         3.773e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                  2.093e+06   1.28e+05     16.381      0.000    1.84e+06    2.34e+06\n",
      "surface_total_in_m2      -8.6448      0.603    -14.334      0.000      -9.827      -7.462\n",
      "surface_covered_in_m2     8.6467      0.681     12.697      0.000       7.311       9.982\n",
      "Ambientes                 5.9175     16.521      0.358      0.720     -26.479      38.314\n",
      "pileta                  386.4655     46.227      8.360      0.000     295.817     477.114\n",
      "gimnasio                476.5775     48.958      9.734      0.000     380.573     572.582\n",
      "laundry                 213.5747     45.773      4.666      0.000     123.816     303.334\n",
      "sum                     -59.7417     44.027     -1.357      0.175    -146.076      26.593\n",
      "solarium                 12.1292     46.379      0.262      0.794     -78.818     103.077\n",
      "a estrenar              231.9580     43.561      5.325      0.000     146.537     317.379\n",
      "subte                  -106.1593     32.902     -3.227      0.001    -170.679     -41.640\n",
      "cochera                 303.1341     29.178     10.389      0.000     245.916     360.352\n",
      "latitud                2.755e+04   1927.100     14.297      0.000    2.38e+04    3.13e+04\n",
      "longitud               1.946e+04   1129.367     17.232      0.000    1.72e+04    2.17e+04\n",
      "BARRIO_PALERMO          212.6946     25.724      8.268      0.000     162.252     263.137\n",
      "==============================================================================\n",
      "Omnibus:                      189.828   Durbin-Watson:                   2.076\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              284.572\n",
      "Skew:                           0.622   Prob(JB):                     1.61e-62\n",
      "Kurtosis:                       4.141   Cond. No.                     1.86e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.86e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Agregar constante\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.plot(y_train,y_train, '-.', c='grey')\n",
    "plt.scatter(predictions, y_train, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos el MSE y un resumen del modelo\n",
    "print (\"EMC:\", mean_squared_error(y_train, predictions))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El R2 y el R2 ajustado empeoran ligeramente, probando en el test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No cambia... 'carajo, mierda!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. AnÃ¡lisis de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>Ambientes</th>\n",
       "      <th>pileta</th>\n",
       "      <th>gimnasio</th>\n",
       "      <th>laundry</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>BARRIO_PALERMO</th>\n",
       "      <th>error</th>\n",
       "      <th>error_abs</th>\n",
       "      <th>precioxm2</th>\n",
       "      <th>pred</th>\n",
       "      <th>error_prop</th>\n",
       "      <th>error_prop_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588889</td>\n",
       "      <td>-58.430556</td>\n",
       "      <td>1</td>\n",
       "      <td>-1759.340494</td>\n",
       "      <td>1759.340494</td>\n",
       "      <td>1115.873226</td>\n",
       "      <td>2875.213720</td>\n",
       "      <td>-1.576649</td>\n",
       "      <td>1.576649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588889</td>\n",
       "      <td>-58.430556</td>\n",
       "      <td>1</td>\n",
       "      <td>-1738.234521</td>\n",
       "      <td>1738.234521</td>\n",
       "      <td>1128.345789</td>\n",
       "      <td>2866.580311</td>\n",
       "      <td>-1.540516</td>\n",
       "      <td>1.540516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588889</td>\n",
       "      <td>-58.430556</td>\n",
       "      <td>1</td>\n",
       "      <td>-1690.143689</td>\n",
       "      <td>1690.143689</td>\n",
       "      <td>1202.374865</td>\n",
       "      <td>2892.518554</td>\n",
       "      <td>-1.405671</td>\n",
       "      <td>1.405671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588889</td>\n",
       "      <td>-58.430556</td>\n",
       "      <td>1</td>\n",
       "      <td>-1661.403015</td>\n",
       "      <td>1661.403015</td>\n",
       "      <td>1222.457419</td>\n",
       "      <td>2883.860435</td>\n",
       "      <td>-1.359068</td>\n",
       "      <td>1.359068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.561882</td>\n",
       "      <td>-58.454043</td>\n",
       "      <td>0</td>\n",
       "      <td>-1540.736718</td>\n",
       "      <td>1540.736718</td>\n",
       "      <td>1196.319018</td>\n",
       "      <td>2737.055736</td>\n",
       "      <td>-1.287898</td>\n",
       "      <td>1.287898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588889</td>\n",
       "      <td>-58.430556</td>\n",
       "      <td>1</td>\n",
       "      <td>-1593.100707</td>\n",
       "      <td>1593.100707</td>\n",
       "      <td>1279.387576</td>\n",
       "      <td>2872.488283</td>\n",
       "      <td>-1.245206</td>\n",
       "      <td>1.245206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588889</td>\n",
       "      <td>-58.430556</td>\n",
       "      <td>1</td>\n",
       "      <td>-1578.074324</td>\n",
       "      <td>1578.074324</td>\n",
       "      <td>1268.500426</td>\n",
       "      <td>2846.574750</td>\n",
       "      <td>-1.244047</td>\n",
       "      <td>1.244047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588889</td>\n",
       "      <td>-58.430556</td>\n",
       "      <td>1</td>\n",
       "      <td>-1561.993686</td>\n",
       "      <td>1561.993686</td>\n",
       "      <td>1284.581064</td>\n",
       "      <td>2846.574750</td>\n",
       "      <td>-1.215956</td>\n",
       "      <td>1.215956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.574907</td>\n",
       "      <td>-58.435853</td>\n",
       "      <td>1</td>\n",
       "      <td>-1425.582514</td>\n",
       "      <td>1425.582514</td>\n",
       "      <td>1187.500000</td>\n",
       "      <td>2613.082514</td>\n",
       "      <td>-1.200491</td>\n",
       "      <td>1.200491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>1.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.564858</td>\n",
       "      <td>-58.454128</td>\n",
       "      <td>0</td>\n",
       "      <td>-1479.767446</td>\n",
       "      <td>1479.767446</td>\n",
       "      <td>1470.588235</td>\n",
       "      <td>2950.355681</td>\n",
       "      <td>-1.006242</td>\n",
       "      <td>1.006242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.573035</td>\n",
       "      <td>-58.438826</td>\n",
       "      <td>1</td>\n",
       "      <td>-1182.014237</td>\n",
       "      <td>1182.014237</td>\n",
       "      <td>1210.916625</td>\n",
       "      <td>2392.930862</td>\n",
       "      <td>-0.976132</td>\n",
       "      <td>0.976132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.582416</td>\n",
       "      <td>-58.420049</td>\n",
       "      <td>1</td>\n",
       "      <td>-1550.053331</td>\n",
       "      <td>1550.053331</td>\n",
       "      <td>1645.569620</td>\n",
       "      <td>3195.622952</td>\n",
       "      <td>-0.941955</td>\n",
       "      <td>0.941955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.575756</td>\n",
       "      <td>-58.434491</td>\n",
       "      <td>1</td>\n",
       "      <td>-1384.218375</td>\n",
       "      <td>1384.218375</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2884.218375</td>\n",
       "      <td>-0.922812</td>\n",
       "      <td>0.922812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.563573</td>\n",
       "      <td>-58.436475</td>\n",
       "      <td>1</td>\n",
       "      <td>-1351.741573</td>\n",
       "      <td>1351.741573</td>\n",
       "      <td>1483.333333</td>\n",
       "      <td>2835.074906</td>\n",
       "      <td>-0.911286</td>\n",
       "      <td>0.911286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>1.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.595937</td>\n",
       "      <td>-58.393205</td>\n",
       "      <td>0</td>\n",
       "      <td>-1384.736389</td>\n",
       "      <td>1384.736389</td>\n",
       "      <td>1557.377049</td>\n",
       "      <td>2942.113438</td>\n",
       "      <td>-0.889147</td>\n",
       "      <td>0.889147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.582466</td>\n",
       "      <td>-58.420037</td>\n",
       "      <td>1</td>\n",
       "      <td>-1141.448551</td>\n",
       "      <td>1141.448551</td>\n",
       "      <td>1309.090909</td>\n",
       "      <td>2450.539460</td>\n",
       "      <td>-0.871940</td>\n",
       "      <td>0.871940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1</td>\n",
       "      <td>-1710.933769</td>\n",
       "      <td>1710.933769</td>\n",
       "      <td>2172.727273</td>\n",
       "      <td>3883.661042</td>\n",
       "      <td>-0.787459</td>\n",
       "      <td>0.787459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.564408</td>\n",
       "      <td>-58.437251</td>\n",
       "      <td>1</td>\n",
       "      <td>-1818.912258</td>\n",
       "      <td>1818.912258</td>\n",
       "      <td>2321.428571</td>\n",
       "      <td>4140.340830</td>\n",
       "      <td>-0.783531</td>\n",
       "      <td>0.783531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.562084</td>\n",
       "      <td>-58.456686</td>\n",
       "      <td>0</td>\n",
       "      <td>-959.028303</td>\n",
       "      <td>959.028303</td>\n",
       "      <td>1227.272727</td>\n",
       "      <td>2186.301031</td>\n",
       "      <td>-0.781430</td>\n",
       "      <td>0.781430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.591171</td>\n",
       "      <td>-58.394832</td>\n",
       "      <td>0</td>\n",
       "      <td>-1309.053626</td>\n",
       "      <td>1309.053626</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>3009.053626</td>\n",
       "      <td>-0.770032</td>\n",
       "      <td>0.770032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  surface_total_in_m2  surface_covered_in_m2  Ambientes  pileta  \\\n",
       "1302    1.0                 31.0                   24.0          1       0   \n",
       "1300    1.0                 38.0                   30.0          1       0   \n",
       "1294    1.0                 37.0                   32.0          1       0   \n",
       "1304    1.0                 31.0                   25.0          1       0   \n",
       "2092    1.0                326.0                  326.0          6       0   \n",
       "1305    1.0                 33.0                   25.0          2       0   \n",
       "1299    1.0                 47.0                   36.0          2       0   \n",
       "1297    1.0                 47.0                   36.0          2       0   \n",
       "482     1.0                 80.0                   19.0          1       0   \n",
       "2329    1.0                187.0                  187.0          5       0   \n",
       "534     1.0                 80.0                   19.0          3       0   \n",
       "1683    1.0                237.0                  220.0          5       0   \n",
       "679     1.0                 62.0                   32.0          1       0   \n",
       "124     1.0                120.0                   74.0          4       0   \n",
       "3659    1.0                244.0                  240.0          5       0   \n",
       "982     1.0                165.0                  110.0          4       0   \n",
       "437     1.0                110.0                  100.0          4       1   \n",
       "117     1.0                280.0                  260.0          6       1   \n",
       "2175    1.0                110.0                   55.0          3       0   \n",
       "2996    1.0                 40.0                   35.0          1       0   \n",
       "\n",
       "      gimnasio  laundry  sum  solarium  a estrenar  subte  cochera    latitud  \\\n",
       "1302         0        0    0         0           0      0        1 -34.588889   \n",
       "1300         0        0    0         0           0      0        1 -34.588889   \n",
       "1294         0        0    0         0           0      0        1 -34.588889   \n",
       "1304         0        0    0         0           0      0        1 -34.588889   \n",
       "2092         0        0    0         0           0      0        0 -34.561882   \n",
       "1305         0        0    0         0           0      0        1 -34.588889   \n",
       "1299         0        0    0         0           0      0        1 -34.588889   \n",
       "1297         0        0    0         0           0      0        1 -34.588889   \n",
       "482          0        1    0         1           0      0        0 -34.574907   \n",
       "2329         0        0    0         0           0      0        1 -34.564858   \n",
       "534          0        0    0         0           0      0        0 -34.573035   \n",
       "1683         0        0    0         0           0      0        1 -34.582416   \n",
       "679          0        1    0         1           0      0        0 -34.575756   \n",
       "124          0        0    0         0           0      0        0 -34.563573   \n",
       "3659         0        0    0         0           0      0        0 -34.595937   \n",
       "982          0        0    0         0           0      1        0 -34.582466   \n",
       "437          0        0    0         0           0      0        1 -34.571150   \n",
       "117          1        0    1         0           0      0        1 -34.564408   \n",
       "2175         0        0    0         0           0      0        0 -34.562084   \n",
       "2996         0        0    0         0           0      0        0 -34.591171   \n",
       "\n",
       "       longitud  BARRIO_PALERMO        error    error_abs    precioxm2  \\\n",
       "1302 -58.430556               1 -1759.340494  1759.340494  1115.873226   \n",
       "1300 -58.430556               1 -1738.234521  1738.234521  1128.345789   \n",
       "1294 -58.430556               1 -1690.143689  1690.143689  1202.374865   \n",
       "1304 -58.430556               1 -1661.403015  1661.403015  1222.457419   \n",
       "2092 -58.454043               0 -1540.736718  1540.736718  1196.319018   \n",
       "1305 -58.430556               1 -1593.100707  1593.100707  1279.387576   \n",
       "1299 -58.430556               1 -1578.074324  1578.074324  1268.500426   \n",
       "1297 -58.430556               1 -1561.993686  1561.993686  1284.581064   \n",
       "482  -58.435853               1 -1425.582514  1425.582514  1187.500000   \n",
       "2329 -58.454128               0 -1479.767446  1479.767446  1470.588235   \n",
       "534  -58.438826               1 -1182.014237  1182.014237  1210.916625   \n",
       "1683 -58.420049               1 -1550.053331  1550.053331  1645.569620   \n",
       "679  -58.434491               1 -1384.218375  1384.218375  1500.000000   \n",
       "124  -58.436475               1 -1351.741573  1351.741573  1483.333333   \n",
       "3659 -58.393205               0 -1384.736389  1384.736389  1557.377049   \n",
       "982  -58.420037               1 -1141.448551  1141.448551  1309.090909   \n",
       "437  -58.423297               1 -1710.933769  1710.933769  2172.727273   \n",
       "117  -58.437251               1 -1818.912258  1818.912258  2321.428571   \n",
       "2175 -58.456686               0  -959.028303   959.028303  1227.272727   \n",
       "2996 -58.394832               0 -1309.053626  1309.053626  1700.000000   \n",
       "\n",
       "             pred  error_prop  error_prop_abs  \n",
       "1302  2875.213720   -1.576649        1.576649  \n",
       "1300  2866.580311   -1.540516        1.540516  \n",
       "1294  2892.518554   -1.405671        1.405671  \n",
       "1304  2883.860435   -1.359068        1.359068  \n",
       "2092  2737.055736   -1.287898        1.287898  \n",
       "1305  2872.488283   -1.245206        1.245206  \n",
       "1299  2846.574750   -1.244047        1.244047  \n",
       "1297  2846.574750   -1.215956        1.215956  \n",
       "482   2613.082514   -1.200491        1.200491  \n",
       "2329  2950.355681   -1.006242        1.006242  \n",
       "534   2392.930862   -0.976132        0.976132  \n",
       "1683  3195.622952   -0.941955        0.941955  \n",
       "679   2884.218375   -0.922812        0.922812  \n",
       "124   2835.074906   -0.911286        0.911286  \n",
       "3659  2942.113438   -0.889147        0.889147  \n",
       "982   2450.539460   -0.871940        0.871940  \n",
       "437   3883.661042   -0.787459        0.787459  \n",
       "117   4140.340830   -0.783531        0.783531  \n",
       "2175  2186.301031   -0.781430        0.781430  \n",
       "2996  3009.053626   -0.770032        0.770032  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los mayores errores proporcionalmente se dan al sobrevaluar propiedades baratas\n",
    "\n",
    "data_e = X_train\n",
    "data_e['error'] = y_train - predictions\n",
    "data_e['error_abs'] = np.abs(y_train - predictions)\n",
    "data_e['precioxm2'] = y_train\n",
    "data_e['pred'] = predictions\n",
    "data_e['error_prop'] = data_e['error'] / data_e['precioxm2']\n",
    "data_e['error_prop_abs'] = data_e['error_abs'] / data_e['precioxm2']\n",
    "data_e.sort_values(by='error_prop_abs',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>Ambientes</th>\n",
       "      <th>pileta</th>\n",
       "      <th>gimnasio</th>\n",
       "      <th>laundry</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>BARRIO_PALERMO</th>\n",
       "      <th>error</th>\n",
       "      <th>error_abs</th>\n",
       "      <th>precioxm2</th>\n",
       "      <th>pred</th>\n",
       "      <th>error_prop</th>\n",
       "      <th>error_prop_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.589410</td>\n",
       "      <td>-58.431334</td>\n",
       "      <td>1</td>\n",
       "      <td>2662.765350</td>\n",
       "      <td>2662.765350</td>\n",
       "      <td>5245.901639</td>\n",
       "      <td>2583.136289</td>\n",
       "      <td>0.507590</td>\n",
       "      <td>0.507590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.583042</td>\n",
       "      <td>-58.400016</td>\n",
       "      <td>1</td>\n",
       "      <td>2501.367749</td>\n",
       "      <td>2501.367749</td>\n",
       "      <td>5387.523629</td>\n",
       "      <td>2886.155880</td>\n",
       "      <td>0.464289</td>\n",
       "      <td>0.464289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.577166</td>\n",
       "      <td>-58.425303</td>\n",
       "      <td>1</td>\n",
       "      <td>2408.218221</td>\n",
       "      <td>2408.218221</td>\n",
       "      <td>5434.782609</td>\n",
       "      <td>3026.564388</td>\n",
       "      <td>0.443112</td>\n",
       "      <td>0.443112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.562084</td>\n",
       "      <td>-58.456686</td>\n",
       "      <td>0</td>\n",
       "      <td>2398.725102</td>\n",
       "      <td>2398.725102</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>2601.274898</td>\n",
       "      <td>0.479745</td>\n",
       "      <td>0.479745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.555357</td>\n",
       "      <td>-58.458188</td>\n",
       "      <td>0</td>\n",
       "      <td>2297.759598</td>\n",
       "      <td>2297.759598</td>\n",
       "      <td>5043.859649</td>\n",
       "      <td>2746.100051</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.455556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.577761</td>\n",
       "      <td>-58.424323</td>\n",
       "      <td>1</td>\n",
       "      <td>2244.639951</td>\n",
       "      <td>2244.639951</td>\n",
       "      <td>5267.857143</td>\n",
       "      <td>3023.217192</td>\n",
       "      <td>0.426101</td>\n",
       "      <td>0.426101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.577777</td>\n",
       "      <td>-58.424300</td>\n",
       "      <td>1</td>\n",
       "      <td>2205.953497</td>\n",
       "      <td>2205.953497</td>\n",
       "      <td>5175.438596</td>\n",
       "      <td>2969.485100</td>\n",
       "      <td>0.426235</td>\n",
       "      <td>0.426235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.589546</td>\n",
       "      <td>-58.397364</td>\n",
       "      <td>0</td>\n",
       "      <td>2181.372167</td>\n",
       "      <td>2181.372167</td>\n",
       "      <td>5303.030303</td>\n",
       "      <td>3121.658136</td>\n",
       "      <td>0.411344</td>\n",
       "      <td>0.411344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.588583</td>\n",
       "      <td>-58.387745</td>\n",
       "      <td>0</td>\n",
       "      <td>2170.728806</td>\n",
       "      <td>2170.728806</td>\n",
       "      <td>5363.636364</td>\n",
       "      <td>3192.907557</td>\n",
       "      <td>0.404712</td>\n",
       "      <td>0.404712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.563342</td>\n",
       "      <td>-58.436630</td>\n",
       "      <td>1</td>\n",
       "      <td>2148.403691</td>\n",
       "      <td>2148.403691</td>\n",
       "      <td>5384.615385</td>\n",
       "      <td>3236.211694</td>\n",
       "      <td>0.398989</td>\n",
       "      <td>0.398989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.586732</td>\n",
       "      <td>-58.409907</td>\n",
       "      <td>1</td>\n",
       "      <td>2065.631787</td>\n",
       "      <td>2065.631787</td>\n",
       "      <td>5128.205128</td>\n",
       "      <td>3062.573341</td>\n",
       "      <td>0.402798</td>\n",
       "      <td>0.402798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.590962</td>\n",
       "      <td>-58.406078</td>\n",
       "      <td>0</td>\n",
       "      <td>2064.566536</td>\n",
       "      <td>2064.566536</td>\n",
       "      <td>4883.720930</td>\n",
       "      <td>2819.154395</td>\n",
       "      <td>0.422745</td>\n",
       "      <td>0.422745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.570547</td>\n",
       "      <td>-58.434497</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.929529</td>\n",
       "      <td>1988.929529</td>\n",
       "      <td>5333.333333</td>\n",
       "      <td>3344.403804</td>\n",
       "      <td>0.372924</td>\n",
       "      <td>0.372924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.589652</td>\n",
       "      <td>-58.406289</td>\n",
       "      <td>0</td>\n",
       "      <td>1980.102735</td>\n",
       "      <td>1980.102735</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>3019.897265</td>\n",
       "      <td>0.396021</td>\n",
       "      <td>0.396021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>1.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.589546</td>\n",
       "      <td>-58.397364</td>\n",
       "      <td>0</td>\n",
       "      <td>1976.050767</td>\n",
       "      <td>1976.050767</td>\n",
       "      <td>4970.760234</td>\n",
       "      <td>2994.709467</td>\n",
       "      <td>0.397535</td>\n",
       "      <td>0.397535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.583396</td>\n",
       "      <td>-58.433728</td>\n",
       "      <td>1</td>\n",
       "      <td>1965.832503</td>\n",
       "      <td>1965.832503</td>\n",
       "      <td>4700.000000</td>\n",
       "      <td>2734.167497</td>\n",
       "      <td>0.418262</td>\n",
       "      <td>0.418262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>1.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.591346</td>\n",
       "      <td>-58.388321</td>\n",
       "      <td>0</td>\n",
       "      <td>1958.538011</td>\n",
       "      <td>1958.538011</td>\n",
       "      <td>5459.770115</td>\n",
       "      <td>3501.232104</td>\n",
       "      <td>0.358722</td>\n",
       "      <td>0.358722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>1.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.596988</td>\n",
       "      <td>-58.388055</td>\n",
       "      <td>0</td>\n",
       "      <td>1956.577443</td>\n",
       "      <td>1956.577443</td>\n",
       "      <td>5307.692308</td>\n",
       "      <td>3351.114865</td>\n",
       "      <td>0.368631</td>\n",
       "      <td>0.368631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1</td>\n",
       "      <td>1954.147222</td>\n",
       "      <td>1954.147222</td>\n",
       "      <td>5111.111111</td>\n",
       "      <td>3156.963889</td>\n",
       "      <td>0.382333</td>\n",
       "      <td>0.382333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.571541</td>\n",
       "      <td>-58.432132</td>\n",
       "      <td>1</td>\n",
       "      <td>1926.448952</td>\n",
       "      <td>1926.448952</td>\n",
       "      <td>5161.290323</td>\n",
       "      <td>3234.841371</td>\n",
       "      <td>0.373249</td>\n",
       "      <td>0.373249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  surface_total_in_m2  surface_covered_in_m2  Ambientes  pileta  \\\n",
       "1420    1.0                 61.0                   58.0          2       0   \n",
       "84      1.0                529.0                  431.0          8       0   \n",
       "661     1.0                115.0                  110.0          3       0   \n",
       "1737    1.0                 74.0                   67.0          3       0   \n",
       "1742    1.0                114.0                  105.0          4       0   \n",
       "632     1.0                 56.0                   51.0          2       0   \n",
       "631     1.0                114.0                  100.0          4       0   \n",
       "2890    1.0                330.0                  300.0          6       0   \n",
       "2823    1.0                110.0                  100.0          4       0   \n",
       "200     1.0                130.0                  130.0          4       0   \n",
       "1271    1.0                 78.0                   73.0          3       0   \n",
       "3000    1.0                 43.0                   40.0          2       0   \n",
       "472     1.0                 45.0                   42.0          2       0   \n",
       "3077    1.0                 80.0                   69.0          3       0   \n",
       "2618    1.0                342.0                  298.0          5       0   \n",
       "1078    1.0                100.0                  100.0          3       0   \n",
       "3186    1.0                174.0                  174.0          5       0   \n",
       "2622    1.0                260.0                  260.0          5       0   \n",
       "352     1.0                225.0                  210.0          5       0   \n",
       "416     1.0                 31.0                   18.0          3       0   \n",
       "\n",
       "      gimnasio  laundry  sum  solarium  a estrenar  subte  cochera    latitud  \\\n",
       "1420         0        0    0         0           0      0        0 -34.589410   \n",
       "84           0        0    0         0           0      0        1 -34.583042   \n",
       "661          0        0    0         0           0      0        0 -34.577166   \n",
       "1737         0        0    0         0           0      0        0 -34.562084   \n",
       "1742         0        0    0         0           0      0        0 -34.555357   \n",
       "632          0        0    0         0           0      0        0 -34.577761   \n",
       "631          0        0    0         1           0      0        0 -34.577777   \n",
       "2890         0        0    0         0           0      0        1 -34.589546   \n",
       "2823         0        0    0         0           0      0        0 -34.588583   \n",
       "200          0        0    0         0           0      0        0 -34.563342   \n",
       "1271         0        0    0         0           0      0        0 -34.586732   \n",
       "3000         0        0    0         0           0      0        0 -34.590962   \n",
       "472          0        0    0         0           0      0        1 -34.570547   \n",
       "3077         0        0    0         0           1      0        0 -34.589652   \n",
       "2618         0        0    0         0           0      0        1 -34.589546   \n",
       "1078         0        0    0         0           0      0        0 -34.583396   \n",
       "3186         0        0    0         0           0      0        1 -34.591346   \n",
       "2622         0        0    0         0           0      0        1 -34.596988   \n",
       "352          0        0    0         0           0      0        0 -34.571150   \n",
       "416          0        0    1         1           0      0        1 -34.571541   \n",
       "\n",
       "       longitud  BARRIO_PALERMO        error    error_abs    precioxm2  \\\n",
       "1420 -58.431334               1  2662.765350  2662.765350  5245.901639   \n",
       "84   -58.400016               1  2501.367749  2501.367749  5387.523629   \n",
       "661  -58.425303               1  2408.218221  2408.218221  5434.782609   \n",
       "1737 -58.456686               0  2398.725102  2398.725102  5000.000000   \n",
       "1742 -58.458188               0  2297.759598  2297.759598  5043.859649   \n",
       "632  -58.424323               1  2244.639951  2244.639951  5267.857143   \n",
       "631  -58.424300               1  2205.953497  2205.953497  5175.438596   \n",
       "2890 -58.397364               0  2181.372167  2181.372167  5303.030303   \n",
       "2823 -58.387745               0  2170.728806  2170.728806  5363.636364   \n",
       "200  -58.436630               1  2148.403691  2148.403691  5384.615385   \n",
       "1271 -58.409907               1  2065.631787  2065.631787  5128.205128   \n",
       "3000 -58.406078               0  2064.566536  2064.566536  4883.720930   \n",
       "472  -58.434497               1  1988.929529  1988.929529  5333.333333   \n",
       "3077 -58.406289               0  1980.102735  1980.102735  5000.000000   \n",
       "2618 -58.397364               0  1976.050767  1976.050767  4970.760234   \n",
       "1078 -58.433728               1  1965.832503  1965.832503  4700.000000   \n",
       "3186 -58.388321               0  1958.538011  1958.538011  5459.770115   \n",
       "2622 -58.388055               0  1956.577443  1956.577443  5307.692308   \n",
       "352  -58.423297               1  1954.147222  1954.147222  5111.111111   \n",
       "416  -58.432132               1  1926.448952  1926.448952  5161.290323   \n",
       "\n",
       "             pred  error_prop  error_prop_abs  \n",
       "1420  2583.136289    0.507590        0.507590  \n",
       "84    2886.155880    0.464289        0.464289  \n",
       "661   3026.564388    0.443112        0.443112  \n",
       "1737  2601.274898    0.479745        0.479745  \n",
       "1742  2746.100051    0.455556        0.455556  \n",
       "632   3023.217192    0.426101        0.426101  \n",
       "631   2969.485100    0.426235        0.426235  \n",
       "2890  3121.658136    0.411344        0.411344  \n",
       "2823  3192.907557    0.404712        0.404712  \n",
       "200   3236.211694    0.398989        0.398989  \n",
       "1271  3062.573341    0.402798        0.402798  \n",
       "3000  2819.154395    0.422745        0.422745  \n",
       "472   3344.403804    0.372924        0.372924  \n",
       "3077  3019.897265    0.396021        0.396021  \n",
       "2618  2994.709467    0.397535        0.397535  \n",
       "1078  2734.167497    0.418262        0.418262  \n",
       "3186  3501.232104    0.358722        0.358722  \n",
       "2622  3351.114865    0.368631        0.368631  \n",
       "352   3156.963889    0.382333        0.382333  \n",
       "416   3234.841371    0.373249        0.373249  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e.sort_values(by='error_abs',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>Ambientes</th>\n",
       "      <th>pileta</th>\n",
       "      <th>gimnasio</th>\n",
       "      <th>laundry</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>BARRIO_PALERMO</th>\n",
       "      <th>error</th>\n",
       "      <th>error_abs</th>\n",
       "      <th>precioxm2</th>\n",
       "      <th>pred</th>\n",
       "      <th>error_prop</th>\n",
       "      <th>error_prop_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2399.0</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2.399000e+03</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>102.491038</td>\n",
       "      <td>90.738641</td>\n",
       "      <td>3.011672</td>\n",
       "      <td>0.223426</td>\n",
       "      <td>0.134223</td>\n",
       "      <td>0.132138</td>\n",
       "      <td>0.155065</td>\n",
       "      <td>0.117549</td>\n",
       "      <td>0.104210</td>\n",
       "      <td>0.192163</td>\n",
       "      <td>0.409754</td>\n",
       "      <td>-34.579077</td>\n",
       "      <td>-58.424129</td>\n",
       "      <td>0.451855</td>\n",
       "      <td>1.309968e-09</td>\n",
       "      <td>468.331615</td>\n",
       "      <td>3120.518690</td>\n",
       "      <td>3120.518690</td>\n",
       "      <td>-0.039795</td>\n",
       "      <td>0.158020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>82.043601</td>\n",
       "      <td>72.416289</td>\n",
       "      <td>1.496963</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>0.340962</td>\n",
       "      <td>0.338712</td>\n",
       "      <td>0.362042</td>\n",
       "      <td>0.322140</td>\n",
       "      <td>0.305597</td>\n",
       "      <td>0.394083</td>\n",
       "      <td>0.491891</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.497780</td>\n",
       "      <td>6.147883e+02</td>\n",
       "      <td>398.169129</td>\n",
       "      <td>785.685402</td>\n",
       "      <td>489.220736</td>\n",
       "      <td>0.215536</td>\n",
       "      <td>0.151853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>-58.472364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.818912e+03</td>\n",
       "      <td>0.078030</td>\n",
       "      <td>1098.039216</td>\n",
       "      <td>1161.654504</td>\n",
       "      <td>-1.576649</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.589884</td>\n",
       "      <td>-58.440513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.968371e+02</td>\n",
       "      <td>169.919161</td>\n",
       "      <td>2583.333333</td>\n",
       "      <td>2813.167701</td>\n",
       "      <td>-0.150656</td>\n",
       "      <td>0.055678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.581687</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.380355e+01</td>\n",
       "      <td>376.074566</td>\n",
       "      <td>2997.777778</td>\n",
       "      <td>3059.680708</td>\n",
       "      <td>-0.019368</td>\n",
       "      <td>0.121589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-34.567018</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.433305e+02</td>\n",
       "      <td>644.259263</td>\n",
       "      <td>3530.323529</td>\n",
       "      <td>3377.978990</td>\n",
       "      <td>0.101394</td>\n",
       "      <td>0.214176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-34.549922</td>\n",
       "      <td>-58.384275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.662765e+03</td>\n",
       "      <td>2662.765350</td>\n",
       "      <td>5466.666667</td>\n",
       "      <td>4713.650614</td>\n",
       "      <td>0.618314</td>\n",
       "      <td>1.576649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        const  surface_total_in_m2  surface_covered_in_m2    Ambientes  \\\n",
       "count  2399.0          2399.000000            2399.000000  2399.000000   \n",
       "mean      1.0           102.491038              90.738641     3.011672   \n",
       "std       0.0            82.043601              72.416289     1.496963   \n",
       "min       1.0            21.000000               4.000000     1.000000   \n",
       "25%       1.0            46.000000              41.000000     2.000000   \n",
       "50%       1.0            78.000000              68.000000     3.000000   \n",
       "75%       1.0           130.000000             116.000000     4.000000   \n",
       "max       1.0           789.000000             690.000000     8.000000   \n",
       "\n",
       "            pileta     gimnasio      laundry          sum     solarium  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.223426     0.134223     0.132138     0.155065     0.117549   \n",
       "std       0.416629     0.340962     0.338712     0.362042     0.322140   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        a estrenar        subte      cochera      latitud     longitud  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.104210     0.192163     0.409754   -34.579077   -58.424129   \n",
       "std       0.305597     0.394083     0.491891     0.012964     0.022798   \n",
       "min       0.000000     0.000000     0.000000   -34.599730   -58.472364   \n",
       "25%       0.000000     0.000000     0.000000   -34.589884   -58.440513   \n",
       "50%       0.000000     0.000000     0.000000   -34.581687   -58.423297   \n",
       "75%       0.000000     0.000000     1.000000   -34.567018   -58.404019   \n",
       "max       1.000000     1.000000     1.000000   -34.549922   -58.384275   \n",
       "\n",
       "       BARRIO_PALERMO         error    error_abs    precioxm2         pred  \\\n",
       "count     2399.000000  2.399000e+03  2399.000000  2399.000000  2399.000000   \n",
       "mean         0.451855  1.309968e-09   468.331615  3120.518690  3120.518690   \n",
       "std          0.497780  6.147883e+02   398.169129   785.685402   489.220736   \n",
       "min          0.000000 -1.818912e+03     0.078030  1098.039216  1161.654504   \n",
       "25%          0.000000 -3.968371e+02   169.919161  2583.333333  2813.167701   \n",
       "50%          0.000000 -5.380355e+01   376.074566  2997.777778  3059.680708   \n",
       "75%          1.000000  3.433305e+02   644.259263  3530.323529  3377.978990   \n",
       "max          1.000000  2.662765e+03  2662.765350  5466.666667  4713.650614   \n",
       "\n",
       "        error_prop  error_prop_abs  \n",
       "count  2399.000000     2399.000000  \n",
       "mean     -0.039795        0.158020  \n",
       "std       0.215536        0.151853  \n",
       "min      -1.576649        0.000027  \n",
       "25%      -0.150656        0.055678  \n",
       "50%      -0.019368        0.121589  \n",
       "75%       0.101394        0.214176  \n",
       "max       0.618314        1.576649  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Histograma')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(data_e.error,color = 'b', bins=20)\n",
    "plt.grid(True)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('error')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.title('Histograma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Histograma')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(data_e.error_prop,color = 'b', bins=20)\n",
    "plt.grid(True)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('error')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.title('Histograma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los errores parecen ser mayores en tÃ©rminos absolutos subvaluando propiedades mÃ¡s caras, pero en tÃ©rminos relativos se sobrevalÃºa propiedades mÃ¡s baratas. Por lo general son casos con pocas dummies (muchos 'ceros'), pero no parece haber motivos para sacarlas. Lo ideal serÃ­a tener mÃ¡s features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Segundo modelado con Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Creando Polynomial features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>Ambientes</th>\n",
       "      <th>pileta</th>\n",
       "      <th>amenities</th>\n",
       "      <th>gimnasio</th>\n",
       "      <th>laundry</th>\n",
       "      <th>sum</th>\n",
       "      <th>solarium</th>\n",
       "      <th>parrilla</th>\n",
       "      <th>a estrenar</th>\n",
       "      <th>subte</th>\n",
       "      <th>cochera</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>BARRIO_PALERMO</th>\n",
       "      <th>BARRIO_RECOLETA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>145.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.567161</td>\n",
       "      <td>-58.433130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.580504</td>\n",
       "      <td>-58.405874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.581538</td>\n",
       "      <td>-58.415915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.584294</td>\n",
       "      <td>-58.436469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.591108</td>\n",
       "      <td>-58.415921</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>61.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>174.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.567798</td>\n",
       "      <td>-58.446126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.582449</td>\n",
       "      <td>-58.413420</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.586119</td>\n",
       "      <td>-58.420016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.597424</td>\n",
       "      <td>-58.415989</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>172.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.562966</td>\n",
       "      <td>-58.439613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.574394</td>\n",
       "      <td>-58.437400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.583130</td>\n",
       "      <td>-58.419100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>242.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.577071</td>\n",
       "      <td>-58.404312</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>120.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.566005</td>\n",
       "      <td>-58.439133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.575874</td>\n",
       "      <td>-58.433872</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>85.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.577924</td>\n",
       "      <td>-58.436915</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>145.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.567161</td>\n",
       "      <td>-58.433130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>145.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.567161</td>\n",
       "      <td>-58.433130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.573747</td>\n",
       "      <td>-58.432352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.583848</td>\n",
       "      <td>-58.410753</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.570000</td>\n",
       "      <td>-58.432411</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.592742</td>\n",
       "      <td>-58.406147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.592742</td>\n",
       "      <td>-58.406147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>44.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.592742</td>\n",
       "      <td>-58.406147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.592742</td>\n",
       "      <td>-58.406147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.589240</td>\n",
       "      <td>-58.399604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.597294</td>\n",
       "      <td>-58.395978</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>164.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.596221</td>\n",
       "      <td>-58.402166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.589546</td>\n",
       "      <td>-58.397364</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>104.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.588881</td>\n",
       "      <td>-58.395254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>284.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.592401</td>\n",
       "      <td>-58.392742</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.590113</td>\n",
       "      <td>-58.387827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>177.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.587001</td>\n",
       "      <td>-58.397299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>103.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.596859</td>\n",
       "      <td>-58.392085</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>227.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.586787</td>\n",
       "      <td>-58.385877</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>227.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.586787</td>\n",
       "      <td>-58.385877</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588719</td>\n",
       "      <td>-58.388496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588684</td>\n",
       "      <td>-58.388496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>266.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.590108</td>\n",
       "      <td>-58.392045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>220.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.594774</td>\n",
       "      <td>-58.401548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.589887</td>\n",
       "      <td>-58.396331</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>-58.398735</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>-58.398735</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.593339</td>\n",
       "      <td>-58.399164</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>275.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.589041</td>\n",
       "      <td>-58.390847</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>114.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.592124</td>\n",
       "      <td>-58.401144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>82.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.593388</td>\n",
       "      <td>-58.405405</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>201.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.595857</td>\n",
       "      <td>-58.387697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.596714</td>\n",
       "      <td>-58.415507</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588872</td>\n",
       "      <td>-58.400253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>175.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-34.588872</td>\n",
       "      <td>-58.400253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3428 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      surface_total_in_m2  surface_covered_in_m2  Ambientes  pileta  \\\n",
       "0                   185.0                  103.0          5       1   \n",
       "1                   185.0                  185.0          5       0   \n",
       "2                    84.0                   70.0          3       0   \n",
       "3                    77.0                   68.0          4       1   \n",
       "4                    58.0                   58.0          3       0   \n",
       "5                   145.0                  124.0          4       0   \n",
       "7                   104.0                   96.0          4       0   \n",
       "8                   120.0                  120.0          4       0   \n",
       "9                    54.0                   45.0          2       0   \n",
       "10                  175.0                   90.0          5       1   \n",
       "11                   86.0                   79.0          4       0   \n",
       "12                   61.0                   55.0          2       1   \n",
       "13                  174.0                  140.0          5       0   \n",
       "15                  128.0                  128.0          4       1   \n",
       "16                   44.0                   42.0          2       0   \n",
       "17                   75.0                   67.0          3       1   \n",
       "18                  124.0                   67.0          3       1   \n",
       "19                  172.0                  160.0          5       0   \n",
       "20                   84.0                   84.0          3       0   \n",
       "21                   62.0                   62.0          3       0   \n",
       "22                   36.0                   36.0          2       0   \n",
       "23                  242.0                  226.0          4       0   \n",
       "24                  120.0                   85.0          4       0   \n",
       "25                   75.0                   67.0          3       0   \n",
       "26                   85.0                   75.0          3       0   \n",
       "27                  145.0                  124.0          5       0   \n",
       "28                  145.0                  124.0          5       0   \n",
       "29                   70.0                   70.0          3       0   \n",
       "30                  130.0                  130.0          4       0   \n",
       "31                   36.0                   33.0          1       0   \n",
       "...                   ...                    ...        ...     ...   \n",
       "3703                 45.0                   40.0          2       0   \n",
       "3704                 43.0                   37.0          2       0   \n",
       "3705                 44.0                   38.0          2       0   \n",
       "3706                 43.0                   37.0          2       0   \n",
       "3707                100.0                   90.0          4       0   \n",
       "3708                113.0                  113.0          3       0   \n",
       "3710                164.0                  135.0          5       0   \n",
       "3711                 95.0                   88.0          4       0   \n",
       "3712                104.0                   92.0          4       0   \n",
       "3713                284.0                  258.0          6       0   \n",
       "3714                130.0                  120.0          4       0   \n",
       "3715                177.0                  175.0          5       0   \n",
       "3716                103.0                   93.0          4       0   \n",
       "3717                227.0                  203.0          1       0   \n",
       "3718                227.0                  203.0          1       0   \n",
       "3719                128.0                  128.0          4       1   \n",
       "3720                111.0                  111.0          4       1   \n",
       "3721                266.0                  266.0          5       0   \n",
       "3722                220.0                  217.0          5       0   \n",
       "3723                 97.0                   97.0          4       0   \n",
       "3724                 50.0                   49.0          2       0   \n",
       "3725                 50.0                   49.0          2       0   \n",
       "3726                110.0                  100.0          4       0   \n",
       "3727                275.0                  252.0          6       0   \n",
       "3728                114.0                   12.0          4       0   \n",
       "3729                 82.0                   71.0          4       0   \n",
       "3730                201.0                  201.0          5       0   \n",
       "3731                 37.0                   33.0          1       0   \n",
       "3732                 41.0                   37.0          1       0   \n",
       "3733                175.0                  140.0          5       0   \n",
       "\n",
       "      amenities  gimnasio  laundry  sum  solarium  parrilla  a estrenar  \\\n",
       "0             0         1        1    1         1         1           0   \n",
       "1             0         0        0    0         0         0           0   \n",
       "2             1         1        0    0         0         1           1   \n",
       "3             1         0        0    1         1         1           0   \n",
       "4             0         0        0    0         0         0           0   \n",
       "5             0         0        0    0         0         0           0   \n",
       "7             0         0        0    0         0         0           0   \n",
       "8             0         0        0    0         0         0           0   \n",
       "9             0         0        0    0         0         0           0   \n",
       "10            1         1        0    1         1         1           0   \n",
       "11            0         0        0    0         0         0           0   \n",
       "12            1         1        1    1         0         1           0   \n",
       "13            0         1        1    1         0         0           0   \n",
       "15            1         0        0    1         0         1           0   \n",
       "16            0         0        0    0         0         0           0   \n",
       "17            0         1        1    1         0         0           0   \n",
       "18            0         0        0    0         0         0           0   \n",
       "19            0         0        0    0         0         0           0   \n",
       "20            0         0        0    0         0         0           0   \n",
       "21            0         0        0    0         0         0           0   \n",
       "22            0         0        0    0         0         0           0   \n",
       "23            0         0        0    0         0         0           0   \n",
       "24            0         0        0    0         0         1           0   \n",
       "25            0         0        0    0         0         0           0   \n",
       "26            0         0        0    0         0         0           0   \n",
       "27            0         0        0    0         0         0           0   \n",
       "28            0         0        0    0         0         0           0   \n",
       "29            0         0        0    0         0         1           1   \n",
       "30            0         0        0    0         0         0           0   \n",
       "31            1         0        0    1         0         1           0   \n",
       "...         ...       ...      ...  ...       ...       ...         ...   \n",
       "3703          1         0        0    0         0         0           0   \n",
       "3704          1         0        0    0         0         0           0   \n",
       "3705          1         0        0    0         0         0           0   \n",
       "3706          1         0        0    0         0         0           0   \n",
       "3707          0         0        0    0         0         0           0   \n",
       "3708          0         0        0    0         0         0           0   \n",
       "3710          0         0        0    0         0         1           0   \n",
       "3711          0         0        0    0         0         0           0   \n",
       "3712          0         0        0    0         0         0           0   \n",
       "3713          0         0        0    0         0         0           0   \n",
       "3714          0         0        0    0         0         0           0   \n",
       "3715          0         0        0    0         0         0           0   \n",
       "3716          0         0        0    0         0         0           0   \n",
       "3717          0         0        0    0         0         0           0   \n",
       "3718          0         0        0    0         0         0           0   \n",
       "3719          0         1        0    0         0         0           0   \n",
       "3720          0         1        0    0         0         0           0   \n",
       "3721          0         0        0    0         0         0           0   \n",
       "3722          0         0        0    0         0         0           0   \n",
       "3723          0         0        0    0         0         0           0   \n",
       "3724          0         0        0    0         0         0           0   \n",
       "3725          0         0        0    0         0         0           0   \n",
       "3726          0         0        0    0         0         0           0   \n",
       "3727          0         0        0    0         0         0           0   \n",
       "3728          0         0        0    0         0         0           0   \n",
       "3729          0         0        0    0         0         0           0   \n",
       "3730          0         0        0    0         0         0           0   \n",
       "3731          1         0        0    1         0         1           1   \n",
       "3732          0         1        1    0         1         0           0   \n",
       "3733          0         1        1    0         1         0           0   \n",
       "\n",
       "      subte  cochera    latitud   longitud  BARRIO_PALERMO  BARRIO_RECOLETA  \n",
       "0         0        1 -34.569983 -58.434669               1                0  \n",
       "1         0        0 -34.571150 -58.423297               1                0  \n",
       "2         0        0 -34.569355 -58.433363               1                0  \n",
       "3         0        1 -34.580572 -58.440032               1                0  \n",
       "4         1        0 -34.580978 -58.428962               1                0  \n",
       "5         0        1 -34.567161 -58.433130               1                0  \n",
       "7         0        0 -34.580504 -58.405874               1                0  \n",
       "8         0        0 -34.581538 -58.415915               1                0  \n",
       "9         0        0 -34.571150 -58.423297               1                0  \n",
       "10        1        1 -34.584294 -58.436469               1                0  \n",
       "11        1        0 -34.591108 -58.415921               1                0  \n",
       "12        0        1 -34.571150 -58.423297               1                0  \n",
       "13        0        0 -34.571150 -58.423297               1                0  \n",
       "15        0        1 -34.567798 -58.446126               1                0  \n",
       "16        1        0 -34.582449 -58.413420               1                0  \n",
       "17        0        1 -34.586119 -58.420016               1                0  \n",
       "18        0        0 -34.597424 -58.415989               1                0  \n",
       "19        0        1 -34.562966 -58.439613               1                0  \n",
       "20        0        0 -34.574394 -58.437400               1                0  \n",
       "21        1        0 -34.571150 -58.423297               1                0  \n",
       "22        0        0 -34.583130 -58.419100               1                0  \n",
       "23        0        1 -34.577071 -58.404312               1                0  \n",
       "24        0        1 -34.566005 -58.439133               1                0  \n",
       "25        0        0 -34.575874 -58.433872               1                0  \n",
       "26        0        0 -34.577924 -58.436915               1                0  \n",
       "27        0        0 -34.567161 -58.433130               1                0  \n",
       "28        0        0 -34.567161 -58.433130               1                0  \n",
       "29        1        0 -34.573747 -58.432352               1                0  \n",
       "30        0        0 -34.583848 -58.410753               1                0  \n",
       "31        1        0 -34.570000 -58.432411               1                0  \n",
       "...     ...      ...        ...        ...             ...              ...  \n",
       "3703      0        0 -34.592742 -58.406147               0                1  \n",
       "3704      0        0 -34.592742 -58.406147               0                1  \n",
       "3705      0        0 -34.592742 -58.406147               0                1  \n",
       "3706      0        0 -34.592742 -58.406147               0                1  \n",
       "3707      0        0 -34.589240 -58.399604               0                1  \n",
       "3708      0        0 -34.597294 -58.395978               0                1  \n",
       "3710      0        0 -34.596221 -58.402166               0                1  \n",
       "3711      0        0 -34.589546 -58.397364               0                1  \n",
       "3712      0        0 -34.588881 -58.395254               0                1  \n",
       "3713      0        0 -34.592401 -58.392742               0                1  \n",
       "3714      0        0 -34.590113 -58.387827               0                1  \n",
       "3715      0        0 -34.587001 -58.397299               0                1  \n",
       "3716      0        0 -34.596859 -58.392085               0                1  \n",
       "3717      0        1 -34.586787 -58.385877               0                1  \n",
       "3718      0        1 -34.586787 -58.385877               0                1  \n",
       "3719      0        1 -34.588719 -58.388496               0                1  \n",
       "3720      0        1 -34.588684 -58.388496               0                1  \n",
       "3721      0        1 -34.590108 -58.392045               0                1  \n",
       "3722      0        0 -34.594774 -58.401548               0                1  \n",
       "3723      0        0 -34.589887 -58.396331               0                1  \n",
       "3724      1        0 -34.599730 -58.398735               0                1  \n",
       "3725      1        0 -34.599730 -58.398735               0                1  \n",
       "3726      0        1 -34.593339 -58.399164               0                1  \n",
       "3727      0        0 -34.589041 -58.390847               0                1  \n",
       "3728      0        0 -34.592124 -58.401144               0                1  \n",
       "3729      0        0 -34.593388 -58.405405               0                1  \n",
       "3730      0        0 -34.595857 -58.387697               0                1  \n",
       "3731      0        1 -34.596714 -58.415507               0                1  \n",
       "3732      0        1 -34.588872 -58.400253               0                1  \n",
       "3733      0        1 -34.588872 -58.400253               0                1  \n",
       "\n",
       "[3428 rows x 17 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux_sq = PolynomialFeatures(2,include_bias=True,interaction_only=False).fit_transform(data_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 171)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aux_sq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399, 171) (2399,)\n",
      "(1029, 171) (1029,)\n"
     ]
    }
   ],
   "source": [
    "#Split train y test \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_aux_sq, data.price_usd_per_m2, test_size=0.3, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NormalizaciÃ³n (para Ridge y Lasso)\n",
    "se = StandardScaler()\n",
    "X_train_s = se.fit_transform(X_train)\n",
    "X_test_s = se.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>19055.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>-6395.446939</td>\n",
       "      <td>-10810.413796</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-3560.708296</td>\n",
       "      <td>-6018.770924</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-172.849917</td>\n",
       "      <td>-292.173346</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.083756</td>\n",
       "      <td>2020.085546</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3414.610561</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6395.662676</td>\n",
       "      <td>-10808.309871</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6395.662676</td>\n",
       "      <td>-10808.309871</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-172.855748</td>\n",
       "      <td>-292.116483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.164385</td>\n",
       "      <td>2019.760527</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3413.281586</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2903.825861</td>\n",
       "      <td>-4908.402454</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2419.854884</td>\n",
       "      <td>-4090.335378</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.708066</td>\n",
       "      <td>-175.300088</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.040339</td>\n",
       "      <td>2020.003682</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3414.457858</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5929.0</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-2662.704044</td>\n",
       "      <td>-4499.882433</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4624.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-2351.478896</td>\n",
       "      <td>-3973.922149</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-138.322288</td>\n",
       "      <td>-233.760126</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.815960</td>\n",
       "      <td>2020.889720</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3415.237293</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2005.696730</td>\n",
       "      <td>-3388.879813</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2005.696730</td>\n",
       "      <td>-3388.879813</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.742934</td>\n",
       "      <td>-175.286887</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.844046</td>\n",
       "      <td>2020.530666</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3413.943635</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2    3    4    5    6    7    8    9    10   11   12   13   \\\n",
       "0  1.0  185.0  103.0  5.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1  1.0  185.0  185.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  1.0   84.0   70.0  3.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "3  1.0   77.0   68.0  4.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "4  1.0   58.0   58.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "         14         15   16   17       18       19     20     21    22   \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  34225.0  19055.0  925.0  185.0   0.0   \n",
       "1 -34.571150 -58.423297  1.0  0.0  34225.0  34225.0  925.0    0.0   0.0   \n",
       "2 -34.569355 -58.433363  1.0  0.0   7056.0   5880.0  252.0    0.0  84.0   \n",
       "3 -34.580572 -58.440032  1.0  0.0   5929.0   5236.0  308.0   77.0  77.0   \n",
       "4 -34.580978 -58.428962  1.0  0.0   3364.0   3364.0  174.0    0.0   0.0   \n",
       "\n",
       "     23     24     25     26     27    28    29     30           31   \\\n",
       "0  185.0  185.0  185.0  185.0  185.0   0.0   0.0  185.0 -6395.446939   \n",
       "1    0.0    0.0    0.0    0.0    0.0   0.0   0.0    0.0 -6395.662676   \n",
       "2   84.0    0.0    0.0    0.0   84.0  84.0   0.0    0.0 -2903.825861   \n",
       "3    0.0    0.0   77.0   77.0   77.0   0.0   0.0   77.0 -2662.704044   \n",
       "4    0.0    0.0    0.0    0.0    0.0   0.0  58.0    0.0 -2005.696730   \n",
       "\n",
       "            32     33   34       35     36     37    38     39     40     41   \\\n",
       "0 -10810.413796  185.0  0.0  10609.0  515.0  103.0   0.0  103.0  103.0  103.0   \n",
       "1 -10808.309871  185.0  0.0  34225.0  925.0    0.0   0.0    0.0    0.0    0.0   \n",
       "2  -4908.402454   84.0  0.0   4900.0  210.0    0.0  70.0   70.0    0.0    0.0   \n",
       "3  -4499.882433   77.0  0.0   4624.0  272.0   68.0  68.0    0.0    0.0   68.0   \n",
       "4  -3388.879813   58.0  0.0   3364.0  174.0    0.0   0.0    0.0    0.0    0.0   \n",
       "\n",
       "     42     43    44    45     46           47            48     49   50   \\\n",
       "0  103.0  103.0   0.0   0.0  103.0 -3560.708296  -6018.770924  103.0  0.0   \n",
       "1    0.0    0.0   0.0   0.0    0.0 -6395.662676 -10808.309871  185.0  0.0   \n",
       "2    0.0   70.0  70.0   0.0    0.0 -2419.854884  -4090.335378   70.0  0.0   \n",
       "3   68.0   68.0   0.0   0.0   68.0 -2351.478896  -3973.922149   68.0  0.0   \n",
       "4    0.0    0.0   0.0  58.0    0.0 -2005.696730  -3388.879813   58.0  0.0   \n",
       "\n",
       "    51   52   53   54   55   56   57   58   59   60   61          62   \\\n",
       "0  25.0  5.0  0.0  5.0  5.0  5.0  5.0  5.0  0.0  0.0  5.0 -172.849917   \n",
       "1  25.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -172.855748   \n",
       "2   9.0  0.0  3.0  3.0  0.0  0.0  0.0  3.0  3.0  0.0  0.0 -103.708066   \n",
       "3  16.0  4.0  4.0  0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0 -138.322288   \n",
       "4   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0 -103.742934   \n",
       "\n",
       "          63   64   65   66   67   68   69   70   71   72   73   74   75   \\\n",
       "0 -292.173346  5.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1 -292.116483  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -175.300088  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3 -233.760126  4.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "4 -175.286887  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         76         77   78   79   80   81   82   83   84   85   86   87   \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
       "3 -34.580572 -58.440032  1.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
       "4  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   88         89         90   91   92   93   94   95   96   97   98   99   \\\n",
       "0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0 -34.569355 -58.433363  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
       "3  1.0 -34.580572 -58.440032  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   100        101        102  103  104  105  106  107  108  109  110  111  \\\n",
       "0  1.0 -34.569983 -58.434669  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0 -34.569355 -58.433363  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         112        113  114  115  116  117  118  119  120  121        122  \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0 -34.569983   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "2  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "3  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0 -34.580572   \n",
       "4  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "\n",
       "         123  124  125  126  127  128  129  130        131        132  133  \\\n",
       "0 -58.434669  1.0  0.0  1.0  1.0  0.0  0.0  1.0 -34.569983 -58.434669  1.0   \n",
       "1  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "2  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "3 -58.440032  1.0  0.0  1.0  1.0  0.0  0.0  1.0 -34.580572 -58.440032  1.0   \n",
       "4  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "\n",
       "   134  135  136  137  138        139        140  141  142  143  144  145  \\\n",
       "0  0.0  1.0  0.0  0.0  1.0 -34.569983 -58.434669  1.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  1.0  0.0  0.0 -34.569355 -58.433363  1.0  0.0  1.0  0.0  0.0   \n",
       "3  0.0  1.0  0.0  0.0  1.0 -34.580572 -58.440032  1.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         146        147  148  149  150  151        152        153  154  155  \\\n",
       "0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "2 -34.569355 -58.433363  1.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "3  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "4  -0.000000  -0.000000  0.0  0.0  1.0  0.0 -34.580978 -58.428962  1.0  0.0   \n",
       "\n",
       "   156        157        158  159  160          161          162        163  \\\n",
       "0  1.0 -34.569983 -58.434669  1.0  0.0  1195.083756  2020.085546 -34.569983   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  1195.164385  2019.760527 -34.571150   \n",
       "2  0.0  -0.000000  -0.000000  0.0  0.0  1195.040339  2020.003682 -34.569355   \n",
       "3  1.0 -34.580572 -58.440032  1.0  0.0  1195.815960  2020.889720 -34.580572   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  1195.844046  2020.530666 -34.580978   \n",
       "\n",
       "   164          165        166  167  168  169  170  \n",
       "0 -0.0  3414.610561 -58.434669 -0.0  1.0  0.0  0.0  \n",
       "1 -0.0  3413.281586 -58.423297 -0.0  1.0  0.0  0.0  \n",
       "2 -0.0  3414.457858 -58.433363 -0.0  1.0  0.0  0.0  \n",
       "3 -0.0  3415.237293 -58.440032 -0.0  1.0  0.0  0.0  \n",
       "4 -0.0  3413.943635 -58.428962 -0.0  1.0  0.0  0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = pd.DataFrame(data_aux_sq)\n",
    "prueba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PerdÃ­ todos los nombres de columnas... No sÃ© cÃ³mo gadorchas tenerlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1. RegresiÃ³n lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n MÃ­nimos Cuadrados Ordinarios\n",
      "Coeficientes: [-2.39846499e+01 -2.46414393e+04  1.92916004e+04  2.46820541e+05\n",
      " -3.78690036e+05  7.39693628e+05  1.99521614e+05  1.16301798e+05\n",
      "  4.12631391e+05 -1.63397681e+05 -1.70140175e+05  4.96215342e+05\n",
      " -3.49106721e+05  3.17708655e+05  4.66475941e+07  7.98050046e+07\n",
      " -1.91674746e+04 -2.04392997e+05  1.50716793e-02 -6.29425555e-03\n",
      "  1.24907139e+00 -5.70441092e+00 -2.43781447e+00  5.05646423e+00\n",
      " -4.15864149e+00  1.97936097e+00  4.28108296e+00  1.70970703e+00\n",
      " -3.04442053e+00 -3.07027350e+00 -1.70119347e+00 -3.12611172e+02\n",
      " -2.36395305e+02  4.21975457e-01  4.35458229e+00 -1.45455398e-02\n",
      " -1.24814369e-01  1.06951886e+01  2.08686364e+00 -8.23836750e+00\n",
      "  9.60639637e+00 -3.89955049e+00 -7.64359581e+00 -6.23967323e+00\n",
      "  5.20889131e+00  1.47725822e-01  1.94962753e+00  2.53403620e+02\n",
      "  1.79949797e+02  2.71608228e+00 -3.16222765e+00 -3.58402200e+01\n",
      " -1.86986773e+02  5.96228930e+01  1.58534770e+02  5.79393847e+00\n",
      "  7.73156271e+01  2.04077991e+02  7.05625010e+01  1.62862633e-01\n",
      "  6.65876702e+01 -1.53677257e+01  1.33725680e+03  3.42928667e+03\n",
      " -1.51353465e+02 -2.15060066e+02 -3.78686953e+05 -6.99065206e+01\n",
      "  2.21450702e+02  9.79848947e+00 -1.60868197e+02 -1.77385424e+02\n",
      "  7.65179004e+01  5.71434797e+01 -9.09190480e+01  2.20590476e+02\n",
      " -9.82478639e+03 -7.15598792e+03 -8.66148247e+01  1.52389637e+02\n",
      "  7.40236241e+05 -2.80134750e+02 -4.09532333e+01 -1.46592770e+02\n",
      "  3.55415791e+02  4.29113795e+01  1.73654322e+01 -1.06728893e+02\n",
      " -1.32463719e+02  2.08262278e+04  1.29985718e+04 -2.53365976e+02\n",
      " -1.25435401e+02  1.99351801e+05  3.07816086e+02  3.31290779e+02\n",
      " -1.22091240e+02  3.33794403e+01 -3.14359858e+02  1.69353311e+02\n",
      " -1.16446498e+01 -1.37741430e+03  7.64238407e+03 -1.14119050e+02\n",
      " -4.28436177e+02  1.16286230e+05 -1.52839290e+02 -1.30391682e+02\n",
      "  1.70648354e+02 -4.82754992e+01  1.86100338e+02 -3.11779510e+02\n",
      " -1.37383652e+02  4.06389162e+03 -2.95946616e+01 -1.19419663e+02\n",
      "  4.12653768e+05 -1.18350470e+02 -6.65598890e+01 -5.14272503e+01\n",
      "  1.67497576e+02  7.15642032e+01  1.04764999e+04  7.92518205e+03\n",
      "  8.61301007e+01  4.90424845e+01 -1.63397781e+05 -1.25928216e+02\n",
      " -2.47909949e+02 -1.21439065e+02 -1.76245961e+02 -4.82730255e+03\n",
      " -2.73700200e+03  5.39579943e+01 -5.72197626e+01 -1.70123478e+05\n",
      " -7.13052236e+01  9.77560109e+01  2.66451043e+02 -6.57166588e+03\n",
      " -1.93539709e+03 -8.20840317e+01 -1.96520425e+01  4.96193888e+05\n",
      "  1.12500494e+02 -1.14408758e+02  1.11169203e+04  1.04006470e+04\n",
      "  1.12912842e+02 -6.38639920e+01 -3.49111857e+05 -2.56618448e+01\n",
      " -6.52980877e+03 -8.08217599e+03  7.31339896e+01  3.19272720e+02\n",
      "  3.17704998e+05  5.20598192e+03  7.78658322e+03 -1.22188271e+02\n",
      " -1.79638606e+02  1.04717860e+05  6.74257072e+05  1.61621958e+04\n",
      "  2.54757581e+04  4.83237570e+05 -1.02204378e+04 -2.20804917e+04\n",
      " -1.91653563e+04  0.00000000e+00 -2.04393335e+05]\n",
      "Residual sum of squares: 303079.91\n",
      "Varianza explicada: 0.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print ('RegresiÃ³n MÃ­nimos Cuadrados Ordinarios')\n",
    "#Coeficiente\n",
    "print('Coeficientes:',regr.coef_)\n",
    "# MSE \n",
    "print(\"Residual sum of squares: %.2f\"\n",
    " % np.mean((regr.predict(X_train) - y_train) ** 2))\n",
    "# Varianza explicada\n",
    "print('Varianza explicada: %.2f\\n' % regr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36486097 0.48000469 0.31956727 0.41279438 0.37396097]\n",
      "0.3902376538780348\n",
      "0.05379616376578437\n"
     ]
    }
   ],
   "source": [
    "# Un cross validation\n",
    "results = cross_val_score(regr,X_train,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr.predict(X_test)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2. RegresiÃ³n Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Lasso\n",
      "alpha: 2.41\n",
      "\n",
      "Coeficientes: [ 0.00000000e+00 -3.72768929e+02  1.91190714e+02 -0.00000000e+00\n",
      "  0.00000000e+00  3.40533020e+01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  7.56597633e+00  1.36827382e+01\n",
      " -2.89665358e+00  7.12520050e+01 -0.00000000e+00  1.03766505e+02\n",
      "  5.93209572e+00 -4.19344869e+01  1.17741575e+02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -4.74310340e+01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -6.66204814e+01 -0.00000000e+00  3.02858666e+02\n",
      "  4.06150225e+00 -9.80514710e+01 -5.83477037e+01 -0.00000000e+00\n",
      "  0.00000000e+00  2.64475200e+01  0.00000000e+00 -0.00000000e+00\n",
      "  7.99231016e+01  0.00000000e+00 -9.58459876e+01 -1.13915807e+02\n",
      "  5.52666604e+01 -0.00000000e+00  8.11850773e+01 -2.81070853e+02\n",
      " -0.00000000e+00  1.45784054e+02 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  7.66646245e+01  2.24741664e+01  1.61612951e+01\n",
      "  1.89837020e+01  1.53164997e+02  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.75979575e+00\n",
      " -0.00000000e+00 -7.96468836e+00  3.22032111e+01  3.72731684e+00\n",
      "  6.39317533e+01  0.00000000e+00 -3.03842527e+01 -1.11413151e+01\n",
      "  7.32864139e+00  1.85349661e+01 -0.00000000e+00  1.05845612e+02\n",
      " -2.27943640e+01 -0.00000000e+00 -1.42054159e+01  1.91709098e+01\n",
      "  1.22552356e+01 -3.35318229e+01 -3.98053976e-01 -4.02163705e+01\n",
      "  5.27715038e+01  0.00000000e+00 -1.77557763e+00 -0.00000000e+00\n",
      " -3.40278757e+01 -5.65078355e-01 -1.26389012e+00 -2.09096725e+01\n",
      " -0.00000000e+00  0.00000000e+00  6.86085586e+01  6.97029546e+01\n",
      " -3.63609436e+01  2.02749486e-01 -7.54821550e+01  8.14242815e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  2.48624217e+01\n",
      "  9.39728762e+00  0.00000000e+00 -1.88089421e+01 -4.46602148e+01\n",
      "  2.70014501e+01 -0.00000000e+00  5.86558843e+00 -6.70277355e+01\n",
      " -0.00000000e+00 -0.00000000e+00  5.22808866e+00  0.00000000e+00\n",
      "  0.00000000e+00 -3.40132616e+01 -0.00000000e+00 -1.68687449e+01\n",
      "  5.78207409e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  7.09048702e+00  6.52074391e+00  0.00000000e+00 -1.37425055e+01\n",
      " -2.79220578e+01 -8.33051678e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  1.04880766e+01  9.01674726e+00  9.88406764e+00\n",
      " -6.30332691e+00  2.22058838e+01  4.76697053e+01 -6.77060779e-01\n",
      " -0.00000000e+00  0.00000000e+00  2.58465246e+01  4.89056806e+00\n",
      "  1.67346334e+01 -1.69563759e+01 -3.06672332e-01 -0.00000000e+00\n",
      "  6.23746062e+01  2.61753304e+01 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  8.04017554e+00\n",
      "  5.93626009e-01 -9.57247071e-01 -0.00000000e+00  1.80595879e+01\n",
      "  2.59913679e+01  0.00000000e+00 -1.83508571e+02 -6.74642056e-01\n",
      "  5.98175239e+00 -1.23520526e+01 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00]\n",
      "\n",
      "Residual sum of squares: 332656.07\n",
      "\n",
      "Varianza explicada: 0.46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "regr2=linear_model.LassoCV(cv=5).fit(X_train_s, y_train)\n",
    "\n",
    "print ('RegresiÃ³n Lasso' )\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr2.alpha_)\n",
    "# Coeficiente\n",
    "print ('Coeficientes:', regr2.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr2.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr2.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39391073 0.46382384 0.37754854 0.42620613 0.39982551]\n",
      "0.41226294964874627\n",
      "0.030164621997500897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(regr2,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr2.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 RegresiÃ³n Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Ridge\n",
      "alpha: 10.00\n",
      "\n",
      "Coeficientes: [   0.         -278.05216119  196.28531804   -2.48766762   33.65918017\n",
      "   20.57767675  -13.06705613   -7.4362738    -2.01282758    2.69362881\n",
      "    0.42519241    9.15066647  -12.97385695   25.14920725    9.71296999\n",
      "   82.2580479    -0.73387932  -17.69306139  234.63043831  -15.18944983\n",
      "  204.46713073  -15.51221059 -187.93904159   51.21877264  -86.9603419\n",
      "  -17.92488624   78.31373478   72.79750473  -43.07859899  -83.78797269\n",
      "  -98.59098684  277.03148322  279.21020237 -213.67046646  -92.8607651\n",
      " -233.89264204   82.45318304  171.24508141  128.9626677  -116.06954074\n",
      "  214.7754621    -5.94901889 -201.01318239 -238.15170356   94.90233107\n",
      "  -44.31235389  136.90817538 -197.16836663 -194.9784052   274.16603052\n",
      "   37.92786431 -106.20000209 -161.66979721  103.74667062  115.43745082\n",
      "    6.12607282   37.52586795  194.25075056   45.09051006   -7.74421589\n",
      "   98.55539533   -8.23871235    1.64904127    3.85922798  -18.48028924\n",
      "  -21.33502272   33.65918017   15.16173978   68.37359445   -0.3310672\n",
      "  -58.14293242  -36.40709857   16.037642     35.27385474  -11.66398111\n",
      "  100.15483381  -34.19096323  -33.39018842  -45.69683718   12.20885628\n",
      "   20.57767675  -54.57371572   -5.02554849  -60.40514415   72.01571665\n",
      "    1.78312667   -5.05315961  -14.68335004  -48.60719589  -19.89848869\n",
      "  -20.07862909  -55.38133694  -16.01657468  -13.06705613   83.37689538\n",
      "   92.63769288  -50.16550425    3.28689256  -67.30107334   24.23720905\n",
      "   -0.73390274   12.85716212   14.05235479   32.20998394   12.27095069\n",
      "   -7.4362738   -35.19046823  -51.29110581   33.571283    -11.96791931\n",
      "   23.02592207  -77.01196988    7.32047456    7.7665037    14.92701565\n",
      "   -1.28541341   -2.01282758  -26.74643485   -7.46934785  -30.11819669\n",
      "   27.69483399   18.40468493    1.85884675    2.57900495   27.93866694\n",
      "   19.83805163    2.69362881  -16.78687507  -31.32849796  -19.73412544\n",
      "  -12.69488726   -3.16820323   -2.71689708   18.40558152   11.08869088\n",
      "    0.42519241  -14.45620507   28.78983931   64.4775606    -1.28674198\n",
      "   -0.42676287    6.63442205   23.67921122    9.15066647   25.01894711\n",
      "  -32.39652965   -8.422558     -8.67681704   64.75143124   29.1256121\n",
      "  -12.97385695   -5.32867403   12.97106648   12.38696315   -1.01933975\n",
      "   16.15332833   25.14920725  -25.72406291  -23.64484206   27.82795517\n",
      "   40.76318856  -11.96904715 -165.96793309    0.93177693   19.21244686\n",
      "  -81.10337992    1.58771385   17.97341813   -0.73387932    0.\n",
      "  -17.69306139]\n",
      "\n",
      "Residual sum of squares: 322763.72\n",
      "\n",
      "Varianza explicada: 0.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr3=linear_model.RidgeCV(alphas=[0.1,0.2,0.5,0.7,1.38,1.39,1.5,1.6,3.0,5.0,7.0,10.0, 18.9, 19.0, 50.0])\n",
    "regr3.fit(X_train_s,y_train)\n",
    "\n",
    "print ('RegresiÃ³n Ridge')\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr3.alpha_)\n",
    "# Coeficientes\n",
    "print('Coeficientes:', regr3.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr3.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr3.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39297735 0.46355559 0.3495934  0.44056704 0.38360877]\n",
      "0.4060604305996865\n",
      "0.04089051075388417\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(regr3,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr3.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Lasso y la Ridge dieron mejor, y la Lasso ademÃ¡s eliminÃ³ varias variables, nos quedarÃ­amos con esa. Ya se veÃ­a que habÃ­a overfitting en el cross validation de la regresiÃ³n comÃºn y silvestre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. AnÃ¡lisis de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMC: 303079.91043343436\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       price_usd_per_m2   R-squared:                       0.509\n",
      "Model:                            OLS   Adj. R-squared:                  0.474\n",
      "Method:                 Least Squares   F-statistic:                     14.79\n",
      "Date:                Sun, 30 Sep 2018   Prob (F-statistic):          5.00e-246\n",
      "Time:                        11:16:41   Log-Likelihood:                -18544.\n",
      "No. Observations:                2399   AIC:                         3.740e+04\n",
      "Df Residuals:                    2241   BIC:                         3.832e+04\n",
      "Df Model:                         157                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3.139e+09   1.14e+09      2.763      0.006    9.11e+08    5.37e+09\n",
      "x1         -2.464e+04   7822.659     -3.150      0.002      -4e+04   -9301.024\n",
      "x2          1.929e+04   8724.495      2.211      0.027    2182.664    3.64e+04\n",
      "x3          2.468e+05   1.76e+05      1.404      0.160   -9.79e+04    5.92e+05\n",
      "x4         -3.787e+05   2.37e+05     -1.599      0.110   -8.43e+05    8.57e+04\n",
      "x5            7.4e+05    2.4e+05      3.079      0.002    2.69e+05    1.21e+06\n",
      "x6          1.994e+05   2.67e+05      0.747      0.455   -3.24e+05    7.23e+05\n",
      "x7          1.163e+05   2.52e+05      0.462      0.644   -3.78e+05     6.1e+05\n",
      "x8          4.126e+05   2.41e+05      1.713      0.087   -5.97e+04    8.85e+05\n",
      "x9         -1.634e+05    2.4e+05     -0.680      0.497   -6.35e+05    3.08e+05\n",
      "x10        -1.701e+05   2.03e+05     -0.837      0.403   -5.69e+05    2.28e+05\n",
      "x11         4.962e+05   2.18e+05      2.275      0.023    6.85e+04    9.24e+05\n",
      "x12        -3.491e+05   2.18e+05     -1.604      0.109   -7.76e+05    7.76e+04\n",
      "x13         3.177e+05   1.51e+05      2.101      0.036    2.12e+04    6.14e+05\n",
      "x14         4.665e+07   3.49e+07      1.335      0.182   -2.19e+07    1.15e+08\n",
      "x15         7.981e+07   2.31e+07      3.460      0.001    3.46e+07    1.25e+08\n",
      "x16        -1.917e+04   3.76e+05     -0.051      0.959   -7.56e+05    7.18e+05\n",
      "x17        -2.044e+05   5.82e+05     -0.351      0.725   -1.34e+06    9.36e+05\n",
      "x18            0.0151      0.013      1.159      0.247      -0.010       0.041\n",
      "x19           -0.0063      0.025     -0.257      0.797      -0.054       0.042\n",
      "x20            1.2491      0.779      1.604      0.109      -0.278       2.777\n",
      "x21           -5.7044      2.473     -2.307      0.021     -10.554      -0.855\n",
      "x22           -2.4378      2.398     -1.016      0.310      -7.141       2.266\n",
      "x23            5.0565      2.950      1.714      0.087      -0.729      10.842\n",
      "x24           -4.1586      3.036     -1.370      0.171     -10.113       1.795\n",
      "x25            1.9794      2.336      0.847      0.397      -2.602       6.560\n",
      "x26            4.2811      2.886      1.483      0.138      -1.379       9.941\n",
      "x27            1.7097      1.909      0.896      0.370      -2.033       5.453\n",
      "x28           -3.0444      3.183     -0.956      0.339      -9.287       3.198\n",
      "x29           -3.0703      2.071     -1.483      0.138      -7.131       0.990\n",
      "x30           -1.7012      1.573     -1.081      0.280      -4.787       1.384\n",
      "x31         -312.6112    109.898     -2.845      0.004    -528.123     -97.099\n",
      "x32         -236.3953     86.845     -2.722      0.007    -406.701     -66.089\n",
      "x33            0.4220      2.886      0.146      0.884      -5.237       6.081\n",
      "x34            4.3546      4.688      0.929      0.353      -4.839      13.548\n",
      "x35           -0.0145      0.014     -1.031      0.303      -0.042       0.013\n",
      "x36           -0.1248      0.875     -0.143      0.887      -1.842       1.592\n",
      "x37           10.6952      3.075      3.478      0.001       4.665      16.726\n",
      "x38            2.0869      2.794      0.747      0.455      -3.392       7.566\n",
      "x39           -8.2384      3.403     -2.421      0.016     -14.912      -1.565\n",
      "x40            9.6064      3.490      2.753      0.006       2.763      16.450\n",
      "x41           -3.8996      2.860     -1.363      0.173      -9.509       1.710\n",
      "x42           -7.6436      3.244     -2.356      0.019     -14.005      -1.282\n",
      "x43           -6.2397      2.259     -2.762      0.006     -10.670      -1.809\n",
      "x44            5.2089      3.842      1.356      0.175      -2.325      12.743\n",
      "x45            0.1477      2.708      0.055      0.956      -5.162       5.457\n",
      "x46            1.9496      1.697      1.149      0.251      -1.378       5.278\n",
      "x47          253.4036    129.342      1.959      0.050      -0.239     507.047\n",
      "x48          179.9498     96.704      1.861      0.063      -9.689     369.588\n",
      "x49            2.7161      3.302      0.822      0.411      -3.760       9.192\n",
      "x50           -3.1622      5.500     -0.575      0.565     -13.948       7.624\n",
      "x51          -35.8402     15.846     -2.262      0.024     -66.915      -4.766\n",
      "x52         -186.9868     64.483     -2.900      0.004    -313.439     -60.535\n",
      "x53           59.6229     57.297      1.041      0.298     -52.737     171.983\n",
      "x54          158.5348     69.462      2.282      0.023      22.319     294.751\n",
      "x55            5.7939     73.286      0.079      0.937    -137.922     149.510\n",
      "x56           77.3156     65.400      1.182      0.237     -50.934     205.566\n",
      "x57          204.0780     64.484      3.165      0.002      77.623     330.533\n",
      "x58           70.5625     58.721      1.202      0.230     -44.590     185.715\n",
      "x59            0.1629     73.179      0.002      0.998    -143.342     143.668\n",
      "x60           66.5877     51.960      1.282      0.200     -35.307     168.482\n",
      "x61          -15.3677     40.915     -0.376      0.707     -95.603      64.867\n",
      "x62         1337.2568   2918.009      0.458      0.647   -4385.026    7059.539\n",
      "x63         3429.2867   2041.205      1.680      0.093    -573.563    7432.137\n",
      "x64         -151.3535     82.930     -1.825      0.068    -313.981      11.274\n",
      "x65         -215.0601    134.853     -1.595      0.111    -479.510      49.390\n",
      "x66        -3.787e+05   2.37e+05     -1.599      0.110   -8.43e+05    8.57e+04\n",
      "x67          -69.9065    119.664     -0.584      0.559    -304.570     164.757\n",
      "x68          221.4507    140.630      1.575      0.115     -54.328     497.229\n",
      "x69            9.7985    129.024      0.076      0.939    -243.220     262.817\n",
      "x70         -160.8682    112.391     -1.431      0.152    -381.270      59.534\n",
      "x71         -177.3854    127.945     -1.386      0.166    -428.289      73.518\n",
      "x72           76.5179    111.227      0.688      0.492    -141.600     294.636\n",
      "x73           57.1435    132.183      0.432      0.666    -202.071     316.358\n",
      "x74          -90.9190    128.921     -0.705      0.481    -343.737     161.899\n",
      "x75          220.5905    106.009      2.081      0.038      12.705     428.476\n",
      "x76        -9824.7864   7605.491     -1.292      0.197   -2.47e+04    5089.758\n",
      "x77        -7155.9879   6015.272     -1.190      0.234    -1.9e+04    4640.099\n",
      "x78          -86.6148    240.907     -0.360      0.719    -559.039     385.809\n",
      "x79          152.3896    391.265      0.389      0.697    -614.890     919.670\n",
      "x80           7.4e+05    2.4e+05      3.079      0.002    2.69e+05    1.21e+06\n",
      "x81         -280.1347    118.546     -2.363      0.018    -512.606     -47.663\n",
      "x82          -40.9532    110.127     -0.372      0.710    -256.915     175.008\n",
      "x83         -146.5928    104.186     -1.407      0.160    -350.904      57.718\n",
      "x84          355.4158    108.450      3.277      0.001     142.743     568.088\n",
      "x85           42.9114    101.738      0.422      0.673    -156.598     242.421\n",
      "x86           17.3654    119.437      0.145      0.884    -216.853     251.583\n",
      "x87         -106.7289    122.418     -0.872      0.383    -346.793     133.335\n",
      "x88         -132.4637    100.842     -1.314      0.189    -330.216      65.289\n",
      "x89         2.083e+04   7479.604      2.784      0.005    6158.551    3.55e+04\n",
      "x90           1.3e+04   5930.360      2.192      0.028    1368.999    2.46e+04\n",
      "x91         -253.3660    221.103     -1.146      0.252    -686.954     180.222\n",
      "x92         -125.4354    379.731     -0.330      0.741    -870.097     619.226\n",
      "x93         1.994e+05   2.67e+05      0.747      0.455   -3.24e+05    7.23e+05\n",
      "x94          307.8161    126.455      2.434      0.015      59.835     555.797\n",
      "x95          331.2908    115.217      2.875      0.004     105.347     557.235\n",
      "x96         -122.0912    126.035     -0.969      0.333    -369.249     125.066\n",
      "x97           33.3794    123.197      0.271      0.786    -208.213     274.971\n",
      "x98         -314.3599    146.831     -2.141      0.032    -602.299     -26.420\n",
      "x99          169.3533    154.201      1.098      0.272    -133.039     471.746\n",
      "x100         -11.6446    122.781     -0.095      0.924    -252.421     229.132\n",
      "x101       -1377.4143   9044.409     -0.152      0.879   -1.91e+04    1.64e+04\n",
      "x102        7642.3841   6381.022      1.198      0.231   -4870.949    2.02e+04\n",
      "x103        -114.1191    251.268     -0.454      0.650    -606.861     378.623\n",
      "x104        -428.4362    437.607     -0.979      0.328   -1286.594     429.722\n",
      "x105        1.163e+05   2.52e+05      0.462      0.644   -3.78e+05     6.1e+05\n",
      "x106        -152.8393    110.159     -1.387      0.165    -368.863      63.184\n",
      "x107        -130.3917    115.665     -1.127      0.260    -357.214      96.431\n",
      "x108         170.6484    109.715      1.555      0.120     -44.506     385.802\n",
      "x109         -48.2755    131.101     -0.368      0.713    -305.367     208.816\n",
      "x110         186.1003    120.215      1.548      0.122     -49.643     421.844\n",
      "x111        -311.7795    113.957     -2.736      0.006    -535.252     -88.307\n",
      "x112        -137.3837   8072.393     -0.017      0.986    -1.6e+04    1.57e+04\n",
      "x113        4063.8916   6301.942      0.645      0.519   -8294.363    1.64e+04\n",
      "x114         -29.5947    238.978     -0.124      0.901    -498.236     439.047\n",
      "x115        -119.4197    416.402     -0.287      0.774    -935.994     697.155\n",
      "x116        4.126e+05   2.41e+05      1.713      0.087   -5.97e+04    8.85e+05\n",
      "x117        -118.3505    113.914     -1.039      0.299    -341.738     105.037\n",
      "x118         -66.5599    102.140     -0.652      0.515    -266.859     133.739\n",
      "x119         -51.4273    122.214     -0.421      0.674    -291.093     188.238\n",
      "x120         167.4976    129.485      1.294      0.196     -86.425     421.420\n",
      "x121          71.5642    107.730      0.664      0.507    -139.696     282.824\n",
      "x122        1.048e+04   8187.039      1.280      0.201   -5578.472    2.65e+04\n",
      "x123        7925.1820   5820.300      1.362      0.173   -3488.561    1.93e+04\n",
      "x124          86.1301    223.019      0.386      0.699    -351.215     523.475\n",
      "x125          49.0425    387.180      0.127      0.899    -710.227     808.312\n",
      "x126       -1.634e+05    2.4e+05     -0.680      0.497   -6.35e+05    3.08e+05\n",
      "x127        -125.9282    112.567     -1.119      0.263    -346.675      94.818\n",
      "x128        -247.9099    128.578     -1.928      0.054    -500.054       4.234\n",
      "x129        -121.4391    131.817     -0.921      0.357    -379.935     137.057\n",
      "x130        -176.2460    112.936     -1.561      0.119    -397.716      45.224\n",
      "x131       -4827.3026   8040.710     -0.600      0.548   -2.06e+04    1.09e+04\n",
      "x132       -2737.0020   5965.671     -0.459      0.646   -1.44e+04    8961.817\n",
      "x133          53.9580    242.364      0.223      0.824    -421.323     529.239\n",
      "x134         -57.2198    421.622     -0.136      0.892    -884.030     769.591\n",
      "x135       -1.701e+05   2.03e+05     -0.837      0.403   -5.69e+05    2.28e+05\n",
      "x136         -71.3052    114.696     -0.622      0.534    -296.226     153.616\n",
      "x137          97.7560    103.922      0.941      0.347    -106.037     301.549\n",
      "x138         266.4510     92.534      2.879      0.004      84.990     447.913\n",
      "x139       -6571.6659   6369.324     -1.032      0.302   -1.91e+04    5918.726\n",
      "x140       -1935.3971   5065.938     -0.382      0.702   -1.19e+04    7999.024\n",
      "x141         -82.0840    188.096     -0.436      0.663    -450.945     286.777\n",
      "x142         -19.6520    325.647     -0.060      0.952    -658.253     618.949\n",
      "x143        4.962e+05   2.18e+05      2.275      0.023    6.85e+04    9.24e+05\n",
      "x144         112.5005    105.988      1.061      0.289     -95.345     320.346\n",
      "x145        -114.4088     97.464     -1.174      0.241    -305.537      76.720\n",
      "x146        1.112e+04   7496.378      1.483      0.138   -3583.649    2.58e+04\n",
      "x147         1.04e+04   5571.506      1.867      0.062    -525.205    2.13e+04\n",
      "x148         112.9128    237.442      0.476      0.634    -352.717     578.542\n",
      "x149         -63.8640    398.148     -0.160      0.873    -844.642     716.914\n",
      "x150       -3.491e+05   2.18e+05     -1.604      0.109   -7.76e+05    7.76e+04\n",
      "x151         -25.6618     79.424     -0.323      0.747    -181.413     130.090\n",
      "x152       -6529.8088   6308.832     -1.035      0.301   -1.89e+04    5841.957\n",
      "x153       -8082.1760   4947.829     -1.633      0.103   -1.78e+04    1620.631\n",
      "x154          73.1340    165.155      0.443      0.658    -250.740     397.008\n",
      "x155         319.2727    274.285      1.164      0.245    -218.606     857.151\n",
      "x156        3.177e+05   1.51e+05      2.101      0.036    2.12e+04    6.14e+05\n",
      "x157        5205.9819   4939.189      1.054      0.292   -4479.882    1.49e+04\n",
      "x158        7786.5832   3486.781      2.233      0.026     948.924    1.46e+04\n",
      "x159        -122.1883    136.976     -0.892      0.372    -390.801     146.424\n",
      "x160        -179.6386    225.754     -0.796      0.426    -622.347     263.069\n",
      "x161        1.047e+05   3.07e+05      0.341      0.733   -4.98e+05    7.07e+05\n",
      "x162        6.743e+05   3.17e+05      2.126      0.034    5.22e+04     1.3e+06\n",
      "x163        1.616e+04   1.29e+04      1.253      0.210   -9131.331    4.15e+04\n",
      "x164        2.548e+04   2.03e+04      1.254      0.210   -1.44e+04    6.53e+04\n",
      "x165        4.832e+05    1.5e+05      3.227      0.001     1.9e+05    7.77e+05\n",
      "x166       -1.022e+04   1.05e+04     -0.969      0.333   -3.09e+04    1.05e+04\n",
      "x167       -2.208e+04   1.75e+04     -1.264      0.206   -5.63e+04    1.22e+04\n",
      "x168       -1.917e+04   3.76e+05     -0.051      0.959   -7.56e+05    7.18e+05\n",
      "x169                0          0        nan        nan           0           0\n",
      "x170       -2.044e+05   5.82e+05     -0.351      0.725   -1.34e+06    9.36e+05\n",
      "==============================================================================\n",
      "Omnibus:                      250.154   Durbin-Watson:                   2.096\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              556.429\n",
      "Skew:                           0.632   Prob(JB):                    1.49e-121\n",
      "Kurtosis:                       4.992   Cond. No.                     1.15e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.52e-20. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "# Agregar constante\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.plot(y_train,y_train, '-.', c='grey')\n",
    "plt.scatter(predictions, y_train, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos el MSE y un resumen del modelo\n",
    "print (\"EMC:\", mean_squared_error(y_train, predictions))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>error</th>\n",
       "      <th>error_abs</th>\n",
       "      <th>precioxm2</th>\n",
       "      <th>pred</th>\n",
       "      <th>error_prop</th>\n",
       "      <th>error_prop_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.563127</td>\n",
       "      <td>-58.462991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1382.525068</td>\n",
       "      <td>-2338.519628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1244.272561</td>\n",
       "      <td>-2104.667665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.563127</td>\n",
       "      <td>-58.462991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.563127</td>\n",
       "      <td>-58.462991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.609727</td>\n",
       "      <td>2020.663755</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3417.921282</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1468.938917</td>\n",
       "      <td>1468.938917</td>\n",
       "      <td>1115.873226</td>\n",
       "      <td>2513.869238</td>\n",
       "      <td>-1.316403</td>\n",
       "      <td>1.316403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.587337</td>\n",
       "      <td>-58.415642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9801.0</td>\n",
       "      <td>9801.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3424.146412</td>\n",
       "      <td>-5783.148538</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9801.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3424.146412</td>\n",
       "      <td>-5783.148538</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-138.349350</td>\n",
       "      <td>-233.662567</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.283915</td>\n",
       "      <td>2020.441518</td>\n",
       "      <td>-34.587337</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3412.387207</td>\n",
       "      <td>-58.415642</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1440.535512</td>\n",
       "      <td>1440.535512</td>\n",
       "      <td>1128.345789</td>\n",
       "      <td>2941.626515</td>\n",
       "      <td>-1.276679</td>\n",
       "      <td>1.276679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.576666</td>\n",
       "      <td>-58.402930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129600.0</td>\n",
       "      <td>129600.0</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>-12447.599688</td>\n",
       "      <td>-21025.054620</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129600.0</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>-12447.599688</td>\n",
       "      <td>-21025.054620</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-242.036661</td>\n",
       "      <td>-408.820507</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.576666</td>\n",
       "      <td>-58.402930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.545818</td>\n",
       "      <td>2019.378575</td>\n",
       "      <td>-34.576666</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3410.902174</td>\n",
       "      <td>-58.402930</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1537.706625</td>\n",
       "      <td>1537.706625</td>\n",
       "      <td>1279.387576</td>\n",
       "      <td>4497.665157</td>\n",
       "      <td>-1.201908</td>\n",
       "      <td>1.201908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.555819</td>\n",
       "      <td>-58.448435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1209.453676</td>\n",
       "      <td>-2045.695218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1105.786218</td>\n",
       "      <td>-1870.349914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.555819</td>\n",
       "      <td>-58.448435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.555819</td>\n",
       "      <td>-58.448435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.555819</td>\n",
       "      <td>-58.448435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.104647</td>\n",
       "      <td>2019.733551</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3416.219531</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1419.044347</td>\n",
       "      <td>1419.044347</td>\n",
       "      <td>1202.374865</td>\n",
       "      <td>2507.486012</td>\n",
       "      <td>-1.180201</td>\n",
       "      <td>1.180201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.577675</td>\n",
       "      <td>-58.424355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3136.0</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-1936.349778</td>\n",
       "      <td>-3271.763880</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2809.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1832.616754</td>\n",
       "      <td>-3096.490815</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-69.155349</td>\n",
       "      <td>-116.848710</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.577675</td>\n",
       "      <td>-58.424355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.577675</td>\n",
       "      <td>-58.424355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.577675</td>\n",
       "      <td>-58.424355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.577675</td>\n",
       "      <td>-58.424355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.615581</td>\n",
       "      <td>2020.178336</td>\n",
       "      <td>-34.577675</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3413.405257</td>\n",
       "      <td>-58.424355</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1510.741972</td>\n",
       "      <td>1510.741972</td>\n",
       "      <td>1284.581064</td>\n",
       "      <td>4463.560766</td>\n",
       "      <td>-1.176058</td>\n",
       "      <td>1.176058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.567402</td>\n",
       "      <td>-58.449891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1140.724253</td>\n",
       "      <td>-1928.846396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1140.724253</td>\n",
       "      <td>-1928.846396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.134803</td>\n",
       "      <td>-116.899782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.567402</td>\n",
       "      <td>-58.449891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.905253</td>\n",
       "      <td>2020.460849</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3416.389735</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1385.151633</td>\n",
       "      <td>1385.151633</td>\n",
       "      <td>1196.319018</td>\n",
       "      <td>2811.615911</td>\n",
       "      <td>-1.157845</td>\n",
       "      <td>1.157845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.567102</td>\n",
       "      <td>-58.456020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1520.952506</td>\n",
       "      <td>-2572.064871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1520.952506</td>\n",
       "      <td>-2572.064871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.134205</td>\n",
       "      <td>-116.912040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.567102</td>\n",
       "      <td>-58.456020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.884568</td>\n",
       "      <td>2020.655222</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3417.106251</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1380.158719</td>\n",
       "      <td>1380.158719</td>\n",
       "      <td>1222.457419</td>\n",
       "      <td>2747.961852</td>\n",
       "      <td>-1.129004</td>\n",
       "      <td>1.129004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.565125</td>\n",
       "      <td>-58.438056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64516.0</td>\n",
       "      <td>56642.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>-8779.541627</td>\n",
       "      <td>-14843.266347</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49729.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>-7708.022767</td>\n",
       "      <td>-13031.686596</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-172.825623</td>\n",
       "      <td>-292.190282</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.565125</td>\n",
       "      <td>-58.438056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.747833</td>\n",
       "      <td>2019.918699</td>\n",
       "      <td>-34.565125</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3415.006446</td>\n",
       "      <td>-58.438056</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1490.326872</td>\n",
       "      <td>1490.326872</td>\n",
       "      <td>1470.588235</td>\n",
       "      <td>3117.912552</td>\n",
       "      <td>-1.013422</td>\n",
       "      <td>1.013422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.559471</td>\n",
       "      <td>-58.455992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-8639.867750</td>\n",
       "      <td>-14613.998100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57600.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>-8294.273040</td>\n",
       "      <td>-14029.438176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-172.797355</td>\n",
       "      <td>-292.279962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.559471</td>\n",
       "      <td>-58.455992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.559471</td>\n",
       "      <td>-58.455992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.559471</td>\n",
       "      <td>-58.455992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.357036</td>\n",
       "      <td>2020.208174</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3417.103047</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1280.803312</td>\n",
       "      <td>1280.803312</td>\n",
       "      <td>1268.500426</td>\n",
       "      <td>3702.024179</td>\n",
       "      <td>-1.009699</td>\n",
       "      <td>1.009699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.574151</td>\n",
       "      <td>-58.420150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2869.654566</td>\n",
       "      <td>-4848.872409</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2869.654566</td>\n",
       "      <td>-4848.872409</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-138.296606</td>\n",
       "      <td>-233.680598</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.371945</td>\n",
       "      <td>2019.827094</td>\n",
       "      <td>-34.574151</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3412.913868</td>\n",
       "      <td>-58.420150</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1651.300602</td>\n",
       "      <td>1651.300602</td>\n",
       "      <td>1645.569620</td>\n",
       "      <td>3221.127532</td>\n",
       "      <td>-1.003483</td>\n",
       "      <td>1.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1520.618924</td>\n",
       "      <td>-2571.585072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1382.380840</td>\n",
       "      <td>-2337.804611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.119042</td>\n",
       "      <td>-116.890231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.360491</td>\n",
       "      <td>2019.835188</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3415.831499</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2034.607507</td>\n",
       "      <td>2034.607507</td>\n",
       "      <td>2033.898305</td>\n",
       "      <td>4197.387357</td>\n",
       "      <td>-1.000349</td>\n",
       "      <td>1.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.583276</td>\n",
       "      <td>-58.426027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-2074.996536</td>\n",
       "      <td>-3505.561620</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-2005.829985</td>\n",
       "      <td>-3388.709566</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-103.749827</td>\n",
       "      <td>-175.278081</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.583276</td>\n",
       "      <td>-58.426027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.002951</td>\n",
       "      <td>2020.563394</td>\n",
       "      <td>-34.583276</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3413.600631</td>\n",
       "      <td>-58.426027</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1022.821823</td>\n",
       "      <td>1022.821823</td>\n",
       "      <td>1187.500000</td>\n",
       "      <td>3116.410918</td>\n",
       "      <td>-0.861324</td>\n",
       "      <td>0.861324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.591393</td>\n",
       "      <td>-58.396558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1210.698758</td>\n",
       "      <td>-2043.879524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1210.698758</td>\n",
       "      <td>-2043.879524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.182786</td>\n",
       "      <td>-116.793116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.564475</td>\n",
       "      <td>2020.018286</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.591393</td>\n",
       "      <td>3410.157966</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.396558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1343.530720</td>\n",
       "      <td>1343.530720</td>\n",
       "      <td>1714.285714</td>\n",
       "      <td>3140.419881</td>\n",
       "      <td>-0.783726</td>\n",
       "      <td>0.783726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.586045</td>\n",
       "      <td>-58.440394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2040.576655</td>\n",
       "      <td>-3447.983246</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1660.130160</td>\n",
       "      <td>-2805.138912</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.172090</td>\n",
       "      <td>-116.880788</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.586045</td>\n",
       "      <td>-58.440394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.586045</td>\n",
       "      <td>-58.440394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.586045</td>\n",
       "      <td>-58.440394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.194509</td>\n",
       "      <td>2021.222097</td>\n",
       "      <td>-34.586045</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3415.279651</td>\n",
       "      <td>-58.440394</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1115.772657</td>\n",
       "      <td>1115.772657</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2800.408107</td>\n",
       "      <td>-0.743848</td>\n",
       "      <td>0.743848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556222</td>\n",
       "      <td>-58.458679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9025.0</td>\n",
       "      <td>5605.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3282.841058</td>\n",
       "      <td>-5553.574507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2038.817078</td>\n",
       "      <td>-3449.062062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.668665</td>\n",
       "      <td>-175.376037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556222</td>\n",
       "      <td>-58.458679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.132456</td>\n",
       "      <td>2020.111070</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3417.417152</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1959.485982</td>\n",
       "      <td>1959.485982</td>\n",
       "      <td>2640.000000</td>\n",
       "      <td>2016.916110</td>\n",
       "      <td>-0.742230</td>\n",
       "      <td>0.742230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.594006</td>\n",
       "      <td>-58.399810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13924.0</td>\n",
       "      <td>13924.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>-4082.092767</td>\n",
       "      <td>-6891.177568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13924.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>-4082.092767</td>\n",
       "      <td>-6891.177568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-138.376026</td>\n",
       "      <td>-233.599240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.594006</td>\n",
       "      <td>-58.399810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.594006</td>\n",
       "      <td>-58.399810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1196.745286</td>\n",
       "      <td>2020.283403</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.594006</td>\n",
       "      <td>3410.537796</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.399810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1345.604114</td>\n",
       "      <td>1345.604114</td>\n",
       "      <td>1906.976744</td>\n",
       "      <td>2948.476072</td>\n",
       "      <td>-0.705622</td>\n",
       "      <td>0.705622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.565955</td>\n",
       "      <td>-58.452589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6561.0</td>\n",
       "      <td>6156.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2799.842363</td>\n",
       "      <td>-4734.659677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5776.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2627.012588</td>\n",
       "      <td>-4442.396734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.697865</td>\n",
       "      <td>-175.357766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.805252</td>\n",
       "      <td>2020.469553</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3416.705114</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-857.573516</td>\n",
       "      <td>857.573516</td>\n",
       "      <td>1227.272727</td>\n",
       "      <td>2732.335020</td>\n",
       "      <td>-0.698764</td>\n",
       "      <td>0.698764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.568157</td>\n",
       "      <td>-58.444332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6561.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2800.020747</td>\n",
       "      <td>-4733.990873</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2419.771016</td>\n",
       "      <td>-4091.103224</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.704472</td>\n",
       "      <td>-175.332995</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.568157</td>\n",
       "      <td>-58.444332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.957504</td>\n",
       "      <td>2020.312858</td>\n",
       "      <td>-34.568157</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3415.739916</td>\n",
       "      <td>-58.444332</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1615.995696</td>\n",
       "      <td>1615.995696</td>\n",
       "      <td>2321.428571</td>\n",
       "      <td>2699.889531</td>\n",
       "      <td>-0.696121</td>\n",
       "      <td>0.696121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.588891</td>\n",
       "      <td>-58.407601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30625.0</td>\n",
       "      <td>28525.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>-6053.055898</td>\n",
       "      <td>-10221.330164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>26569.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>-5637.989208</td>\n",
       "      <td>-9520.438952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-172.944454</td>\n",
       "      <td>-292.038005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.588891</td>\n",
       "      <td>-58.407601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1196.391370</td>\n",
       "      <td>2020.254133</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.588891</td>\n",
       "      <td>3411.447847</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.407601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-840.403359</td>\n",
       "      <td>840.403359</td>\n",
       "      <td>1210.916625</td>\n",
       "      <td>2876.919182</td>\n",
       "      <td>-0.694022</td>\n",
       "      <td>0.694022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.587443</td>\n",
       "      <td>-58.397176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1314.322830</td>\n",
       "      <td>-2219.092682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1314.322830</td>\n",
       "      <td>-2219.092682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.587443</td>\n",
       "      <td>-58.397176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.587443</td>\n",
       "      <td>-58.397176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.587443</td>\n",
       "      <td>-58.397176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.587443</td>\n",
       "      <td>-58.397176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.291206</td>\n",
       "      <td>2019.808985</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.587443</td>\n",
       "      <td>3410.230148</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.397176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1117.202008</td>\n",
       "      <td>1117.202008</td>\n",
       "      <td>1647.058824</td>\n",
       "      <td>3287.557609</td>\n",
       "      <td>-0.678301</td>\n",
       "      <td>0.678301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2    3    4    5    6    7    8    9   10   11   12  \\\n",
       "1302  1.0   40.0   36.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1300  1.0   99.0   99.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1305  1.0  360.0  360.0  7.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1294  1.0   35.0   32.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "1297  1.0   56.0   53.0  2.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2092  1.0   33.0   33.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1304  1.0   44.0   44.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2329  1.0  254.0  223.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1299  1.0  250.0  240.0  5.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1683  1.0   83.0   83.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   1.0   44.0   40.0  2.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  0.0   \n",
       "482   1.0   60.0   58.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "967   1.0   35.0   35.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "679   1.0   59.0   48.0  2.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "745   1.0   95.0   59.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "1082  1.0  118.0  118.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2175  1.0   81.0   76.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "117   1.0   81.0   70.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "534   1.0  175.0  163.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "26    1.0   38.0   38.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0   \n",
       "\n",
       "       13         14         15   16   17        18        19      20     21  \\\n",
       "1302  0.0 -34.563127 -58.462991  0.0  0.0    1600.0    1440.0    40.0    0.0   \n",
       "1300  0.0 -34.587337 -58.415642  1.0  0.0    9801.0    9801.0   396.0    0.0   \n",
       "1305  1.0 -34.576666 -58.402930  1.0  0.0  129600.0  129600.0  2520.0    0.0   \n",
       "1294  0.0 -34.555819 -58.448435  0.0  0.0    1225.0    1120.0    35.0    0.0   \n",
       "1297  1.0 -34.577675 -58.424355  1.0  0.0    3136.0    2968.0   112.0   56.0   \n",
       "2092  0.0 -34.567402 -58.449891  0.0  0.0    1089.0    1089.0    66.0    0.0   \n",
       "1304  0.0 -34.567102 -58.456020  0.0  0.0    1936.0    1936.0    88.0    0.0   \n",
       "2329  1.0 -34.565125 -58.438056  1.0  0.0   64516.0   56642.0  1270.0    0.0   \n",
       "1299  1.0 -34.559471 -58.455992  0.0  0.0   62500.0   60000.0  1250.0  250.0   \n",
       "1683  0.0 -34.574151 -58.420150  1.0  0.0    6889.0    6889.0   332.0    0.0   \n",
       "317   0.0 -34.559521 -58.445115  0.0  0.0    1936.0    1760.0    88.0   44.0   \n",
       "482   1.0 -34.583276 -58.426027  1.0  0.0    3600.0    3480.0   180.0    0.0   \n",
       "967   0.0 -34.591393 -58.396558  0.0  1.0    1225.0    1225.0    70.0    0.0   \n",
       "679   0.0 -34.586045 -58.440394  1.0  0.0    3481.0    2832.0   118.0   59.0   \n",
       "745   0.0 -34.556222 -58.458679  0.0  0.0    9025.0    5605.0   285.0    0.0   \n",
       "1082  1.0 -34.594006 -58.399810  0.0  1.0   13924.0   13924.0   472.0    0.0   \n",
       "2175  0.0 -34.565955 -58.452589  0.0  0.0    6561.0    6156.0   243.0    0.0   \n",
       "117   0.0 -34.568157 -58.444332  1.0  0.0    6561.0    5670.0   243.0    0.0   \n",
       "534   1.0 -34.588891 -58.407601  0.0  1.0   30625.0   28525.0   875.0    0.0   \n",
       "26    0.0 -34.587443 -58.397176  0.0  1.0    1444.0    1444.0    38.0    0.0   \n",
       "\n",
       "        22     23    24    25    26    27   28     29     30            31  \\\n",
       "1302   0.0    0.0   0.0  40.0   0.0   0.0  0.0    0.0    0.0  -1382.525068   \n",
       "1300   0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0    0.0  -3424.146412   \n",
       "1305   0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0  360.0 -12447.599688   \n",
       "1294   0.0   35.0   0.0   0.0   0.0  35.0  0.0    0.0    0.0  -1209.453676   \n",
       "1297   0.0   56.0   0.0  56.0   0.0   0.0  0.0    0.0   56.0  -1936.349778   \n",
       "2092   0.0    0.0   0.0   0.0   0.0   0.0  0.0   33.0    0.0  -1140.724253   \n",
       "1304   0.0    0.0   0.0   0.0   0.0   0.0  0.0   44.0    0.0  -1520.952506   \n",
       "2329   0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0  254.0  -8779.541627   \n",
       "1299   0.0  250.0   0.0   0.0   0.0   0.0  0.0    0.0  250.0  -8639.867750   \n",
       "1683   0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0    0.0  -2869.654566   \n",
       "317   44.0   44.0  44.0   0.0  44.0  44.0  0.0    0.0    0.0  -1520.618924   \n",
       "482    0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0   60.0  -2074.996536   \n",
       "967    0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0    0.0  -1210.698758   \n",
       "679    0.0    0.0   0.0  59.0   0.0  59.0  0.0    0.0    0.0  -2040.576655   \n",
       "745    0.0    0.0   0.0   0.0   0.0   0.0  0.0   95.0    0.0  -3282.841058   \n",
       "1082   0.0    0.0   0.0   0.0   0.0   0.0  0.0  118.0  118.0  -4082.092767   \n",
       "2175   0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0    0.0  -2799.842363   \n",
       "117    0.0    0.0   0.0   0.0   0.0  81.0  0.0    0.0    0.0  -2800.020747   \n",
       "534    0.0    0.0   0.0   0.0   0.0   0.0  0.0    0.0  175.0  -6053.055898   \n",
       "26     0.0    0.0  38.0   0.0  38.0  38.0  0.0    0.0    0.0  -1314.322830   \n",
       "\n",
       "                32     33     34        35      36     37    38     39    40  \\\n",
       "1302  -2338.519628    0.0    0.0    1296.0    36.0    0.0   0.0    0.0   0.0   \n",
       "1300  -5783.148538   99.0    0.0    9801.0   396.0    0.0   0.0    0.0   0.0   \n",
       "1305 -21025.054620  360.0    0.0  129600.0  2520.0    0.0   0.0    0.0   0.0   \n",
       "1294  -2045.695218    0.0    0.0    1024.0    32.0    0.0   0.0   32.0   0.0   \n",
       "1297  -3271.763880   56.0    0.0    2809.0   106.0   53.0   0.0   53.0   0.0   \n",
       "2092  -1928.846396    0.0    0.0    1089.0    66.0    0.0   0.0    0.0   0.0   \n",
       "1304  -2572.064871    0.0    0.0    1936.0    88.0    0.0   0.0    0.0   0.0   \n",
       "2329 -14843.266347  254.0    0.0   49729.0  1115.0    0.0   0.0    0.0   0.0   \n",
       "1299 -14613.998100    0.0    0.0   57600.0  1200.0  240.0   0.0  240.0   0.0   \n",
       "1683  -4848.872409   83.0    0.0    6889.0   332.0    0.0   0.0    0.0   0.0   \n",
       "317   -2571.585072    0.0    0.0    1600.0    80.0   40.0  40.0   40.0  40.0   \n",
       "482   -3505.561620   60.0    0.0    3364.0   174.0    0.0   0.0    0.0   0.0   \n",
       "967   -2043.879524    0.0   35.0    1225.0    70.0    0.0   0.0    0.0   0.0   \n",
       "679   -3447.983246   59.0    0.0    2304.0    96.0   48.0   0.0    0.0   0.0   \n",
       "745   -5553.574507    0.0    0.0    3481.0   177.0    0.0   0.0    0.0   0.0   \n",
       "1082  -6891.177568    0.0  118.0   13924.0   472.0    0.0   0.0    0.0   0.0   \n",
       "2175  -4734.659677    0.0    0.0    5776.0   228.0    0.0   0.0    0.0   0.0   \n",
       "117   -4733.990873   81.0    0.0    4900.0   210.0    0.0   0.0    0.0   0.0   \n",
       "534  -10221.330164    0.0  175.0   26569.0   815.0    0.0   0.0    0.0   0.0   \n",
       "26    -2219.092682    0.0   38.0    1444.0    38.0    0.0   0.0    0.0  38.0   \n",
       "\n",
       "        41    42    43   44     45     46            47            48     49  \\\n",
       "1302  36.0   0.0   0.0  0.0    0.0    0.0  -1244.272561  -2104.667665    0.0   \n",
       "1300   0.0   0.0   0.0  0.0    0.0    0.0  -3424.146412  -5783.148538   99.0   \n",
       "1305   0.0   0.0   0.0  0.0    0.0  360.0 -12447.599688 -21025.054620  360.0   \n",
       "1294   0.0   0.0  32.0  0.0    0.0    0.0  -1105.786218  -1870.349914    0.0   \n",
       "1297  53.0   0.0   0.0  0.0    0.0   53.0  -1832.616754  -3096.490815   53.0   \n",
       "2092   0.0   0.0   0.0  0.0   33.0    0.0  -1140.724253  -1928.846396    0.0   \n",
       "1304   0.0   0.0   0.0  0.0   44.0    0.0  -1520.952506  -2572.064871    0.0   \n",
       "2329   0.0   0.0   0.0  0.0    0.0  223.0  -7708.022767 -13031.686596  223.0   \n",
       "1299   0.0   0.0   0.0  0.0    0.0  240.0  -8294.273040 -14029.438176    0.0   \n",
       "1683   0.0   0.0   0.0  0.0    0.0    0.0  -2869.654566  -4848.872409   83.0   \n",
       "317    0.0  40.0  40.0  0.0    0.0    0.0  -1382.380840  -2337.804611    0.0   \n",
       "482    0.0   0.0   0.0  0.0    0.0   58.0  -2005.829985  -3388.709566   58.0   \n",
       "967    0.0   0.0   0.0  0.0    0.0    0.0  -1210.698758  -2043.879524    0.0   \n",
       "679   48.0   0.0  48.0  0.0    0.0    0.0  -1660.130160  -2805.138912   48.0   \n",
       "745    0.0   0.0   0.0  0.0   59.0    0.0  -2038.817078  -3449.062062    0.0   \n",
       "1082   0.0   0.0   0.0  0.0  118.0  118.0  -4082.092767  -6891.177568    0.0   \n",
       "2175   0.0   0.0   0.0  0.0    0.0    0.0  -2627.012588  -4442.396734    0.0   \n",
       "117    0.0   0.0  70.0  0.0    0.0    0.0  -2419.771016  -4091.103224   70.0   \n",
       "534    0.0   0.0   0.0  0.0    0.0  163.0  -5637.989208  -9520.438952    0.0   \n",
       "26     0.0  38.0  38.0  0.0    0.0    0.0  -1314.322830  -2219.092682    0.0   \n",
       "\n",
       "         50    51   52   53   54   55   56   57   58   59   60   61  \\\n",
       "1302    0.0   1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1300    0.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1305    0.0  49.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  7.0   \n",
       "1294    0.0   1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1297    0.0   4.0  2.0  0.0  2.0  0.0  2.0  0.0  0.0  0.0  0.0  2.0   \n",
       "2092    0.0   4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0   \n",
       "1304    0.0   4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0   \n",
       "2329    0.0  25.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0   \n",
       "1299    0.0  25.0  5.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0   \n",
       "1683    0.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317     0.0   4.0  2.0  2.0  2.0  2.0  0.0  2.0  2.0  0.0  0.0  0.0   \n",
       "482     0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0   \n",
       "967    35.0   4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "679     0.0   4.0  2.0  0.0  0.0  0.0  2.0  0.0  2.0  0.0  0.0  0.0   \n",
       "745     0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0   \n",
       "1082  118.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  4.0   \n",
       "2175    0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "117     0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0   \n",
       "534   163.0  25.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0   \n",
       "26     38.0   1.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "              62          63   64   65   66   67   68   69   70   71   72  \\\n",
       "1302  -34.563127  -58.462991  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1300 -138.349350 -233.662567  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1305 -242.036661 -408.820507  7.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1294  -34.555819  -58.448435  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1297  -69.155349 -116.848710  2.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "2092  -69.134803 -116.899782  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1304  -69.134205 -116.912040  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2329 -172.825623 -292.190282  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1299 -172.797355 -292.279962  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1683 -138.296606 -233.680598  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   -69.119042 -116.890231  0.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0   \n",
       "482  -103.749827 -175.278081  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "967   -69.182786 -116.793116  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "679   -69.172090 -116.880788  2.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0   \n",
       "745  -103.668665 -175.376037  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1082 -138.376026 -233.599240  0.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2175 -103.697865 -175.357766  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "117  -103.704472 -175.332995  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "534  -172.944454 -292.038005  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "26    -34.587443  -58.397176  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       73   74   75         76         77   78   79   80   81   82   83   84  \\\n",
       "1302  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1300  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1305  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1294  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1297  0.0  0.0  1.0 -34.577675 -58.424355  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2092  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1304  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2329  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1299  0.0  0.0  1.0 -34.559471 -58.455992  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1683  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "482   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "967   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "679   0.0  0.0  0.0 -34.586045 -58.440394  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "745   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1082  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2175  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "117   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "534   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "26    0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       85   86   87   88         89         90   91   92   93   94   95   96  \\\n",
       "1302  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1300  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1305  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1294  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1297  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "2092  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1304  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2329  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1299  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1683  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   1.0  0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  1.0  1.0  0.0  1.0   \n",
       "482   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "967   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "679   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "745   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1082  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2175  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "117   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "534   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "26    0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       97   98   99  100        101        102  103  104  105  106  107  108  \\\n",
       "1302  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1300  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1305  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1294  1.0  0.0  0.0  0.0 -34.555819 -58.448435  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1297  0.0  0.0  0.0  1.0 -34.577675 -58.424355  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2092  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1304  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2329  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1299  0.0  0.0  0.0  1.0 -34.559471 -58.455992  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1683  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   1.0  0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "482   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "967   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "679   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "745   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1082  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2175  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "117   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "534   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "26    0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "\n",
       "      109  110  111        112        113  114  115  116  117  118  119  120  \\\n",
       "1302  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1300  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1305  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1294  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1297  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2092  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1304  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2329  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1299  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1683  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "482   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "967   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "679   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "745   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1082  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2175  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "117   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "534   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "26    0.0  0.0  0.0 -34.587443 -58.397176  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      121        122        123  124  125  126  127  128  129  130        131  \\\n",
       "1302  0.0 -34.563127 -58.462991  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1300  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1305  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1294  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1297  1.0 -34.577675 -58.424355  1.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "2092  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1304  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "2329  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1299  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1683  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "317   0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0  0.0 -34.559521   \n",
       "482   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "967   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "679   0.0 -34.586045 -58.440394  1.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "745   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1082  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "2175  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "117   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "534   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "26    0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0  0.0 -34.587443   \n",
       "\n",
       "            132  133  134  135  136  137  138        139        140  141  142  \\\n",
       "1302  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1300  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1305  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1294  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0 -34.555819 -58.448435  0.0  0.0   \n",
       "1297  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "2092  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1304  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "2329  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1299  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1683  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "317  -58.445115  0.0  0.0  1.0  0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0   \n",
       "482   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "967   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "679   -0.000000  0.0  0.0  1.0  0.0  0.0  0.0 -34.586045 -58.440394  1.0  0.0   \n",
       "745   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1082  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "2175  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "117   -0.000000  0.0  0.0  1.0  0.0  0.0  0.0 -34.568157 -58.444332  1.0  0.0   \n",
       "534   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "26   -58.397176  0.0  1.0  1.0  0.0  0.0  0.0 -34.587443 -58.397176  0.0  1.0   \n",
       "\n",
       "      143  144  145  146  147  148  149  150  151        152        153  154  \\\n",
       "1302  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "1300  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "1305  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "1294  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "1297  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "2092  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  1.0  0.0 -34.567402 -58.449891  0.0   \n",
       "1304  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  1.0  0.0 -34.567102 -58.456020  0.0   \n",
       "2329  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "1299  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "1683  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "317   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "482   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "967   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "679   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "745   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  1.0  0.0 -34.556222 -58.458679  0.0   \n",
       "1082  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  1.0  1.0 -34.594006 -58.399810  0.0   \n",
       "2175  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "117   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "534   0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "26    0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "\n",
       "      155  156        157        158  159  160          161          162  \\\n",
       "1302  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.609727  2020.663755   \n",
       "1300  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.283915  2020.441518   \n",
       "1305  0.0  1.0 -34.576666 -58.402930  1.0  0.0  1195.545818  2019.378575   \n",
       "1294  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.104647  2019.733551   \n",
       "1297  0.0  1.0 -34.577675 -58.424355  1.0  0.0  1195.615581  2020.178336   \n",
       "2092  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.905253  2020.460849   \n",
       "1304  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.884568  2020.655222   \n",
       "2329  0.0  1.0 -34.565125 -58.438056  1.0  0.0  1194.747833  2019.918699   \n",
       "1299  0.0  1.0 -34.559471 -58.455992  0.0  0.0  1194.357036  2020.208174   \n",
       "1683  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1195.371945  2019.827094   \n",
       "317   0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.360491  2019.835188   \n",
       "482   0.0  1.0 -34.583276 -58.426027  1.0  0.0  1196.002951  2020.563394   \n",
       "967   0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.564475  2020.018286   \n",
       "679   0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.194509  2021.222097   \n",
       "745   0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.132456  2020.111070   \n",
       "1082  1.0  1.0 -34.594006 -58.399810  0.0  1.0  1196.745286  2020.283403   \n",
       "2175  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.805252  2020.469553   \n",
       "117   0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.957504  2020.312858   \n",
       "534   0.0  1.0 -34.588891 -58.407601  0.0  1.0  1196.391370  2020.254133   \n",
       "26    0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.291206  2019.808985   \n",
       "\n",
       "            163        164          165        166        167  168  169  170  \\\n",
       "1302  -0.000000  -0.000000  3417.921282  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "1300 -34.587337  -0.000000  3412.387207 -58.415642  -0.000000  1.0  0.0  0.0   \n",
       "1305 -34.576666  -0.000000  3410.902174 -58.402930  -0.000000  1.0  0.0  0.0   \n",
       "1294  -0.000000  -0.000000  3416.219531  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "1297 -34.577675  -0.000000  3413.405257 -58.424355  -0.000000  1.0  0.0  0.0   \n",
       "2092  -0.000000  -0.000000  3416.389735  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "1304  -0.000000  -0.000000  3417.106251  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "2329 -34.565125  -0.000000  3415.006446 -58.438056  -0.000000  1.0  0.0  0.0   \n",
       "1299  -0.000000  -0.000000  3417.103047  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "1683 -34.574151  -0.000000  3412.913868 -58.420150  -0.000000  1.0  0.0  0.0   \n",
       "317   -0.000000  -0.000000  3415.831499  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "482  -34.583276  -0.000000  3413.600631 -58.426027  -0.000000  1.0  0.0  0.0   \n",
       "967   -0.000000 -34.591393  3410.157966  -0.000000 -58.396558  0.0  0.0  1.0   \n",
       "679  -34.586045  -0.000000  3415.279651 -58.440394  -0.000000  1.0  0.0  0.0   \n",
       "745   -0.000000  -0.000000  3417.417152  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "1082  -0.000000 -34.594006  3410.537796  -0.000000 -58.399810  0.0  0.0  1.0   \n",
       "2175  -0.000000  -0.000000  3416.705114  -0.000000  -0.000000  0.0  0.0  0.0   \n",
       "117  -34.568157  -0.000000  3415.739916 -58.444332  -0.000000  1.0  0.0  0.0   \n",
       "534   -0.000000 -34.588891  3411.447847  -0.000000 -58.407601  0.0  0.0  1.0   \n",
       "26    -0.000000 -34.587443  3410.230148  -0.000000 -58.397176  0.0  0.0  1.0   \n",
       "\n",
       "            error    error_abs    precioxm2         pred  error_prop  \\\n",
       "1302 -1468.938917  1468.938917  1115.873226  2513.869238   -1.316403   \n",
       "1300 -1440.535512  1440.535512  1128.345789  2941.626515   -1.276679   \n",
       "1305 -1537.706625  1537.706625  1279.387576  4497.665157   -1.201908   \n",
       "1294 -1419.044347  1419.044347  1202.374865  2507.486012   -1.180201   \n",
       "1297 -1510.741972  1510.741972  1284.581064  4463.560766   -1.176058   \n",
       "2092 -1385.151633  1385.151633  1196.319018  2811.615911   -1.157845   \n",
       "1304 -1380.158719  1380.158719  1222.457419  2747.961852   -1.129004   \n",
       "2329 -1490.326872  1490.326872  1470.588235  3117.912552   -1.013422   \n",
       "1299 -1280.803312  1280.803312  1268.500426  3702.024179   -1.009699   \n",
       "1683 -1651.300602  1651.300602  1645.569620  3221.127532   -1.003483   \n",
       "317  -2034.607507  2034.607507  2033.898305  4197.387357   -1.000349   \n",
       "482  -1022.821823  1022.821823  1187.500000  3116.410918   -0.861324   \n",
       "967  -1343.530720  1343.530720  1714.285714  3140.419881   -0.783726   \n",
       "679  -1115.772657  1115.772657  1500.000000  2800.408107   -0.743848   \n",
       "745  -1959.485982  1959.485982  2640.000000  2016.916110   -0.742230   \n",
       "1082 -1345.604114  1345.604114  1906.976744  2948.476072   -0.705622   \n",
       "2175  -857.573516   857.573516  1227.272727  2732.335020   -0.698764   \n",
       "117  -1615.995696  1615.995696  2321.428571  2699.889531   -0.696121   \n",
       "534   -840.403359   840.403359  1210.916625  2876.919182   -0.694022   \n",
       "26   -1117.202008  1117.202008  1647.058824  3287.557609   -0.678301   \n",
       "\n",
       "      error_prop_abs  \n",
       "1302        1.316403  \n",
       "1300        1.276679  \n",
       "1305        1.201908  \n",
       "1294        1.180201  \n",
       "1297        1.176058  \n",
       "2092        1.157845  \n",
       "1304        1.129004  \n",
       "2329        1.013422  \n",
       "1299        1.009699  \n",
       "1683        1.003483  \n",
       "317         1.000349  \n",
       "482         0.861324  \n",
       "967         0.783726  \n",
       "679         0.743848  \n",
       "745         0.742230  \n",
       "1082        0.705622  \n",
       "2175        0.698764  \n",
       "117         0.696121  \n",
       "534         0.694022  \n",
       "26          0.678301  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los mayores errores proporcionalmente se dan al sobrevaluar propiedades baratas\n",
    "\n",
    "data_e = pd.DataFrame(X_train)\n",
    "data_e['error'] = y_train - predictions\n",
    "data_e['error_abs'] = np.abs(y_train - predictions)\n",
    "data_e['precioxm2'] = y_train\n",
    "data_e['pred'] = predictions\n",
    "data_e['error_prop'] = data_e['error'] / data_e['precioxm2']\n",
    "data_e['error_prop_abs'] = data_e['error_abs'] / data_e['precioxm2']\n",
    "data_e.sort_values(by='error_prop_abs',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>error</th>\n",
       "      <th>error_abs</th>\n",
       "      <th>precioxm2</th>\n",
       "      <th>pred</th>\n",
       "      <th>error_prop</th>\n",
       "      <th>error_prop_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.582680</td>\n",
       "      <td>-58.434648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12321.0</td>\n",
       "      <td>8991.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3838.677524</td>\n",
       "      <td>-6486.245884</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6561.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2801.197112</td>\n",
       "      <td>-4733.206456</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.165361</td>\n",
       "      <td>-116.869295</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.582680</td>\n",
       "      <td>-58.434648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.961784</td>\n",
       "      <td>2020.826742</td>\n",
       "      <td>-34.582680</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3414.608040</td>\n",
       "      <td>-58.434648</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2551.377525</td>\n",
       "      <td>2551.377525</td>\n",
       "      <td>5245.901639</td>\n",
       "      <td>2361.338368</td>\n",
       "      <td>0.486356</td>\n",
       "      <td>0.486356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.588309</td>\n",
       "      <td>-58.411826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37249.0</td>\n",
       "      <td>30880.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-6675.543705</td>\n",
       "      <td>-11273.482432</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25600.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-5534.129497</td>\n",
       "      <td>-9345.892171</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-138.353237</td>\n",
       "      <td>-233.647304</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.588309</td>\n",
       "      <td>-58.411826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.588309</td>\n",
       "      <td>-58.411826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.351144</td>\n",
       "      <td>2020.366310</td>\n",
       "      <td>-34.588309</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3411.941425</td>\n",
       "      <td>-58.411826</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2530.188734</td>\n",
       "      <td>2530.188734</td>\n",
       "      <td>5043.859649</td>\n",
       "      <td>2528.482493</td>\n",
       "      <td>0.501637</td>\n",
       "      <td>0.501637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-2592.836220</td>\n",
       "      <td>-4381.747245</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4624.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-2350.838173</td>\n",
       "      <td>-3972.784169</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-69.142299</td>\n",
       "      <td>-116.846593</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.164385</td>\n",
       "      <td>2019.760527</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3413.281586</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2413.291646</td>\n",
       "      <td>2413.291646</td>\n",
       "      <td>5434.782609</td>\n",
       "      <td>5075.453823</td>\n",
       "      <td>0.444046</td>\n",
       "      <td>0.444046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.556865</td>\n",
       "      <td>-58.447706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12769.0</td>\n",
       "      <td>10622.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>-3904.925725</td>\n",
       "      <td>-6604.590828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8836.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-3248.345293</td>\n",
       "      <td>-5494.084406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-138.227459</td>\n",
       "      <td>-233.790826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.556865</td>\n",
       "      <td>-58.447706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.176906</td>\n",
       "      <td>2019.769491</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3416.134388</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2348.573648</td>\n",
       "      <td>2348.573648</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>2911.031712</td>\n",
       "      <td>0.469715</td>\n",
       "      <td>0.469715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-1383.121755</td>\n",
       "      <td>-2337.529408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-1175.653492</td>\n",
       "      <td>-1986.899996</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.641119</td>\n",
       "      <td>2020.679861</td>\n",
       "      <td>-34.578044</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3415.027332</td>\n",
       "      <td>-58.438235</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2258.503405</td>\n",
       "      <td>2258.503405</td>\n",
       "      <td>5267.857143</td>\n",
       "      <td>3536.424270</td>\n",
       "      <td>0.428733</td>\n",
       "      <td>0.428733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.595025</td>\n",
       "      <td>-58.390616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13689.0</td>\n",
       "      <td>13689.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4047.617878</td>\n",
       "      <td>-6831.702072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>13689.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4047.617878</td>\n",
       "      <td>-6831.702072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-138.380098</td>\n",
       "      <td>-233.562464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.815727</td>\n",
       "      <td>2020.024797</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.595025</td>\n",
       "      <td>3409.464037</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.390616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2215.181962</td>\n",
       "      <td>2215.181962</td>\n",
       "      <td>5384.615385</td>\n",
       "      <td>2885.683984</td>\n",
       "      <td>0.411391</td>\n",
       "      <td>0.411391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.594281</td>\n",
       "      <td>-58.398064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1487.554096</td>\n",
       "      <td>-2511.116756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1487.554096</td>\n",
       "      <td>-2511.116756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.188563</td>\n",
       "      <td>-116.796128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.594281</td>\n",
       "      <td>-58.398064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.764299</td>\n",
       "      <td>2020.239057</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.594281</td>\n",
       "      <td>3410.333891</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.398064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2206.464959</td>\n",
       "      <td>2206.464959</td>\n",
       "      <td>4972.222222</td>\n",
       "      <td>2916.215272</td>\n",
       "      <td>0.443758</td>\n",
       "      <td>0.443758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1520.618924</td>\n",
       "      <td>-2571.585072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1382.380840</td>\n",
       "      <td>-2337.804611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.119042</td>\n",
       "      <td>-116.890231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.559521</td>\n",
       "      <td>-58.445115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.360491</td>\n",
       "      <td>2019.835188</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3415.831499</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2034.607507</td>\n",
       "      <td>2034.607507</td>\n",
       "      <td>2033.898305</td>\n",
       "      <td>4197.387357</td>\n",
       "      <td>-1.000349</td>\n",
       "      <td>1.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.590224</td>\n",
       "      <td>-58.424096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1625.740513</td>\n",
       "      <td>-2745.932524</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2209.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1625.740513</td>\n",
       "      <td>-2745.932524</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.770671</td>\n",
       "      <td>-175.272289</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.590224</td>\n",
       "      <td>-58.424096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.483574</td>\n",
       "      <td>2020.902557</td>\n",
       "      <td>-34.590224</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3413.375022</td>\n",
       "      <td>-58.424096</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1984.824600</td>\n",
       "      <td>1984.824600</td>\n",
       "      <td>5333.333333</td>\n",
       "      <td>2663.939250</td>\n",
       "      <td>0.372155</td>\n",
       "      <td>0.372155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.585934</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2905.218448</td>\n",
       "      <td>-4905.937621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5329.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2524.773175</td>\n",
       "      <td>-4263.493409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-138.343736</td>\n",
       "      <td>-233.616077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.585934</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.585934</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.585934</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.585934</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.585934</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.186824</td>\n",
       "      <td>2019.957551</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.585934</td>\n",
       "      <td>3411.029470</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1963.087268</td>\n",
       "      <td>1963.087268</td>\n",
       "      <td>5111.111111</td>\n",
       "      <td>4582.911304</td>\n",
       "      <td>0.384082</td>\n",
       "      <td>0.384082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556222</td>\n",
       "      <td>-58.458679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9025.0</td>\n",
       "      <td>5605.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3282.841058</td>\n",
       "      <td>-5553.574507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2038.817078</td>\n",
       "      <td>-3449.062062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.668665</td>\n",
       "      <td>-175.376037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556222</td>\n",
       "      <td>-58.458679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.132456</td>\n",
       "      <td>2020.111070</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3417.417152</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1959.485982</td>\n",
       "      <td>1959.485982</td>\n",
       "      <td>2640.000000</td>\n",
       "      <td>2016.916110</td>\n",
       "      <td>-0.742230</td>\n",
       "      <td>0.742230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.588328</td>\n",
       "      <td>-58.389993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35721.0</td>\n",
       "      <td>35721.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6537.194068</td>\n",
       "      <td>-11035.708658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>35721.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6537.194068</td>\n",
       "      <td>-11035.708658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-138.353314</td>\n",
       "      <td>-233.559972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.352462</td>\n",
       "      <td>2019.612250</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.588328</td>\n",
       "      <td>3409.391271</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.389993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1952.368501</td>\n",
       "      <td>1952.368501</td>\n",
       "      <td>4776.119403</td>\n",
       "      <td>3129.815674</td>\n",
       "      <td>0.408777</td>\n",
       "      <td>0.408777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.594777</td>\n",
       "      <td>-58.393414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72900.0</td>\n",
       "      <td>71550.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>-9340.589898</td>\n",
       "      <td>-15766.221861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>70225.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-9167.616011</td>\n",
       "      <td>-15474.254789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-207.568664</td>\n",
       "      <td>-350.360486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.594777</td>\n",
       "      <td>-58.393414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1196.798623</td>\n",
       "      <td>2020.107169</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.594777</td>\n",
       "      <td>3409.790834</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.393414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1888.710150</td>\n",
       "      <td>1888.710150</td>\n",
       "      <td>4481.818182</td>\n",
       "      <td>2976.525450</td>\n",
       "      <td>0.421416</td>\n",
       "      <td>0.421416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.597618</td>\n",
       "      <td>-58.402749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9604.0</td>\n",
       "      <td>9016.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3390.566596</td>\n",
       "      <td>-5723.469449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8464.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3182.980886</td>\n",
       "      <td>-5373.052952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-138.390473</td>\n",
       "      <td>-233.610998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.597618</td>\n",
       "      <td>-58.402749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.995194</td>\n",
       "      <td>2020.596036</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.597618</td>\n",
       "      <td>3410.881146</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.402749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1841.469519</td>\n",
       "      <td>1841.469519</td>\n",
       "      <td>4700.000000</td>\n",
       "      <td>2434.765597</td>\n",
       "      <td>0.391802</td>\n",
       "      <td>0.391802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7744.0</td>\n",
       "      <td>7216.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-3043.529205</td>\n",
       "      <td>-5141.238722</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6724.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-2836.015850</td>\n",
       "      <td>-4790.699718</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-103.756677</td>\n",
       "      <td>-175.269502</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.160902</td>\n",
       "      <td>2020.597908</td>\n",
       "      <td>-34.585559</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3413.266476</td>\n",
       "      <td>-58.423167</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.063671</td>\n",
       "      <td>1827.063671</td>\n",
       "      <td>4972.727273</td>\n",
       "      <td>4608.252843</td>\n",
       "      <td>0.367417</td>\n",
       "      <td>0.367417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.577604</td>\n",
       "      <td>-58.412539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2040.078660</td>\n",
       "      <td>-3446.339801</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2040.078660</td>\n",
       "      <td>-3446.339801</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.732813</td>\n",
       "      <td>-175.237617</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.577604</td>\n",
       "      <td>-58.412539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.610726</td>\n",
       "      <td>2019.765666</td>\n",
       "      <td>-34.577604</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3412.024712</td>\n",
       "      <td>-58.412539</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1814.282412</td>\n",
       "      <td>1814.282412</td>\n",
       "      <td>4615.384615</td>\n",
       "      <td>4110.667904</td>\n",
       "      <td>0.393095</td>\n",
       "      <td>0.393095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.577678</td>\n",
       "      <td>-58.412645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1141.063382</td>\n",
       "      <td>-1927.617275</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1141.063382</td>\n",
       "      <td>-1927.617275</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.577678</td>\n",
       "      <td>-58.412645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.577678</td>\n",
       "      <td>-58.412645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.615833</td>\n",
       "      <td>2019.773634</td>\n",
       "      <td>-34.577678</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3412.037060</td>\n",
       "      <td>-58.412645</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1807.841969</td>\n",
       "      <td>1807.841969</td>\n",
       "      <td>5128.205128</td>\n",
       "      <td>3665.902962</td>\n",
       "      <td>0.352529</td>\n",
       "      <td>0.352529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1416.811854</td>\n",
       "      <td>-2396.937829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1416.811854</td>\n",
       "      <td>-2396.937829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.556387</td>\n",
       "      <td>-58.461898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1194.143861</td>\n",
       "      <td>2020.231964</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3417.793550</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1803.139400</td>\n",
       "      <td>1803.139400</td>\n",
       "      <td>5409.638554</td>\n",
       "      <td>2696.348833</td>\n",
       "      <td>0.333320</td>\n",
       "      <td>0.333320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.579830</td>\n",
       "      <td>-58.413793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13456.0</td>\n",
       "      <td>13456.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4011.260231</td>\n",
       "      <td>-6776.000036</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13456.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4011.260231</td>\n",
       "      <td>-6776.000036</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.739489</td>\n",
       "      <td>-175.241380</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.764613</td>\n",
       "      <td>2019.939021</td>\n",
       "      <td>-34.579830</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3412.171261</td>\n",
       "      <td>-58.413793</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1771.430990</td>\n",
       "      <td>1771.430990</td>\n",
       "      <td>5138.888889</td>\n",
       "      <td>3277.156253</td>\n",
       "      <td>0.344711</td>\n",
       "      <td>0.344711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.593990</td>\n",
       "      <td>-58.404168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1591.323540</td>\n",
       "      <td>-2686.591719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1452.947580</td>\n",
       "      <td>-2452.975048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-69.187980</td>\n",
       "      <td>-116.808336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.593990</td>\n",
       "      <td>-58.404168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.593990</td>\n",
       "      <td>-58.404168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.593990</td>\n",
       "      <td>-58.404168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1196.744144</td>\n",
       "      <td>2020.433197</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-34.593990</td>\n",
       "      <td>3411.046816</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-58.404168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1719.887380</td>\n",
       "      <td>1719.887380</td>\n",
       "      <td>2777.777778</td>\n",
       "      <td>3776.251699</td>\n",
       "      <td>-0.619159</td>\n",
       "      <td>0.619159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2    3    4    5    6    7    8    9   10   11   12  \\\n",
       "1420  1.0  111.0   81.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "1742  1.0  193.0  160.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "661   1.0   75.0   68.0  2.0  1.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0   \n",
       "1737  1.0  113.0   94.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "632   1.0   40.0   34.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0   \n",
       "200   1.0  117.0  117.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "722   1.0   43.0   43.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "317   1.0   44.0   40.0  2.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  0.0   \n",
       "472   1.0   47.0   47.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "352   1.0   84.0   73.0  4.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0   \n",
       "745   1.0   95.0   59.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "114   1.0  189.0  189.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1524  1.0  270.0  265.0  6.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1078  1.0   98.0   92.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "975   1.0   88.0   82.0  3.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0   \n",
       "2042  1.0   59.0   59.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1271  1.0   33.0   33.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "455   1.0   41.0   41.0  1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0   \n",
       "33    1.0  116.0  116.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "743   1.0   46.0   42.0  2.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       13         14         15   16   17       18       19      20    21  \\\n",
       "1420  0.0 -34.582680 -58.434648  1.0  0.0  12321.0   8991.0   222.0   0.0   \n",
       "1742  1.0 -34.588309 -58.411826  1.0  0.0  37249.0  30880.0   772.0   0.0   \n",
       "661   1.0 -34.571150 -58.423297  1.0  0.0   5625.0   5100.0   150.0  75.0   \n",
       "1737  1.0 -34.556865 -58.447706  0.0  0.0  12769.0  10622.0   452.0   0.0   \n",
       "632   1.0 -34.578044 -58.438235  1.0  0.0   1600.0   1360.0    40.0  40.0   \n",
       "200   0.0 -34.595025 -58.390616  0.0  1.0  13689.0  13689.0   468.0   0.0   \n",
       "722   0.0 -34.594281 -58.398064  0.0  1.0   1849.0   1849.0    86.0   0.0   \n",
       "317   0.0 -34.559521 -58.445115  0.0  0.0   1936.0   1760.0    88.0  44.0   \n",
       "472   0.0 -34.590224 -58.424096  1.0  0.0   2209.0   2209.0   141.0   0.0   \n",
       "352   0.0 -34.585934 -58.404019  0.0  1.0   7056.0   6132.0   336.0  84.0   \n",
       "745   0.0 -34.556222 -58.458679  0.0  0.0   9025.0   5605.0   285.0   0.0   \n",
       "114   0.0 -34.588328 -58.389993  0.0  1.0  35721.0  35721.0   756.0   0.0   \n",
       "1524  1.0 -34.594777 -58.393414  0.0  1.0  72900.0  71550.0  1620.0   0.0   \n",
       "1078  0.0 -34.597618 -58.402749  0.0  1.0   9604.0   9016.0   392.0   0.0   \n",
       "975   1.0 -34.585559 -58.423167  1.0  0.0   7744.0   7216.0   264.0  88.0   \n",
       "2042  0.0 -34.577604 -58.412539  1.0  0.0   3481.0   3481.0   177.0   0.0   \n",
       "1271  0.0 -34.577678 -58.412645  1.0  0.0   1089.0   1089.0    33.0   0.0   \n",
       "455   0.0 -34.556387 -58.461898  0.0  0.0   1681.0   1681.0    41.0   0.0   \n",
       "33    0.0 -34.579830 -58.413793  1.0  0.0  13456.0  13456.0   348.0   0.0   \n",
       "743   0.0 -34.593990 -58.404168  0.0  1.0   2116.0   1932.0    92.0  46.0   \n",
       "\n",
       "        22    23    24    25    26     27    28     29     30           31  \\\n",
       "1420   0.0   0.0   0.0   0.0   0.0  111.0   0.0    0.0    0.0 -3838.677524   \n",
       "1742   0.0   0.0   0.0   0.0   0.0    0.0   0.0  193.0  193.0 -6675.543705   \n",
       "661    0.0  75.0  75.0   0.0   0.0   75.0  75.0   75.0   75.0 -2592.836220   \n",
       "1737   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0  113.0 -3904.925725   \n",
       "632   40.0   0.0  40.0   0.0   0.0   40.0   0.0   40.0   40.0 -1383.121755   \n",
       "200    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0 -4047.617878   \n",
       "722    0.0   0.0   0.0   0.0   0.0    0.0   0.0   43.0    0.0 -1487.554096   \n",
       "317   44.0  44.0  44.0   0.0  44.0   44.0   0.0    0.0    0.0 -1520.618924   \n",
       "472    0.0   0.0   0.0   0.0   0.0    0.0   0.0   47.0    0.0 -1625.740513   \n",
       "352   84.0  84.0  84.0   0.0  84.0    0.0   0.0    0.0    0.0 -2905.218448   \n",
       "745    0.0   0.0   0.0   0.0   0.0    0.0   0.0   95.0    0.0 -3282.841058   \n",
       "114    0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0 -6537.194068   \n",
       "1524   0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0  270.0 -9340.589898   \n",
       "1078   0.0   0.0   0.0   0.0   0.0    0.0   0.0   98.0    0.0 -3390.566596   \n",
       "975   88.0  88.0  88.0  88.0   0.0   88.0  88.0   88.0   88.0 -3043.529205   \n",
       "2042   0.0   0.0   0.0   0.0   0.0    0.0  59.0    0.0    0.0 -2040.078660   \n",
       "1271  33.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0 -1141.063382   \n",
       "455   41.0  41.0  41.0   0.0  41.0   41.0  41.0   41.0    0.0 -1416.811854   \n",
       "33     0.0   0.0   0.0   0.0   0.0    0.0   0.0    0.0    0.0 -4011.260231   \n",
       "743    0.0  46.0  46.0   0.0   0.0    0.0   0.0    0.0    0.0 -1591.323540   \n",
       "\n",
       "                32     33     34       35      36    37    38    39    40  \\\n",
       "1420  -6486.245884  111.0    0.0   6561.0   162.0   0.0   0.0   0.0   0.0   \n",
       "1742 -11273.482432  193.0    0.0  25600.0   640.0   0.0   0.0   0.0   0.0   \n",
       "661   -4381.747245   75.0    0.0   4624.0   136.0  68.0   0.0  68.0  68.0   \n",
       "1737  -6604.590828    0.0    0.0   8836.0   376.0   0.0   0.0   0.0   0.0   \n",
       "632   -2337.529408   40.0    0.0   1156.0    34.0  34.0  34.0   0.0  34.0   \n",
       "200   -6831.702072    0.0  117.0  13689.0   468.0   0.0   0.0   0.0   0.0   \n",
       "722   -2511.116756    0.0   43.0   1849.0    86.0   0.0   0.0   0.0   0.0   \n",
       "317   -2571.585072    0.0    0.0   1600.0    80.0  40.0  40.0  40.0  40.0   \n",
       "472   -2745.932524   47.0    0.0   2209.0   141.0   0.0   0.0   0.0   0.0   \n",
       "352   -4905.937621    0.0   84.0   5329.0   292.0  73.0  73.0  73.0  73.0   \n",
       "745   -5553.574507    0.0    0.0   3481.0   177.0   0.0   0.0   0.0   0.0   \n",
       "114  -11035.708658    0.0  189.0  35721.0   756.0   0.0   0.0   0.0   0.0   \n",
       "1524 -15766.221861    0.0  270.0  70225.0  1590.0   0.0   0.0   0.0   0.0   \n",
       "1078  -5723.469449    0.0   98.0   8464.0   368.0   0.0   0.0   0.0   0.0   \n",
       "975   -5141.238722   88.0    0.0   6724.0   246.0  82.0  82.0  82.0  82.0   \n",
       "2042  -3446.339801   59.0    0.0   3481.0   177.0   0.0   0.0   0.0   0.0   \n",
       "1271  -1927.617275   33.0    0.0   1089.0    33.0   0.0  33.0   0.0   0.0   \n",
       "455   -2396.937829    0.0    0.0   1681.0    41.0   0.0  41.0  41.0  41.0   \n",
       "33    -6776.000036  116.0    0.0  13456.0   348.0   0.0   0.0   0.0   0.0   \n",
       "743   -2686.591719    0.0   46.0   1764.0    84.0  42.0   0.0  42.0  42.0   \n",
       "\n",
       "        41    42    43    44     45     46           47            48     49  \\\n",
       "1420   0.0   0.0  81.0   0.0    0.0    0.0 -2801.197112  -4733.206456   81.0   \n",
       "1742   0.0   0.0   0.0   0.0  160.0  160.0 -5534.129497  -9345.892171  160.0   \n",
       "661    0.0   0.0  68.0  68.0   68.0   68.0 -2350.838173  -3972.784169   68.0   \n",
       "1737   0.0   0.0   0.0   0.0    0.0   94.0 -3248.345293  -5494.084406    0.0   \n",
       "632    0.0   0.0  34.0   0.0   34.0   34.0 -1175.653492  -1986.899996   34.0   \n",
       "200    0.0   0.0   0.0   0.0    0.0    0.0 -4047.617878  -6831.702072    0.0   \n",
       "722    0.0   0.0   0.0   0.0   43.0    0.0 -1487.554096  -2511.116756    0.0   \n",
       "317    0.0  40.0  40.0   0.0    0.0    0.0 -1382.380840  -2337.804611    0.0   \n",
       "472    0.0   0.0   0.0   0.0   47.0    0.0 -1625.740513  -2745.932524   47.0   \n",
       "352    0.0  73.0   0.0   0.0    0.0    0.0 -2524.773175  -4263.493409    0.0   \n",
       "745    0.0   0.0   0.0   0.0   59.0    0.0 -2038.817078  -3449.062062    0.0   \n",
       "114    0.0   0.0   0.0   0.0    0.0    0.0 -6537.194068 -11035.708658    0.0   \n",
       "1524   0.0   0.0   0.0   0.0    0.0  265.0 -9167.616011 -15474.254789    0.0   \n",
       "1078   0.0   0.0   0.0   0.0   92.0    0.0 -3182.980886  -5373.052952    0.0   \n",
       "975   82.0   0.0  82.0  82.0   82.0   82.0 -2836.015850  -4790.699718   82.0   \n",
       "2042   0.0   0.0   0.0  59.0    0.0    0.0 -2040.078660  -3446.339801   59.0   \n",
       "1271   0.0   0.0   0.0   0.0    0.0    0.0 -1141.063382  -1927.617275   33.0   \n",
       "455    0.0  41.0  41.0  41.0   41.0    0.0 -1416.811854  -2396.937829    0.0   \n",
       "33     0.0   0.0   0.0   0.0    0.0    0.0 -4011.260231  -6776.000036  116.0   \n",
       "743    0.0   0.0   0.0   0.0    0.0    0.0 -1452.947580  -2452.975048    0.0   \n",
       "\n",
       "         50    51   52   53   54   55   56   57   58   59   60   61  \\\n",
       "1420    0.0   4.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0   \n",
       "1742    0.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  4.0   \n",
       "661     0.0   4.0  2.0  0.0  2.0  2.0  0.0  0.0  2.0  2.0  2.0  2.0   \n",
       "1737    0.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0   \n",
       "632     0.0   1.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "200   117.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "722    43.0   4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0   \n",
       "317     0.0   4.0  2.0  2.0  2.0  2.0  0.0  2.0  2.0  0.0  0.0  0.0   \n",
       "472     0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0   \n",
       "352    73.0  16.0  4.0  4.0  4.0  4.0  0.0  4.0  0.0  0.0  0.0  0.0   \n",
       "745     0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0   \n",
       "114   189.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1524  265.0  36.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  6.0   \n",
       "1078   92.0  16.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0   \n",
       "975     0.0   9.0  3.0  3.0  3.0  3.0  3.0  0.0  3.0  3.0  3.0  3.0   \n",
       "2042    0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0   \n",
       "1271    0.0   1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "455     0.0   1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  0.0   \n",
       "33      0.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "743    42.0   4.0  2.0  0.0  2.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "              62          63   64   65   66   67   68   69   70   71   72  \\\n",
       "1420  -69.165361 -116.869295  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1742 -138.353237 -233.647304  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "661   -69.142299 -116.846593  2.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1737 -138.227459 -233.790826  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "632   -34.578044  -58.438235  1.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0   \n",
       "200  -138.380098 -233.562464  0.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "722   -69.188563 -116.796128  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   -69.119042 -116.890231  0.0  0.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0   \n",
       "472  -103.770671 -175.272289  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "352  -138.343736 -233.616077  0.0  4.0  1.0  1.0  1.0  1.0  0.0  1.0  0.0   \n",
       "745  -103.668665 -175.376037  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "114  -138.353314 -233.559972  0.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1524 -207.568664 -350.360486  0.0  6.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1078 -138.390473 -233.610998  0.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "975  -103.756677 -175.269502  3.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0   \n",
       "2042 -103.732813 -175.237617  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1271  -34.577678  -58.412645  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "455   -34.556387  -58.461898  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "33   -103.739489 -175.241380  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "743   -69.187980 -116.808336  0.0  2.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "       73   74   75         76         77   78   79   80   81   82   83   84  \\\n",
       "1420  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1742  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "661   1.0  1.0  1.0 -34.571150 -58.423297  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1737  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "632   0.0  1.0  1.0 -34.578044 -58.438235  1.0  0.0  1.0  0.0  1.0  0.0  0.0   \n",
       "200   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "722   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "472   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "352   0.0  0.0  0.0 -34.585934 -58.404019  0.0  1.0  1.0  1.0  1.0  0.0  1.0   \n",
       "745   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "114   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1524  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1078  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "975   1.0  1.0  1.0 -34.585559 -58.423167  1.0  0.0  1.0  1.0  1.0  1.0  0.0   \n",
       "2042  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1271  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "455   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "33    0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "743   0.0  0.0  0.0 -34.593990 -58.404168  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       85   86   87   88         89         90   91   92   93   94   95   96  \\\n",
       "1420  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1742  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "661   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "1737  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "632   1.0  0.0  1.0  1.0 -34.578044 -58.438235  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "200   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "722   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   1.0  0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  1.0  1.0  0.0  1.0   \n",
       "472   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "352   0.0  0.0  0.0  0.0 -34.585934 -58.404019  0.0  1.0  1.0  1.0  0.0  1.0   \n",
       "745   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "114   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1524  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1078  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "975   1.0  1.0  1.0  1.0 -34.585559 -58.423167  1.0  0.0  1.0  1.0  1.0  0.0   \n",
       "2042  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1271  0.0  0.0  0.0  0.0 -34.577678 -58.412645  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "455   1.0  1.0  1.0  0.0 -34.556387 -58.461898  0.0  0.0  1.0  1.0  0.0  1.0   \n",
       "33    0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "743   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "\n",
       "       97   98   99  100        101        102  103  104  105  106  107  108  \\\n",
       "1420  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1742  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "661   1.0  1.0  1.0  1.0 -34.571150 -58.423297  1.0  0.0  1.0  0.0  0.0  1.0   \n",
       "1737  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "632   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "200   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "722   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   1.0  0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "472   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "352   0.0  0.0  0.0  0.0 -34.585934 -58.404019  0.0  1.0  1.0  0.0  1.0  0.0   \n",
       "745   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "114   0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1524  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1078  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "975   1.0  1.0  1.0  1.0 -34.585559 -58.423167  1.0  0.0  1.0  1.0  0.0  1.0   \n",
       "2042  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1271  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "455   1.0  1.0  1.0  0.0 -34.556387 -58.461898  0.0  0.0  1.0  0.0  1.0  1.0   \n",
       "33    0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "743   0.0  0.0  0.0  0.0 -34.593990 -58.404168  0.0  1.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "      109  110  111        112        113  114  115  116  117  118  119  120  \\\n",
       "1420  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1742  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "661   1.0  1.0  1.0 -34.571150 -58.423297  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1737  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "632   0.0  1.0  1.0 -34.578044 -58.438235  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "200   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "722   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "317   0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "472   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "352   0.0  0.0  0.0 -34.585934 -58.404019  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "745   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "114   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1524  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1078  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "975   1.0  1.0  1.0 -34.585559 -58.423167  1.0  0.0  1.0  0.0  1.0  1.0  1.0   \n",
       "2042  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1271  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "455   1.0  1.0  0.0 -34.556387 -58.461898  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "33    0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "743   0.0  0.0  0.0 -34.593990 -58.404168  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      121        122        123  124  125  126  127  128  129  130        131  \\\n",
       "1420  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1742  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "661   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1737  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "632   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "200   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "722   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "317   0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0  0.0 -34.559521   \n",
       "472   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "352   0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0  0.0 -34.585934   \n",
       "745   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "114   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1524  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1078  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "975   1.0 -34.585559 -58.423167  1.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "2042  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1271  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "455   0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  1.0  0.0 -34.556387   \n",
       "33    0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "743   0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "\n",
       "            132  133  134  135  136  137  138        139        140  141  142  \\\n",
       "1420  -0.000000  0.0  0.0  1.0  0.0  0.0  0.0 -34.582680 -58.434648  1.0  0.0   \n",
       "1742  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "661   -0.000000  0.0  0.0  1.0  1.0  1.0  1.0 -34.571150 -58.423297  1.0  0.0   \n",
       "1737  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "632   -0.000000  0.0  0.0  1.0  0.0  1.0  1.0 -34.578044 -58.438235  1.0  0.0   \n",
       "200   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "722   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "317  -58.445115  0.0  0.0  1.0  0.0  0.0  0.0 -34.559521 -58.445115  0.0  0.0   \n",
       "472   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "352  -58.404019  0.0  1.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "745   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "114   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1524  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1078  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "975   -0.000000  0.0  0.0  1.0  1.0  1.0  1.0 -34.585559 -58.423167  1.0  0.0   \n",
       "2042  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1271  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "455  -58.461898  0.0  0.0  1.0  1.0  1.0  0.0 -34.556387 -58.461898  0.0  0.0   \n",
       "33    -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "743   -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "\n",
       "      143  144  145        146        147  148  149  150  151        152  \\\n",
       "1420  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1742  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0 -34.588309   \n",
       "661   1.0  1.0  1.0 -34.571150 -58.423297  1.0  0.0  1.0  1.0 -34.571150   \n",
       "1737  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "632   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0 -34.578044   \n",
       "200   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "722   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0 -34.594281   \n",
       "317   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "472   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0 -34.590224   \n",
       "352   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "745   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0 -34.556222   \n",
       "114   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1524  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "1078  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  0.0 -34.597618   \n",
       "975   1.0  1.0  1.0 -34.585559 -58.423167  1.0  0.0  1.0  1.0 -34.585559   \n",
       "2042  1.0  0.0  0.0 -34.577604 -58.412539  1.0  0.0  0.0  0.0  -0.000000   \n",
       "1271  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "455   1.0  1.0  0.0 -34.556387 -58.461898  0.0  0.0  1.0  0.0 -34.556387   \n",
       "33    0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "743   0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000   \n",
       "\n",
       "            153  154  155  156        157        158  159  160          161  \\\n",
       "1420  -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1195.961784   \n",
       "1742 -58.411826  1.0  0.0  1.0 -34.588309 -58.411826  1.0  0.0  1196.351144   \n",
       "661  -58.423297  1.0  0.0  1.0 -34.571150 -58.423297  1.0  0.0  1195.164385   \n",
       "1737  -0.000000  0.0  0.0  1.0 -34.556865 -58.447706  0.0  0.0  1194.176906   \n",
       "632  -58.438235  1.0  0.0  1.0 -34.578044 -58.438235  1.0  0.0  1195.641119   \n",
       "200   -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.815727   \n",
       "722  -58.398064  0.0  1.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.764299   \n",
       "317   -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.360491   \n",
       "472  -58.424096  1.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.483574   \n",
       "352   -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.186824   \n",
       "745  -58.458679  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.132456   \n",
       "114   -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.352462   \n",
       "1524  -0.000000  0.0  0.0  1.0 -34.594777 -58.393414  0.0  1.0  1196.798623   \n",
       "1078 -58.402749  0.0  1.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.995194   \n",
       "975  -58.423167  1.0  0.0  1.0 -34.585559 -58.423167  1.0  0.0  1196.160902   \n",
       "2042  -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1195.610726   \n",
       "1271  -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1195.615833   \n",
       "455  -58.461898  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1194.143861   \n",
       "33    -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1195.764613   \n",
       "743   -0.000000  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  1196.744144   \n",
       "\n",
       "              162        163        164          165        166        167  \\\n",
       "1420  2020.826742 -34.582680  -0.000000  3414.608040 -58.434648  -0.000000   \n",
       "1742  2020.366310 -34.588309  -0.000000  3411.941425 -58.411826  -0.000000   \n",
       "661   2019.760527 -34.571150  -0.000000  3413.281586 -58.423297  -0.000000   \n",
       "1737  2019.769491  -0.000000  -0.000000  3416.134388  -0.000000  -0.000000   \n",
       "632   2020.679861 -34.578044  -0.000000  3415.027332 -58.438235  -0.000000   \n",
       "200   2020.024797  -0.000000 -34.595025  3409.464037  -0.000000 -58.390616   \n",
       "722   2020.239057  -0.000000 -34.594281  3410.333891  -0.000000 -58.398064   \n",
       "317   2019.835188  -0.000000  -0.000000  3415.831499  -0.000000  -0.000000   \n",
       "472   2020.902557 -34.590224  -0.000000  3413.375022 -58.424096  -0.000000   \n",
       "352   2019.957551  -0.000000 -34.585934  3411.029470  -0.000000 -58.404019   \n",
       "745   2020.111070  -0.000000  -0.000000  3417.417152  -0.000000  -0.000000   \n",
       "114   2019.612250  -0.000000 -34.588328  3409.391271  -0.000000 -58.389993   \n",
       "1524  2020.107169  -0.000000 -34.594777  3409.790834  -0.000000 -58.393414   \n",
       "1078  2020.596036  -0.000000 -34.597618  3410.881146  -0.000000 -58.402749   \n",
       "975   2020.597908 -34.585559  -0.000000  3413.266476 -58.423167  -0.000000   \n",
       "2042  2019.765666 -34.577604  -0.000000  3412.024712 -58.412539  -0.000000   \n",
       "1271  2019.773634 -34.577678  -0.000000  3412.037060 -58.412645  -0.000000   \n",
       "455   2020.231964  -0.000000  -0.000000  3417.793550  -0.000000  -0.000000   \n",
       "33    2019.939021 -34.579830  -0.000000  3412.171261 -58.413793  -0.000000   \n",
       "743   2020.433197  -0.000000 -34.593990  3411.046816  -0.000000 -58.404168   \n",
       "\n",
       "      168  169  170        error    error_abs    precioxm2         pred  \\\n",
       "1420  1.0  0.0  0.0  2551.377525  2551.377525  5245.901639  2361.338368   \n",
       "1742  1.0  0.0  0.0  2530.188734  2530.188734  5043.859649  2528.482493   \n",
       "661   1.0  0.0  0.0  2413.291646  2413.291646  5434.782609  5075.453823   \n",
       "1737  0.0  0.0  0.0  2348.573648  2348.573648  5000.000000  2911.031712   \n",
       "632   1.0  0.0  0.0  2258.503405  2258.503405  5267.857143  3536.424270   \n",
       "200   0.0  0.0  1.0  2215.181962  2215.181962  5384.615385  2885.683984   \n",
       "722   0.0  0.0  1.0  2206.464959  2206.464959  4972.222222  2916.215272   \n",
       "317   0.0  0.0  0.0 -2034.607507  2034.607507  2033.898305  4197.387357   \n",
       "472   1.0  0.0  0.0  1984.824600  1984.824600  5333.333333  2663.939250   \n",
       "352   0.0  0.0  1.0  1963.087268  1963.087268  5111.111111  4582.911304   \n",
       "745   0.0  0.0  0.0 -1959.485982  1959.485982  2640.000000  2016.916110   \n",
       "114   0.0  0.0  1.0  1952.368501  1952.368501  4776.119403  3129.815674   \n",
       "1524  0.0  0.0  1.0  1888.710150  1888.710150  4481.818182  2976.525450   \n",
       "1078  0.0  0.0  1.0  1841.469519  1841.469519  4700.000000  2434.765597   \n",
       "975   1.0  0.0  0.0  1827.063671  1827.063671  4972.727273  4608.252843   \n",
       "2042  1.0  0.0  0.0  1814.282412  1814.282412  4615.384615  4110.667904   \n",
       "1271  1.0  0.0  0.0  1807.841969  1807.841969  5128.205128  3665.902962   \n",
       "455   0.0  0.0  0.0  1803.139400  1803.139400  5409.638554  2696.348833   \n",
       "33    1.0  0.0  0.0  1771.430990  1771.430990  5138.888889  3277.156253   \n",
       "743   0.0  0.0  1.0 -1719.887380  1719.887380  2777.777778  3776.251699   \n",
       "\n",
       "      error_prop  error_prop_abs  \n",
       "1420    0.486356        0.486356  \n",
       "1742    0.501637        0.501637  \n",
       "661     0.444046        0.444046  \n",
       "1737    0.469715        0.469715  \n",
       "632     0.428733        0.428733  \n",
       "200     0.411391        0.411391  \n",
       "722     0.443758        0.443758  \n",
       "317    -1.000349        1.000349  \n",
       "472     0.372155        0.372155  \n",
       "352     0.384082        0.384082  \n",
       "745    -0.742230        0.742230  \n",
       "114     0.408777        0.408777  \n",
       "1524    0.421416        0.421416  \n",
       "1078    0.391802        0.391802  \n",
       "975     0.367417        0.367417  \n",
       "2042    0.393095        0.393095  \n",
       "1271    0.352529        0.352529  \n",
       "455     0.333320        0.333320  \n",
       "33      0.344711        0.344711  \n",
       "743    -0.619159        0.619159  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e.sort_values(by='error_abs',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>error</th>\n",
       "      <th>error_abs</th>\n",
       "      <th>precioxm2</th>\n",
       "      <th>pred</th>\n",
       "      <th>error_prop</th>\n",
       "      <th>error_prop_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2399.0</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>2399.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "      <td>1524.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>102.491038</td>\n",
       "      <td>90.738641</td>\n",
       "      <td>3.011672</td>\n",
       "      <td>0.223426</td>\n",
       "      <td>0.147145</td>\n",
       "      <td>0.134223</td>\n",
       "      <td>0.132138</td>\n",
       "      <td>0.155065</td>\n",
       "      <td>0.117549</td>\n",
       "      <td>0.186328</td>\n",
       "      <td>0.104210</td>\n",
       "      <td>0.192163</td>\n",
       "      <td>0.409754</td>\n",
       "      <td>-34.579077</td>\n",
       "      <td>-58.424129</td>\n",
       "      <td>0.451855</td>\n",
       "      <td>0.321384</td>\n",
       "      <td>17232.759483</td>\n",
       "      <td>15027.423093</td>\n",
       "      <td>411.901626</td>\n",
       "      <td>22.246353</td>\n",
       "      <td>13.496040</td>\n",
       "      <td>15.132138</td>\n",
       "      <td>9.323468</td>\n",
       "      <td>14.364735</td>\n",
       "      <td>10.305127</td>\n",
       "      <td>20.187578</td>\n",
       "      <td>6.779491</td>\n",
       "      <td>14.102960</td>\n",
       "      <td>56.269696</td>\n",
       "      <td>-3544.049278</td>\n",
       "      <td>-5987.652729</td>\n",
       "      <td>44.937891</td>\n",
       "      <td>36.102126</td>\n",
       "      <td>13475.433931</td>\n",
       "      <td>364.163401</td>\n",
       "      <td>18.937474</td>\n",
       "      <td>11.430179</td>\n",
       "      <td>12.912047</td>\n",
       "      <td>8.029179</td>\n",
       "      <td>12.107962</td>\n",
       "      <td>8.698624</td>\n",
       "      <td>16.211338</td>\n",
       "      <td>5.783660</td>\n",
       "      <td>12.202168</td>\n",
       "      <td>49.566903</td>\n",
       "      <td>-3137.676340</td>\n",
       "      <td>-5301.019066</td>\n",
       "      <td>39.250104</td>\n",
       "      <td>32.691538</td>\n",
       "      <td>11.310129</td>\n",
       "      <td>0.608587</td>\n",
       "      <td>0.367653</td>\n",
       "      <td>0.404335</td>\n",
       "      <td>0.283035</td>\n",
       "      <td>0.400167</td>\n",
       "      <td>0.293456</td>\n",
       "      <td>0.515215</td>\n",
       "      <td>0.208837</td>\n",
       "      <td>0.461859</td>\n",
       "      <td>1.472280</td>\n",
       "      <td>-104.141198</td>\n",
       "      <td>-175.948647</td>\n",
       "      <td>1.330554</td>\n",
       "      <td>1.031263</td>\n",
       "      <td>0.223426</td>\n",
       "      <td>0.107962</td>\n",
       "      <td>0.117132</td>\n",
       "      <td>0.096707</td>\n",
       "      <td>0.122551</td>\n",
       "      <td>0.090454</td>\n",
       "      <td>0.113381</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.048770</td>\n",
       "      <td>0.138391</td>\n",
       "      <td>-7.725268</td>\n",
       "      <td>-13.054991</td>\n",
       "      <td>0.116715</td>\n",
       "      <td>0.044602</td>\n",
       "      <td>0.147145</td>\n",
       "      <td>0.073781</td>\n",
       "      <td>0.067111</td>\n",
       "      <td>0.073781</td>\n",
       "      <td>0.061276</td>\n",
       "      <td>0.073781</td>\n",
       "      <td>0.029596</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>-5.087788</td>\n",
       "      <td>-8.597554</td>\n",
       "      <td>0.072113</td>\n",
       "      <td>0.035431</td>\n",
       "      <td>0.134223</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.027095</td>\n",
       "      <td>0.027928</td>\n",
       "      <td>0.090871</td>\n",
       "      <td>-4.641206</td>\n",
       "      <td>-7.842005</td>\n",
       "      <td>0.067111</td>\n",
       "      <td>0.040434</td>\n",
       "      <td>0.132138</td>\n",
       "      <td>0.062109</td>\n",
       "      <td>0.061692</td>\n",
       "      <td>0.074614</td>\n",
       "      <td>0.027095</td>\n",
       "      <td>0.039183</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>-4.569180</td>\n",
       "      <td>-7.720440</td>\n",
       "      <td>0.061276</td>\n",
       "      <td>0.042101</td>\n",
       "      <td>0.155065</td>\n",
       "      <td>0.055857</td>\n",
       "      <td>0.085452</td>\n",
       "      <td>0.035431</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.090038</td>\n",
       "      <td>-5.361515</td>\n",
       "      <td>-9.060980</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>0.117549</td>\n",
       "      <td>0.070446</td>\n",
       "      <td>0.025844</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.060859</td>\n",
       "      <td>-4.064217</td>\n",
       "      <td>-6.868716</td>\n",
       "      <td>0.056273</td>\n",
       "      <td>0.021259</td>\n",
       "      <td>0.186328</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.105461</td>\n",
       "      <td>-6.442498</td>\n",
       "      <td>-10.887645</td>\n",
       "      <td>0.105877</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.104210</td>\n",
       "      <td>0.027928</td>\n",
       "      <td>0.055023</td>\n",
       "      <td>-3.603276</td>\n",
       "      <td>-6.089238</td>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.022509</td>\n",
       "      <td>0.192163</td>\n",
       "      <td>0.062943</td>\n",
       "      <td>-6.644489</td>\n",
       "      <td>-11.228074</td>\n",
       "      <td>0.082118</td>\n",
       "      <td>0.052939</td>\n",
       "      <td>0.409754</td>\n",
       "      <td>-14.168061</td>\n",
       "      <td>-23.940279</td>\n",
       "      <td>0.208420</td>\n",
       "      <td>0.103376</td>\n",
       "      <td>1195.712729</td>\n",
       "      <td>2020.252216</td>\n",
       "      <td>-15.624729</td>\n",
       "      <td>-11.117271</td>\n",
       "      <td>3413.379421</td>\n",
       "      <td>-26.399934</td>\n",
       "      <td>-18.768556</td>\n",
       "      <td>0.451855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321384</td>\n",
       "      <td>1.188667</td>\n",
       "      <td>422.659677</td>\n",
       "      <td>3145.918111</td>\n",
       "      <td>3120.518631</td>\n",
       "      <td>-0.033978</td>\n",
       "      <td>0.142134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>82.043601</td>\n",
       "      <td>72.416289</td>\n",
       "      <td>1.496963</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>0.354324</td>\n",
       "      <td>0.340962</td>\n",
       "      <td>0.338712</td>\n",
       "      <td>0.362042</td>\n",
       "      <td>0.322140</td>\n",
       "      <td>0.389452</td>\n",
       "      <td>0.305597</td>\n",
       "      <td>0.394083</td>\n",
       "      <td>0.491891</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.497780</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>38097.608965</td>\n",
       "      <td>32738.422317</td>\n",
       "      <td>571.739834</td>\n",
       "      <td>61.425238</td>\n",
       "      <td>48.927896</td>\n",
       "      <td>54.178100</td>\n",
       "      <td>33.540926</td>\n",
       "      <td>46.555902</td>\n",
       "      <td>42.643403</td>\n",
       "      <td>63.425866</td>\n",
       "      <td>25.282411</td>\n",
       "      <td>36.202468</td>\n",
       "      <td>93.130865</td>\n",
       "      <td>2836.876659</td>\n",
       "      <td>4792.707963</td>\n",
       "      <td>71.904666</td>\n",
       "      <td>71.460511</td>\n",
       "      <td>29337.144958</td>\n",
       "      <td>499.116961</td>\n",
       "      <td>52.200696</td>\n",
       "      <td>41.391084</td>\n",
       "      <td>46.762707</td>\n",
       "      <td>29.583514</td>\n",
       "      <td>39.237122</td>\n",
       "      <td>36.724892</td>\n",
       "      <td>50.778550</td>\n",
       "      <td>20.634561</td>\n",
       "      <td>30.261185</td>\n",
       "      <td>81.847936</td>\n",
       "      <td>2504.091043</td>\n",
       "      <td>4230.096894</td>\n",
       "      <td>62.821198</td>\n",
       "      <td>65.320087</td>\n",
       "      <td>10.426902</td>\n",
       "      <td>1.362776</td>\n",
       "      <td>1.077817</td>\n",
       "      <td>1.194196</td>\n",
       "      <td>0.859820</td>\n",
       "      <td>1.128492</td>\n",
       "      <td>0.962908</td>\n",
       "      <td>1.287198</td>\n",
       "      <td>0.715716</td>\n",
       "      <td>1.100129</td>\n",
       "      <td>2.036562</td>\n",
       "      <td>51.763971</td>\n",
       "      <td>87.444543</td>\n",
       "      <td>1.773316</td>\n",
       "      <td>1.728756</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>0.310397</td>\n",
       "      <td>0.321645</td>\n",
       "      <td>0.295620</td>\n",
       "      <td>0.327990</td>\n",
       "      <td>0.286891</td>\n",
       "      <td>0.317124</td>\n",
       "      <td>0.202752</td>\n",
       "      <td>0.215432</td>\n",
       "      <td>0.345382</td>\n",
       "      <td>14.405494</td>\n",
       "      <td>24.343957</td>\n",
       "      <td>0.321148</td>\n",
       "      <td>0.206471</td>\n",
       "      <td>0.354324</td>\n",
       "      <td>0.261468</td>\n",
       "      <td>0.250267</td>\n",
       "      <td>0.261468</td>\n",
       "      <td>0.239885</td>\n",
       "      <td>0.261468</td>\n",
       "      <td>0.169504</td>\n",
       "      <td>0.185950</td>\n",
       "      <td>0.273965</td>\n",
       "      <td>12.251382</td>\n",
       "      <td>20.702888</td>\n",
       "      <td>0.258729</td>\n",
       "      <td>0.184906</td>\n",
       "      <td>0.340962</td>\n",
       "      <td>0.250987</td>\n",
       "      <td>0.264168</td>\n",
       "      <td>0.224788</td>\n",
       "      <td>0.245148</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.164802</td>\n",
       "      <td>0.287486</td>\n",
       "      <td>11.789944</td>\n",
       "      <td>19.920855</td>\n",
       "      <td>0.250267</td>\n",
       "      <td>0.197015</td>\n",
       "      <td>0.338712</td>\n",
       "      <td>0.241404</td>\n",
       "      <td>0.240646</td>\n",
       "      <td>0.262823</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.194071</td>\n",
       "      <td>0.236809</td>\n",
       "      <td>11.712228</td>\n",
       "      <td>19.789890</td>\n",
       "      <td>0.239885</td>\n",
       "      <td>0.200861</td>\n",
       "      <td>0.362042</td>\n",
       "      <td>0.229692</td>\n",
       "      <td>0.279612</td>\n",
       "      <td>0.184906</td>\n",
       "      <td>0.196039</td>\n",
       "      <td>0.286295</td>\n",
       "      <td>12.517959</td>\n",
       "      <td>21.155395</td>\n",
       "      <td>0.273965</td>\n",
       "      <td>0.157452</td>\n",
       "      <td>0.322140</td>\n",
       "      <td>0.255951</td>\n",
       "      <td>0.158703</td>\n",
       "      <td>0.165992</td>\n",
       "      <td>0.239121</td>\n",
       "      <td>11.137901</td>\n",
       "      <td>18.823571</td>\n",
       "      <td>0.230497</td>\n",
       "      <td>0.144276</td>\n",
       "      <td>0.389452</td>\n",
       "      <td>0.182797</td>\n",
       "      <td>0.204622</td>\n",
       "      <td>0.307210</td>\n",
       "      <td>13.465765</td>\n",
       "      <td>22.756772</td>\n",
       "      <td>0.307745</td>\n",
       "      <td>0.165992</td>\n",
       "      <td>0.305597</td>\n",
       "      <td>0.164802</td>\n",
       "      <td>0.228073</td>\n",
       "      <td>10.566625</td>\n",
       "      <td>17.856722</td>\n",
       "      <td>0.224788</td>\n",
       "      <td>0.148364</td>\n",
       "      <td>0.394083</td>\n",
       "      <td>0.242911</td>\n",
       "      <td>13.626320</td>\n",
       "      <td>23.026199</td>\n",
       "      <td>0.274601</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.491891</td>\n",
       "      <td>17.008102</td>\n",
       "      <td>28.739199</td>\n",
       "      <td>0.406263</td>\n",
       "      <td>0.304513</td>\n",
       "      <td>0.896523</td>\n",
       "      <td>0.427789</td>\n",
       "      <td>17.212791</td>\n",
       "      <td>16.158043</td>\n",
       "      <td>2.663974</td>\n",
       "      <td>29.083162</td>\n",
       "      <td>27.278559</td>\n",
       "      <td>0.497780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>566.379330</td>\n",
       "      <td>376.866635</td>\n",
       "      <td>812.001478</td>\n",
       "      <td>560.442008</td>\n",
       "      <td>0.200826</td>\n",
       "      <td>0.145845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>-58.472364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27260.828157</td>\n",
       "      <td>-46111.108672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23866.859328</td>\n",
       "      <td>-40300.351071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-276.739596</td>\n",
       "      <td>-467.653491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.597880</td>\n",
       "      <td>-58.472341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.599364</td>\n",
       "      <td>-58.472341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.597677</td>\n",
       "      <td>-58.472341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.598664</td>\n",
       "      <td>-58.472341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.597025</td>\n",
       "      <td>-58.472341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.597290</td>\n",
       "      <td>-58.472339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.598571</td>\n",
       "      <td>-58.472341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.598076</td>\n",
       "      <td>-58.471219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>-58.467042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.598798</td>\n",
       "      <td>-58.472341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1193.697090</td>\n",
       "      <td>2019.222018</td>\n",
       "      <td>-34.597809</td>\n",
       "      <td>-34.599730</td>\n",
       "      <td>3408.723521</td>\n",
       "      <td>-58.448997</td>\n",
       "      <td>-58.415987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2034.607507</td>\n",
       "      <td>0.102928</td>\n",
       "      <td>1098.039216</td>\n",
       "      <td>1047.248343</td>\n",
       "      <td>-1.316403</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.589884</td>\n",
       "      <td>-58.440513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2116.000000</td>\n",
       "      <td>1883.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4496.677848</td>\n",
       "      <td>-7597.678444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1681.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4012.594677</td>\n",
       "      <td>-6780.224573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-138.349069</td>\n",
       "      <td>-233.692278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.571736</td>\n",
       "      <td>-58.419039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1194.878703</td>\n",
       "      <td>2019.929036</td>\n",
       "      <td>-34.578256</td>\n",
       "      <td>-34.589231</td>\n",
       "      <td>3411.029470</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>-58.394375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-353.509682</td>\n",
       "      <td>148.934207</td>\n",
       "      <td>2599.671053</td>\n",
       "      <td>2741.310631</td>\n",
       "      <td>-0.126970</td>\n",
       "      <td>0.049407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.581687</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6084.000000</td>\n",
       "      <td>5194.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2696.264852</td>\n",
       "      <td>-4554.985445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4624.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2350.838173</td>\n",
       "      <td>-3972.784169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-103.737860</td>\n",
       "      <td>-175.269890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1195.893091</td>\n",
       "      <td>2020.227674</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3413.281586</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-25.686041</td>\n",
       "      <td>324.820842</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3010.105231</td>\n",
       "      <td>-0.009104</td>\n",
       "      <td>0.107173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-34.567018</td>\n",
       "      <td>-58.404019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16900.000000</td>\n",
       "      <td>15600.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>-1590.011497</td>\n",
       "      <td>-2687.581947</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>13456.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>-1418.162597</td>\n",
       "      <td>-2395.892984</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-69.134309</td>\n",
       "      <td>-116.826429</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.460043</td>\n",
       "      <td>2020.516612</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3415.293554</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>284.859730</td>\n",
       "      <td>578.180641</td>\n",
       "      <td>3555.555556</td>\n",
       "      <td>3386.292446</td>\n",
       "      <td>0.083698</td>\n",
       "      <td>0.186820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-34.549922</td>\n",
       "      <td>-58.384275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>622521.000000</td>\n",
       "      <td>496800.000000</td>\n",
       "      <td>6312.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>-725.580601</td>\n",
       "      <td>-1226.889229</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>476100.000000</td>\n",
       "      <td>4830.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>-138.344436</td>\n",
       "      <td>-233.550019</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-34.551457</td>\n",
       "      <td>-58.385525</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1197.141295</td>\n",
       "      <td>2021.341784</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3419.017295</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2551.377525</td>\n",
       "      <td>2551.377525</td>\n",
       "      <td>5466.666667</td>\n",
       "      <td>5164.906809</td>\n",
       "      <td>0.501637</td>\n",
       "      <td>1.316403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0            1            2            3            4  \\\n",
       "count  2399.0  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      1.0   102.491038    90.738641     3.011672     0.223426   \n",
       "std       0.0    82.043601    72.416289     1.496963     0.416629   \n",
       "min       1.0    21.000000     4.000000     1.000000     0.000000   \n",
       "25%       1.0    46.000000    41.000000     2.000000     0.000000   \n",
       "50%       1.0    78.000000    68.000000     3.000000     0.000000   \n",
       "75%       1.0   130.000000   116.000000     4.000000     0.000000   \n",
       "max       1.0   789.000000   690.000000     8.000000     1.000000   \n",
       "\n",
       "                 5            6            7            8            9  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.147145     0.134223     0.132138     0.155065     0.117549   \n",
       "std       0.354324     0.340962     0.338712     0.362042     0.322140   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.186328     0.104210     0.192163     0.409754   -34.579077   \n",
       "std       0.389452     0.305597     0.394083     0.491891     0.012964   \n",
       "min       0.000000     0.000000     0.000000     0.000000   -34.599730   \n",
       "25%       0.000000     0.000000     0.000000     0.000000   -34.589884   \n",
       "50%       0.000000     0.000000     0.000000     0.000000   -34.581687   \n",
       "75%       0.000000     0.000000     0.000000     1.000000   -34.567018   \n",
       "max       1.000000     1.000000     1.000000     1.000000   -34.549922   \n",
       "\n",
       "                15           16           17             18             19  \\\n",
       "count  2399.000000  2399.000000  2399.000000    2399.000000    2399.000000   \n",
       "mean    -58.424129     0.451855     0.321384   17232.759483   15027.423093   \n",
       "std       0.022798     0.497780     0.467105   38097.608965   32738.422317   \n",
       "min     -58.472364     0.000000     0.000000     441.000000     160.000000   \n",
       "25%     -58.440513     0.000000     0.000000    2116.000000    1883.000000   \n",
       "50%     -58.423297     0.000000     0.000000    6084.000000    5194.000000   \n",
       "75%     -58.404019     1.000000     1.000000   16900.000000   15600.000000   \n",
       "max     -58.384275     1.000000     1.000000  622521.000000  496800.000000   \n",
       "\n",
       "                20           21           22           23           24  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean    411.901626    22.246353    13.496040    15.132138     9.323468   \n",
       "std     571.739834    61.425238    48.927896    54.178100    33.540926   \n",
       "min      21.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      86.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%     231.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%     520.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max    6312.000000   720.000000   789.000000   720.000000   720.000000   \n",
       "\n",
       "                25           26           27           28           29  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean     14.364735    10.305127    20.187578     6.779491    14.102960   \n",
       "std      46.555902    42.643403    63.425866    25.282411    36.202468   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     655.000000   720.000000   789.000000   389.000000   440.000000   \n",
       "\n",
       "                30            31            32           33           34  \\\n",
       "count  2399.000000   2399.000000   2399.000000  2399.000000  2399.000000   \n",
       "mean     56.269696  -3544.049278  -5987.652729    44.937891    36.102126   \n",
       "std      93.130865   2836.876659   4792.707963    71.904666    71.460511   \n",
       "min       0.000000 -27260.828157 -46111.108672     0.000000     0.000000   \n",
       "25%       0.000000  -4496.677848  -7597.678444     0.000000     0.000000   \n",
       "50%       0.000000  -2696.264852  -4554.985445     0.000000     0.000000   \n",
       "75%      91.500000  -1590.011497  -2687.581947    68.000000    45.000000   \n",
       "max     789.000000   -725.580601  -1226.889229   590.000000   720.000000   \n",
       "\n",
       "                  35           36           37           38           39  \\\n",
       "count    2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean    13475.433931   364.163401    18.937474    11.430179    12.912047   \n",
       "std     29337.144958   499.116961    52.200696    41.391084    46.762707   \n",
       "min        16.000000     8.000000     0.000000     0.000000     0.000000   \n",
       "25%      1681.000000    76.000000     0.000000     0.000000     0.000000   \n",
       "50%      4624.000000   204.000000     0.000000     0.000000     0.000000   \n",
       "75%     13456.000000   468.000000     0.000000     0.000000     0.000000   \n",
       "max    476100.000000  4830.000000   690.000000   690.000000   690.000000   \n",
       "\n",
       "                40           41           42           43           44  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      8.029179    12.107962     8.698624    16.211338     5.783660   \n",
       "std      29.583514    39.237122    36.724892    50.778550    20.634561   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     690.000000   530.000000   690.000000   690.000000   337.000000   \n",
       "\n",
       "                45           46            47            48           49  \\\n",
       "count  2399.000000  2399.000000   2399.000000   2399.000000  2399.000000   \n",
       "mean     12.202168    49.566903  -3137.676340  -5301.019066    39.250104   \n",
       "std      30.261185    81.847936   2504.091043   4230.096894    62.821198   \n",
       "min       0.000000     0.000000 -23866.859328 -40300.351071     0.000000   \n",
       "25%       0.000000     0.000000  -4012.594677  -6780.224573     0.000000   \n",
       "50%       0.000000     0.000000  -2350.838173  -3972.784169     0.000000   \n",
       "75%       0.000000    82.000000  -1418.162597  -2395.892984    60.000000   \n",
       "max     380.000000   690.000000   -138.344436   -233.550019   590.000000   \n",
       "\n",
       "                50           51           52           53           54  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean     32.691538    11.310129     0.608587     0.367653     0.404335   \n",
       "std      65.320087    10.426902     1.362776     1.077817     1.194196   \n",
       "min       0.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     4.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     9.000000     0.000000     0.000000     0.000000   \n",
       "75%      41.000000    16.000000     0.000000     0.000000     0.000000   \n",
       "max     690.000000    64.000000     8.000000     8.000000     8.000000   \n",
       "\n",
       "                55           56           57           58           59  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.283035     0.400167     0.293456     0.515215     0.208837   \n",
       "std       0.859820     1.128492     0.962908     1.287198     0.715716   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       7.000000     8.000000     8.000000     8.000000     7.000000   \n",
       "\n",
       "                60           61           62           63           64  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.461859     1.472280  -104.141198  -175.948647     1.330554   \n",
       "std       1.100129     2.036562    51.763971    87.444543     1.773316   \n",
       "min       0.000000     0.000000  -276.739596  -467.653491     0.000000   \n",
       "25%       0.000000     0.000000  -138.349069  -233.692278     0.000000   \n",
       "50%       0.000000     0.000000  -103.737860  -175.269890     0.000000   \n",
       "75%       0.000000     3.000000   -69.134309  -116.826429     3.000000   \n",
       "max       8.000000     8.000000   -34.551457   -58.385525     8.000000   \n",
       "\n",
       "                65           66           67           68           69  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      1.031263     0.223426     0.107962     0.117132     0.096707   \n",
       "std       1.728756     0.416629     0.310397     0.321645     0.295620   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       8.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                70           71           72           73           74  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.122551     0.090454     0.113381     0.042935     0.048770   \n",
       "std       0.327990     0.286891     0.317124     0.202752     0.215432   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                75           76           77           78           79  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.138391    -7.725268   -13.054991     0.116715     0.044602   \n",
       "std       0.345382    14.405494    24.343957     0.321148     0.206471   \n",
       "min       0.000000   -34.597880   -58.472341     0.000000     0.000000   \n",
       "25%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "50%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "75%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "max       1.000000    -0.000000    -0.000000     1.000000     1.000000   \n",
       "\n",
       "                80           81           82           83           84  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.147145     0.073781     0.067111     0.073781     0.061276   \n",
       "std       0.354324     0.261468     0.250267     0.261468     0.239885   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                85           86           87           88           89  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.073781     0.029596     0.035848     0.081701    -5.087788   \n",
       "std       0.261468     0.169504     0.185950     0.273965    12.251382   \n",
       "min       0.000000     0.000000     0.000000     0.000000   -34.599364   \n",
       "25%       0.000000     0.000000     0.000000     0.000000    -0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000    -0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000    -0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000    -0.000000   \n",
       "\n",
       "                90           91           92           93           94  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean     -8.597554     0.072113     0.035431     0.134223     0.067528   \n",
       "std      20.702888     0.258729     0.184906     0.340962     0.250987   \n",
       "min     -58.472341     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      -0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%      -0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%      -0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max      -0.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                95           96           97           98           99  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.075448     0.053356     0.064193     0.027095     0.027928   \n",
       "std       0.264168     0.224788     0.245148     0.162393     0.164802   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               100          101          102          103          104  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.090871    -4.641206    -7.842005     0.067111     0.040434   \n",
       "std       0.287486    11.789944    19.920855     0.250267     0.197015   \n",
       "min       0.000000   -34.597677   -58.472341     0.000000     0.000000   \n",
       "25%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "50%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "75%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "max       1.000000    -0.000000    -0.000000     1.000000     1.000000   \n",
       "\n",
       "               105          106          107          108          109  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.132138     0.062109     0.061692     0.074614     0.027095   \n",
       "std       0.338712     0.241404     0.240646     0.262823     0.162393   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               110          111          112          113          114  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.039183     0.059608    -4.569180    -7.720440     0.061276   \n",
       "std       0.194071     0.236809    11.712228    19.789890     0.239885   \n",
       "min       0.000000     0.000000   -34.598664   -58.472341     0.000000   \n",
       "25%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "50%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "75%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "max       1.000000     1.000000    -0.000000    -0.000000     1.000000   \n",
       "\n",
       "               115          116          117          118          119  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.042101     0.155065     0.055857     0.085452     0.035431   \n",
       "std       0.200861     0.362042     0.229692     0.279612     0.184906   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               120          121          122          123          124  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.040017     0.090038    -5.361515    -9.060980     0.081701   \n",
       "std       0.196039     0.286295    12.517959    21.155395     0.273965   \n",
       "min       0.000000     0.000000   -34.597025   -58.472341     0.000000   \n",
       "25%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "50%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "75%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "max       1.000000     1.000000    -0.000000    -0.000000     1.000000   \n",
       "\n",
       "               125          126          127          128          129  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.025427     0.117549     0.070446     0.025844     0.028345   \n",
       "std       0.157452     0.322140     0.255951     0.158703     0.165992   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               130          131          132          133          134  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.060859    -4.064217    -6.868716     0.056273     0.021259   \n",
       "std       0.239121    11.137901    18.823571     0.230497     0.144276   \n",
       "min       0.000000   -34.597290   -58.472339     0.000000     0.000000   \n",
       "25%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "50%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "75%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "max       1.000000    -0.000000    -0.000000     1.000000     1.000000   \n",
       "\n",
       "               135          136          137          138          139  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.186328     0.034598     0.043768     0.105461    -6.442498   \n",
       "std       0.389452     0.182797     0.204622     0.307210    13.465765   \n",
       "min       0.000000     0.000000     0.000000     0.000000   -34.598571   \n",
       "25%       0.000000     0.000000     0.000000     0.000000    -0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000    -0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000    -0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000    -0.000000   \n",
       "\n",
       "               140          141          142          143          144  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean    -10.887645     0.105877     0.028345     0.104210     0.027928   \n",
       "std      22.756772     0.307745     0.165992     0.305597     0.164802   \n",
       "min     -58.472341     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      -0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%      -0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%      -0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max      -0.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               145          146          147          148          149  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.055023    -3.603276    -6.089238     0.053356     0.022509   \n",
       "std       0.228073    10.566625    17.856722     0.224788     0.148364   \n",
       "min       0.000000   -34.598076   -58.471219     0.000000     0.000000   \n",
       "25%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "50%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "75%       0.000000    -0.000000    -0.000000     0.000000     0.000000   \n",
       "max       1.000000    -0.000000    -0.000000     1.000000     1.000000   \n",
       "\n",
       "               150          151          152          153          154  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.192163     0.062943    -6.644489   -11.228074     0.082118   \n",
       "std       0.394083     0.242911    13.626320    23.026199     0.274601   \n",
       "min       0.000000     0.000000   -34.599730   -58.467042     0.000000   \n",
       "25%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "50%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "75%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "max       1.000000     1.000000    -0.000000    -0.000000     1.000000   \n",
       "\n",
       "               155          156          157          158          159  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.052939     0.409754   -14.168061   -23.940279     0.208420   \n",
       "std       0.223958     0.491891    17.008102    28.739199     0.406263   \n",
       "min       0.000000     0.000000   -34.598798   -58.472341     0.000000   \n",
       "25%       0.000000     0.000000   -34.571736   -58.419039     0.000000   \n",
       "50%       0.000000     0.000000    -0.000000    -0.000000     0.000000   \n",
       "75%       0.000000     1.000000    -0.000000    -0.000000     0.000000   \n",
       "max       1.000000     1.000000    -0.000000    -0.000000     1.000000   \n",
       "\n",
       "               160          161          162          163          164  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.000000   \n",
       "mean      0.103376  1195.712729  2020.252216   -15.624729   -11.117271   \n",
       "std       0.304513     0.896523     0.427789    17.212791    16.158043   \n",
       "min       0.000000  1193.697090  2019.222018   -34.597809   -34.599730   \n",
       "25%       0.000000  1194.878703  2019.929036   -34.578256   -34.589231   \n",
       "50%       0.000000  1195.893091  2020.227674    -0.000000    -0.000000   \n",
       "75%       0.000000  1196.460043  2020.516612    -0.000000    -0.000000   \n",
       "max       1.000000  1197.141295  2021.341784    -0.000000    -0.000000   \n",
       "\n",
       "               165          166          167          168     169  \\\n",
       "count  2399.000000  2399.000000  2399.000000  2399.000000  2399.0   \n",
       "mean   3413.379421   -26.399934   -18.768556     0.451855     0.0   \n",
       "std       2.663974    29.083162    27.278559     0.497780     0.0   \n",
       "min    3408.723521   -58.448997   -58.415987     0.000000     0.0   \n",
       "25%    3411.029470   -58.423297   -58.394375     0.000000     0.0   \n",
       "50%    3413.281586    -0.000000    -0.000000     0.000000     0.0   \n",
       "75%    3415.293554    -0.000000    -0.000000     1.000000     0.0   \n",
       "max    3419.017295    -0.000000    -0.000000     1.000000     0.0   \n",
       "\n",
       "               170        error    error_abs    precioxm2         pred  \\\n",
       "count  2399.000000  1524.000000  1524.000000  1524.000000  2399.000000   \n",
       "mean      0.321384     1.188667   422.659677  3145.918111  3120.518631   \n",
       "std       0.467105   566.379330   376.866635   812.001478   560.442008   \n",
       "min       0.000000 -2034.607507     0.102928  1098.039216  1047.248343   \n",
       "25%       0.000000  -353.509682   148.934207  2599.671053  2741.310631   \n",
       "50%       0.000000   -25.686041   324.820842  3000.000000  3010.105231   \n",
       "75%       1.000000   284.859730   578.180641  3555.555556  3386.292446   \n",
       "max       1.000000  2551.377525  2551.377525  5466.666667  5164.906809   \n",
       "\n",
       "        error_prop  error_prop_abs  \n",
       "count  1524.000000     1524.000000  \n",
       "mean     -0.033978        0.142134  \n",
       "std       0.200826        0.145845  \n",
       "min      -1.316403        0.000030  \n",
       "25%      -0.126970        0.049407  \n",
       "50%      -0.009104        0.107173  \n",
       "75%       0.083698        0.186820  \n",
       "max       0.501637        1.316403  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los errores parecen ser seguir la misma distribuciÃ³n..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Volvemos a la limpieza a buscar mÃ¡s datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Agregando columnas y creando Polynomial features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHkAAAKuCAYAAAA1h8B1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XmcXmV5//HPd5JAQgJE1oogsS5VBGR1RYtKrVtFKy0q1lKtKK3a2tqfFJei1q3a+tNq/Rm3oFihdSvWCrRo3KqYyJKACm5RLCoiiyBknev3x5zUyThJ5mR5znMePu/X67xynnPu+9zXc2YyyzXXfZ9UFZIkSZIkSeq3sa4DkCRJkiRJ0vYzySNJkiRJkjQCTPJIkiRJkiSNAJM8kiRJkiRJI8AkjyRJkiRJ0ggwySNJkiRJkjQCTPJIkiRJkiSNAJM8kiRJkiRJI8AkjyRJkiRJ0ggwySNJkiRJkjQCZncdgIbLt4777eo6hjYyZ5euQ2hlzl337zqE1ma/4y1dh9DabWvWdB1CKwfM37XrEFr7+vU3dx1Ca3svmN91CK1sqPGuQ2ht3z0WdB1Ca9dcd33XIbSyfkP/Pi8e8IPvdR1Ca7cee2zXIbSyzy03dR1Caz/crV9fL/ad669NgzD357d1HUIra771na5D2CYLjj8uXcewswzy99l7f/HCobyPVvJIkiRJkiSNAFPSkiRJkiSp/2Idi3dAkiRJkiRpBFjJI0mSJEmS+i9DuUzOQFnJI0mSJEmSNAJM8kiSJEmSJI0Ap2tJkiRJkqTey5jTtazkkSRJkiRJGgFW8kiSJEmSpP7zEer9qORJ8uEkK5K8eCePc+YM2ixM8iczvN5tWzh3QJKPtImvjSS/leRrSVY2/z5qZ40lSZIkSZK6N9SVPElmA/sAD62qgwcw5JnA67bSZiHwJ8A/bc9AVXUdcNL2XGMrbgB+p6quS3IocCFwt504niRJkiRJ3fER6oOp5EkyP8mnklyR5MokJydZlWSf5vwxSZY2+2clWZzkIuADwEXAfkkuT/LwJM9Nsqy51keT7Nb02z/Jx5vjVyR5aHP8mUm+2vR/V5JZm4nxDcC8pt2HmmN/0cR7ZZI/b5q+Abhn0+5NSRYkuTjJpU3VzIkzvCeLklzZ7J+a5GNJLkjyrSR/t5W+tyV5Y1Oh819JHphkaZLvJnkSQFVd1iSSAK4C5ibZdSaxSZIkSZKk/hnUdK3HAtdV1QOq6lDggq20Pxo4saqeATwJ+E5VHVFVXwA+VlXHVtUDgG8Az2n6vA34XHP8KOCqJPcDTgYeVlVHABuAU6YbsKrOAO5oxjklydHAHwEPAh4MPDfJkcAZk+L5K2A18JSqOgp4JPD3yTalD49oYj0MODnJQVtoOx9YWlVHA7cCfwv8FvAU4NXTtH8qcFlVrZnuYklOS7I8yfJzf/zDbQhdkiRJkqSOjWVw25Aa1HStlcCbk7wR+Peq+sJW8iDnV9Udmzl3aJK/ZWLa1AImpiEBPAp4FkBVbQBuSfIHTCSMljXjzQOun2HMxwEfr6pfACT5GPBw4Pwp7QK8LskjgHEmpkTtD/x4huNsdHFV3dKM9XXgYODazbRdyy8TZSuBNVW1LslKYNEmwSX3B94IPGZzA1fVYmAxwLeO++1qGbckSZIkSRoCA0nyVNU1TWXM44HXN1Ox1vPLSqK5U7r8YguXWwI8uaquSHIqcPwW2gY4u6r+ehvCnmlq7hRgX+DoJtGyil99PzMxucpmA1v+2Kyrqo3JmPGNfatqvFnHCIAkBwIfB55VVd/ZhpgkSZIkSeqFbZtUM1oGtSbPAcDtVXUO8GYmplOtYqLKBiamE83U7sCPksxh06lXFwOnN+PNSrJHc+ykJPs1x/dKsqUFnNc11wX4PPDkJLslmc/EVKgvMDE9avdJffYErm8SPI9kogKnc0kWAp8C/rqqvtR1PJIkSZIkaeca1HStw4A3JRkH1jGRjJkHvLd5bPklLa71iqb995mYqrQx4fJnwOIkz2GiEub0qvpykpcDFyUZa8b+06bvdBYDK5Jc2qzLswT4anPuPVV1GUCSLzWLJn+aialQn0yyHLgc+GaL97IzvQC4F/CKJK9ojj2mqmY6XU2SJEmSpP4YG9Syw8Mrv5z1I/VvTZ7M2aXrEFqZc9f9uw6htdnveEvXIbR225pp1xgfWgfM79+D775+/c1dh9Da3gvmdx1CKxtqvOsQWtt3jwVdh9DaNdf1628f6zf07/PiAT/4XtchtHbrscd2HUIr+9xyU9chtPbD3fr19WLfuYP62/id29yf39Z1CK2s+VY/V8RYcPxxIzun6Tu//bsD+332nhd+bCjvo1+tJEmSJElS/7kmz50zyZPkEmDqn87/oKpW7oSxDgM+OOXwmqp60Az6DixOSZIkSZLUb3fKJM9MEiw7cKyVwBHb2HdgcUqSJEmS1GtW8gzm6VqSJEmSJEnauUzySJIkSZIkjYA75XQtSZIkSZI0WuIj1K3kkSRJkiRJGgVW8mgTmbNL1yG0UuvWdh1CK2t/cC273P2grsNoZc369V2H0NqG8eo6hFbWjs3pOoTWxnt2jwHWj2/oOoRWeniLuWPNuq5DaK1vXy/Gq1/xAtDDv6pWz+5z9fB7dR+/j2jnW73Hgq5DaCXj412HoKl6+D1nR/MOSAPUtwSPJEmSJKk/rOSRJEmSJEn95yPUreSRJEmSJEkaBVbySJIkSZKk3ouVPFbySJIkSZIkjQIreSRJkiRJUv+NWcljJY8kSZIkSdIIsJJHkiRJkiT1X6xj8Q5IkiRJkiSNACt5JEmSJElS/7kmz86v5Eny4SQrkrx4Z481bJIsSXLSFs6/J8khO2ns3ZJ8Ksk3k1yV5A07YxxJkiRJkjQcdlolT5LZwD7AQ6vq4J01zqAlmV1V63fEtarqj3fEdbbgzVX12SS7ABcneVxVfXonjylJkiRJ0sAlVvJstZInyfymIuSKJFcmOTnJqiT7NOePSbK02T8ryeIkFwEfAC4C9ktyeZKHJ3lukmXNtT6aZLem3/5JPt4cvyLJQ5vjz0zy1ab/u5LM2kKcj01yadP/4ubYXkk+0VQSfSXJ4UnGmvgXTur77SaGfZu4ljXbw6Z7X0lmJXlT02ZFkuc17ZLk7Um+nuRTwH5bubdLkxzT7N+W5LVN/F9Jsv8W+i1J8s4kn03y3SS/meR9Sb6RZAlAVd1eVZ9t9tcClwIHbikeSZIkSZLUXzOZrvVY4LqqekBVHQpcsJX2RwMnVtUzgCcB36mqI6rqC8DHqurYqnoA8A3gOU2ftwGfa44fBVyV5H7AycDDquoIYANwynQDJtkXeDfw1OYav9ecehVwWVUdDpwJfKCqxoF/A57S9H0QsKqqfgK8FXhLVR0LPBV4z2be13OAW5p2xwLPTXKP5pq/ARwGPBd46Fbu1WTzga808X++6b8ldwEeBbwY+CTwFuD+wGFJjphyfxYCvwNcPN2FkpyWZHmS5ede9/0WIUuSJEmSpGExk+laK4E3J3kj8O9V9YWtlECdX1V3bObcoUn+FlgILAAubI4/CngWQFVtAG5J8gdMJFaWNePNA67fzHUfDHy+qr7XXOPG5vhxTCRrqKrPJNk7yZ7AecArgfcDT2teA5wAHDLp/e2RZPdp3tdjgMMnrbezJ3Bv4BHAh5v3cF2Sz2wm3umsBf692f8a8Ftbaf/JqqokK4GfVNVKgCRXAYuAy5vXs4EPA2+rqu9Od6GqWgwsBvj2I3+nWsQsSZIkSdJw8BHqW0/yVNU1SY4GHg+8vpmytJ5fVgHNndLlF1u43BLgyVV1RZJTgeO30DbA2VX111uLsWk7XXJiumxUAV8G7tVUAD0Z+Nvm3BjwkKlJqibpM/l9BXhhVV04pd3jNxPHTKyrqo19N7D1j82a5t/xSfsbX0/uuxj4VlX9322MS5IkSZIk9cBM1uQ5ALi9qs4B3szEdKpVTFTZQFMpM0O7Az9KModNp15dDJzejDcryR7NsZOS7Ncc3yvJ5hZw/jLwm82UKZLs1Rz//MZxkhwP3FBVP2+SKR8H/gH4RlX9rGl/EfCCSe99k2lPk1wInN68D5LcJ8n8ZrynNe/hrsAjZ3JTdpamampP4M+7jEOSJEmSpJ1uLIPbhtRMpmsdBrwpyTiwjolkzDzgvUnOBC5pMd4rmvbfZ2Ia2MapUH8GLE7yHCaqWE6vqi8neTlwUZKxZuw/bfpuoqp+muQ04GNN2+uZmO50FvD+JCuA24E/nNTtPGAZcOqkYy8C3tG0n81E0ub507yP9zAxJerSTJT5/JSJiqCPMzH1bCVwDfC5md6YHS3JgcDLgG82cQK8vares8WOkiRJkiSpl/LLGUJS/9bkqXVruw6hlV3uflDXIbS24a1v6jqE1lavW991CK3sv+fuW280ZK65bnNLpA2vuyyY13UIrYz36qvxhD3nTZ3BPfxW/fTGrTcaIhvGx7sOobUj/+cHXYfQ2s+POqrrEFrZ58Ybug6htWsX7Nl1CK3sv9ucrkPQEMqyy7oOYZsseNQjhrcMZTt9/xl/PLCfoA7+5/cM5X10VSJJkiRJkqQRMJPpWkMlySXArlMO/8HGp0sNoyQfB+4x5fBLpy7cPE2/l/HLx8Fv9K9V9dodGZ8kSZIkSb235SeB3yn0LslTVQ/qOoa2quop29jvtYAJHUmSJEmStFW9S/JIkiRJkiT9Cit5XJNHkiRJkiRpFFjJI0mSJEmS+m/MOhbvgCRJkiRJ0giwkkeSJEmSJPVeXJPHJI82Neeu+3cdwkhb+4Nruw6htTVr1nYdQmu3rV7TdQitLNxtXtchtNa3ewwwd5d+fcvbMF5dh9Da7Fn9KxC+vWdf43ad06/PY4DMmtV1CK2tG9/QdQit9PEej435i5j6b/1NN3cdgvQr+vfTmCRJkiRJ0lRjGdw2A0kem+TqJN9OcsY05++e5LNJLkuyIsnjt/sWbO8FJEmSJEmS9EtJZgHvAB4HHAI8PckhU5q9HPiXqjoSeBrwT9s7rkkeSZIkSZKkHeuBwLer6rtVtRY4FzhxSpsC9mj29wSu295B+zexW5IkSZIkaaoMVR3L3YDJi7L+EHjQlDZnARcleSEwHzhhewcdqjsgSZIkSZI07JKclmT5pO20qU2m6Tb1yRpPB5ZU1YHA44EPJtuXqbKSR5IkSZIk9d8AH6FeVYuBxVto8kPgoEmvD+RXp2M9B3hsc70vJ5kL7ANcv61xWckjSZIkSZK0Yy0D7p3kHkl2YWJh5fOntPkB8GiAJPcD5gI/3Z5BreSRJEmSJEm9lxk+2nwQqmp9khcAFwKzgPdV1VVJXg0sr6rzgb8E3p3kxUxM5Tq1qqZO6WrFJI8kSZIkSdIOVlX/AfzHlGOvnLT/deBhO3JMp2vNQJKnJKkk923Zb0mSk6Y5fkySt21HPGdua19JkiRJkkZSMrhtSJnkmZmnA19kYg7ddquq5VX1ou24hEkeSZIkSZK0CZM8W5FkARPlU8+hSfIkOT7J55L8S5JrkrwhySlJvppkZZJ7TrrECUm+0LR74qT+/97sz0/yviTLklyW5MTm+KlJPpbkgiTfSvJ3zfE3APOSXJ7kQ82xZzZjX57kXUlmNduSJFc2Mb14YDdNkiRJkqRBGxsb3DakXJNn654MXFBV1yS5MclRzfEHAPcDbgS+C7ynqh6Y5M+AFwJ/3rRbBPwmcE/gs0nuNeX6LwM+U1XPTrIQ+GqS/2rOHQEcCawBrk7yj1V1RpIXVNUR8L8rcJ8MPKyq1iX5J+AU4CrgblV1aNNu4Q69K5IkSZIkaagMb/ppeDwdOLfZP7d5DbCsqn5UVWuA7wAXNcdXMpHY2ehfqmq8qr7FRDJo6ro+jwHOSHI5sJSJR6bdvTl3cVXdUlWrga8DB08T36OBo4FlzTUeDfx6M9avJ/nHJI8Ffr65N5jktCTLkyz/529/cwu3QpIkSZKk4ZSxsYFtw8pKni1IsjfwKODQJMXEY8+KidWx10xqOj7p9Tib3tepjz+b+jrAU6vq6iljP2jKGBuY/uMV4Oyq+utp4n8A8NvAnwK/Dzx7mv5U1WJgMcD3n/HH2/W4NkmSJEmS1I3hTT8Nh5OAD1TVwVW1qKoOAr4HHNfiGr+XZKxZp+fXgaunnL8QeGEysTx3kiNncM11SeY0+xcDJyXZr+m/V5KDk+wDjFXVR4FXAEdt5lqSJEmSJPWfT9eykmcrng68YcqxjwKnMzFFayauBj4H7A88v6pWZ9NPiNcA/xdY0SR6VgFP3Mo1FzftL62qU5K8HLgoyRiwjonKnTuA9zfHAH6l0keSJEmSJI0OkzxbUFXHT3PsbcDbNteuqpYysbYOVXXqZq47uc0dwPOmabMEWDLp9RMn7b8UeOmk1+cB500zlNU7kiRJkqQ7hyGusBkUp2tJkiRJkiSNAJM8kiRJkiRJI8DpWpIkSZIkqf+G+NHmg+IdkCRJkiRJGgFW8kiSJEmSpN6LCy9bySNJkiRJkjQKrOSRJEmSJEn9ZyWPlTySJEmSJEmjwEoebWL2O97SdQitrFm/vusQWlmzZm3XIbS269Oe1XUIrR3w3FO7DqGV9Tf8rOsQWjv2wAO6DqG1dT++vusQWpm9795dh9Badt216xBaW3TsUV2H0MrNd9mr6xBam71+ddchtHbgeL9+vli2rusI2jt0br9+DfnmT2/pOoTW7rvvnl2H0NrsVT/oOoRWvnlkv76HbHRs1wHsTGNW8ljJI0mSJEmSNAL6lUKXJEmSJEmaTqxj8Q5IkiRJkiSNACt5JEmSJElS78U1eazkkSRJkiRJGgVW8kiSJEmSpP4bs47FOyBJkiRJkjQCrOSRJEmSJEn9F9fksZJHkiRJkiRpBJjkGWJJ3pPkkGZ/VZJ9ttL+zMFEJkmSJEmSho3TtYZYVf1xyy5nAq/bGbFIkiRJkjTM4nQtK3mGQZJFSb6Z5OwkK5J8JMluSZYmOWaa9s9M8tUklyd5V5JZSd4AzGuOfahp94kkX0tyVZLTBv7GJEmSJEnSwJjkGR6/ASyuqsOBnwN/Ml2jJPcDTgYeVlVHABuAU6rqDOCOqjqiqk5pmj+7qo4GjgFelGTvnf4uJEmSJEnqwtjY4LYhNbyR3flcW1VfavbPAY7bTLtHA0cDy5Jc3rz+9c20fVGSK4CvAAcB956uUZLTkixPsvycJe/f5jcgSZIkSZK645o8w6O28nqjAGdX1V9v6WJJjgdOAB5SVbcnWQrMnXbgqsXAYoD/uenWzY0rSZIkSdLwck0eK3mGyN2TPKTZfzrwxc20uxg4Kcl+AEn2SnJwc25dkjnN/p7ATU2C577Ag3dW4JIkSZIkqXsmeYbHN4A/TLIC2At453SNqurrwMuBi5q2/wnctTm9GFjRLLx8ATC7afMaJqZsSZIkSZI0mpLBbUPK6VrDY7yqnj/l2PEbd6pq0aT984Dzpl6gql4KvHTSocft2BAlSZIkSdKwMskjSZIkSZJ6L0P81KtBMckzBKpqFXBo13FIkiRJkqT+MskjSZIkSZL6b4jXyhkUa5kkSZIkSZJGgJU8kiRJkiSp/8as5LGSR5IkSZIkaQRYySNJkiRJkvrPNXms5JEkSZIkSRoFVvJoE7etWdN1CK1sGK+uQ2jlttX9ur8ABzz31K5DaO1n717SdQit7PcXL+g6hNYyd9euQ2ht1/nzuw6hnR7OKR/bfUHXIbSW2f36UWj2rP79fW72/vt2HUJrd/Tsa9zu8zZ0HUJra8fmdB1CK7vP69fnRF/N2n33rkNoZcP68a5D0BQZ69/3yR3NOyBJkiRJkjQCTPJIkiRJkiSNgH7VKEuSJEmSJE0n1rF4ByRJkiRJkkaAlTySJEmSJKn/evjgih3NSh5JkiRJkqQRYCWPJEmSJEnqvcRKHit5JEmSJEmSRoCVPJIkSZIkqf98upaVPMMuyXuSHNLsnznl3H93E5UkSZIkSRo2VvIMuar640kvzwReN+ncQwcfkSRJkiRJQ8ina1nJsy2SfCLJ15JcleS05thtSd7YHP+vJA9MsjTJd5M8qWkzK8mbkixLsiLJ85rjxzdtP5Lkm0k+lGbFqOb4MUneAMxLcnmSD20cc1JMfzXpuq9qjs1P8qkkVyS5MsnJA75VkiRJkiRpQKzk2TbPrqobk8wDliX5KDAfWFpVL03yceBvgd8CDgHOBs4HngPcUlXHJtkV+FKSi5prHgncH7gO+BLwMOCLGwesqjOSvKCqjpgaTJLHAPcGHggEOD/JI4B9geuq6glNuz13+J2QJEmSJGkY+HQtK3m20YuSXAF8BTiIiQTLWuCC5vxK4HNVta7ZX9QcfwzwrCSXA5cAezd9Ab5aVT+sqnHg8kl9ZuIxzXYZcClw3+a6K4ETmgqjh1fVLdN1TnJakuVJlp/3wQ+0GFaSJEmSJA0LK3laSnI8cALwkKq6PclSYC6wrqqqaTYOrAGoqvEkG+9zgBdW1YXTXHPNpEMbaPexCfD6qnrXNPEeDTweeH2Si6rq1VPbVNViYDHA1T++oaaelyRJkiRp2MU1eazk2QZ7Ajc1CZ77Ag9u0fdC4PQkcwCS3CfJ/Bb9123sO811n51kQXPduyXZL8kBwO1VdQ7wZuCoFmNJkiRJkqQesZKnvQuA5ydZAVzNxJStmXoPE9OwLm0WVv4p8OQW/RcDK5JcWlWnbDxYVRcluR/w5Wa95tuAZwL3At6UZBxYB5zeYixJkiRJkvoj1rGY5GmpqtYAj5vm1IJJbc6a0mdB8+84E49BP3NK36XNtrH9CybtHz9p/6XAS6det9l/K/DWKdf9DhNVPpIkSZIkacSZ5pIkSZIkSRoBVvJIkiRJkqT+8xHqVvJIkiRJkiSNAit5JEmSJElS//kIdSt5JEmSJEmSRoGVPJIkSZIkqfcyZh2Ld0CSJEmSJGkEWMkjSZIkSZL6L9axmOTRJg6Yv2vXIbSydmxO1yG0snC3eV2H0Nr6G37WdQit7fcXL+g6hFau/4e3dx1Ca/u++E+7DqG9DRu6jqCV2fvs3XUIrWV2D3+s6NkCjavXru86hNbm33hz1yG0dscBB3QdQit7zu/fzxd9e8rx/Ln9+hkZ+vdzMsDsW2/tOoRWdlvYv+/VGn09/GlMkiRJkiRpip798WZnsJZJkiRJkiRpBFjJI0mSJEmSei99mwu6E1jJI0mSJEmSNAKs5JEkSZIkSf1nJY+VPJIkSZIkSaPASh5JkiRJktR/Y9axeAckSZIkSZJGgEkeSZIkSZKkEWCSZydJ8uokJ3Qw7pOSnDHocSVJkiRJ6lQyuG1IuSbPTlJVr+xo3POB87sYW5IkSZIkdcdKnh0gySuSfDPJfyb5cJKXJFmS5KTm/Kokr0vy5STLkxyV5MIk30ny/KbN8UmWJvlIc60PJRPpwSSvTLIsyZVJFk86/qIkX0+yIsm5zbFTk7y92T84ycXN+YuT3L2bOyRJkiRJ0s6VZGDbsDLJs52SHAM8FTgS+F3gmM00vbaqHgJ8AVgCnAQ8GHj1pDZHAn8OHAL8OvCw5vjbq+rYqjoUmAc8sTl+BnBkVR0OPH+aMd8OfKA5/yHgbdvyHiVJkiRJ0vAzybP9jgP+raruqKpbgU9upt3GKVQrgUuq6taq+imwOsnC5txXq+qHVTUOXA4sao4/MsklSVYCjwLu3xxfAXwoyTOB9dOM+RDgn5v9Dzax/ookpzUVRsvf//73z+Q9S5IkSZI0XMbGBrcNKdfk2X4zrdNa0/w7Pml/4+vZU9oAbABmJ5kL/BNwTFVdm+QsYG7T5gnAI4AnAa9Icn+2rKY9WLUYWAxw6623TttGkiRJkiQNt+FNP/XHF4HfSTI3yQImEi870saEzg3N9Teu8zMGHFRVnwX+D7AQWDCl738DT2v2T2lilSRJkiRp9Ph0LSt5tldVLUtyPnAF8H1gOXDLDrz+zUnezcQ0r1XAsubULOCcJHsyUU30lqbt5O4vAt6X5K+AnwJ/tKPikiRJkiRJw8Ukz47x5qo6K8luwOeBv6+qd288WVWLJu0vYWLh5annljbbxuMvmLT/cuDl04z7K2vsTL5+Va1iYg0fSZIkSZJG2xCvlTMoJnl2jMVJDmFiatXZVXVp1wFJkiRJkqQ7F5M8O0BVPaPrGCRJkiRJujPL2PCulTMo1jJJkiRJkiSNACt5JEmSJElS/w3xU68GxUoeSZIkSZKkEWAljyRJkiRJ6r9Yx+IdkCRJkiRJGgEmeSRJkiRJkkaA07W0ia9ff3PXIbQyPl5dh9DKbavXdB1Ca8ceeEDXIbSWubt2HUIr+774T7sOobWfvuUdXYfQ2l1f+8quQ2hlw89u7DqE1rJ2XdchtJZZs7oOoZXdZ/Xr+x7ALw46sOsQ2tsw3nUEraxdt6HrEFrbZVa/Yp7Vwykgu4z372vyrD337DqEVq6/5bauQ9g2B3UdwM7jI9St5JEkSZIkSRoJVvJIkiRJkqT+8xHqVvJIkiRJkiSNAit5JEmSJElS//Vw/awdzTsgSZIkSZI0AqzkkSRJkiRJ/efTtazkkSRJkiRJGgVW8kiSJEmSpN6LT9eykkeSJEmSJGkUmOTZyZLcNoAxliY5ZmePI0mSJEnS0BrL4LYZSPLYJFcn+XaSM7bQ7qQktSN+rzfJM8KSzOo6BkmSJEmS7mya38ffATwOOAR4epJDpmm3O/Ai4JIdMa5JngFJsiDJxUkuTbIyyYnN8UVJrpzU7iVJzmr2lyZ5Y5KvJrkmycOb4/OSnJtkRZLzgHmT+t+W5NVJLgFenuTjk879VpKPDegtS5IkSZI0OGNjg9u27oHAt6vqu1W1FjgXOHGadq8B/g5YvUNuwY64iGZkNfCUqjoKeCTw95nZqlCzq+qBwJ8Df9McOx24vaoOB14LHD2p/Xzgyqp6EPBq4H5J9m3O/RHw/u1/K5IkSZIkaQvuBlw76fUPm2P/K8mRwEFV9e87alCTPIMT4HVJVgD/xcQHd/8Z9NtYefM1YFGz/wjgHICqWgGsmNR+A/DR5lwBHwSemWQh8BDg078SWHJakuVJln/i3A+1fFuSJEmSJA2BjA1sm/x7dLOdNjWaaSKs/z2ZjAFvAf5yR94CH6HaUc1NAAAgAElEQVQ+OKcA+wJHV9W6JKuAucB6Nk22zZ3Sb03z7wY2/XgV01tdVRsmvX4/8EkmKon+tarWT+1QVYuBxQCXfOfazV1XkiRJkiSx6e/Rm/FD4KBJrw8Erpv0enfgUGBpM8nn14DzkzypqpZva1xW8gzOnsD1TYLnkcDBzfGfAPsl2TvJrsATZ3CtzzORNCLJocDhm2tYVdcx8Yn0cmDJtocvSZIkSZJmaBlw7yT3SLIL8DTg/I0nq+qWqtqnqhZV1SLgK8B2JXjASp5B+hDwySTLgcuBbwI0SZ9XM7GS9vc2Ht+KdwLvb6Z+XQ58dQZj71tVX9/W4CVJkiRJGmYzW/Z2MKpqfZIXABcCs4D3VdVVze//y6vq/C1fYduY5NnJqmpB8+8NTKyJM12btwFvm+b48ZP2b6BZk6eq7mAiC7jZ8aY4Dnh3u8glSZIkSdK2qqr/AP5jyrFXbqbt8TtiTJM8Iy7J14BfsIMXc5IkSZIkaaiMDU8lT1dM8oy4qjp6660kSZIkSVLfmeSRJEmSJEn9N0Rr8nTFp2tJkiRJkiSNACt5JEmSJElS/8U6Fu+AJEmSJEnSCLCSR5IkSZIk9V58upaVPJIkSZIkSaPASh5tYu8F87sOoZX14xu6DqGVuyyYxx1r13UdRivrfnx91yG0tuv8fn0es6Ffn8cAd33tK7sOobUfvezVXYfQyq+96syuQ2htw823dB1Ca+O33tZ1CO3M3bXrCFrb/aabug6htdV7LOg6hFa+dfPPuw6htcPvulfXIbQzC75+/c1dR9HKIfst7DqE1mrNmq5DaGWfPXr2M+edgU/XspJHGqS+JXgkSZLUvwSPpDsvK3kkSZIkSVL/jVnH4h2QJEmSJEkaAVbySJIkSZKk3otr8ljJI0mSJEmSNApM8kiSJEmSJI0Ap2tJkiRJkqT+c+FlK3kkSZIkSZJGgZU8kiRJkiSp/1x42UoeSZIkSZKkUWAljyRJkiRJ6r8xK3ms5JEkSZIkSRoBJnmGXJL5ST6V5IokVyY5OcmqJPs0549JsrTZPyvJ2Ukuatr8bpK/S7IyyQVJ5nT6ZiRJkiRJ2kmSsYFtw2p4I9NGjwWuq6oHVNWhwAVbaX9P4AnAicA5wGer6jDgjua4JEmSJEkaQSZ5ht9K4IQkb0zy8Kq6ZSvtP11V65p+s/hlUmglsGi6DklOS7I8yfJzP3j2jopbkiRJkqTBSQa3DSkXXh5yVXVNkqOBxwOvT3IRsJ5fJujmTumypuk3nmRdVVVzfJzNfLyrajGwGODbP7mxpmsjSZIkSZKGm0meIZfkAODGqjonyW3AqcAq4Gjg08BTu4tOkiRJkqQh4dO1TPL0wGHAm5KMA+uA04F5wHuTnAlc0mVwkiRJkiRpOJjkGXJVdSFw4TSn7jNN27OmvF6wuXOSJEmSJI2UIX7q1aB4ByRJkiRJkkaAlTySJEmSJKn34po8VvJIkiRJkiSNApM8kiRJkiRJI8DpWpIkSZIkqf/idC0reSRJkiRJkkaAlTySJEmSJKn/rOSxkkeSJEmSJGkUWMmjTWyo8a5DaGW8uo6gnQ19CxiYve/eXYfQXs8enTh7n/7d4w0/u7HrEFr7tVed2XUIrfz4b17XdQit7X/GX3QdQmvZZU7XIbSybla/4gVgjwVdR9DavNtXdx1CK7vMntV1CK3dQb9i3nVO/35t6ts9Bth1Tr++xq3f0K/fne4MMmYdi3dAkiRJkiRpBPQvJS1JkiRJkjSVlTxW8kiSJEmSJI0CK3kkSZIkSVL/+XQtK3kkSZIkSZJGgZU8kiRJkiSp/3r2lN2dwUoeSZIkSZKkEWAljyRJkiRJ6r3EOhbvgCRJkiRJ0ggwydOBJEuTHNOyz6uTnLCzYpIkSZIkqdeSwW1DyulaPZBkVlW9sus4JEmSJEnS8LKSZwdJMj/Jp5JckeTKJCcneXSSy5KsTPK+JLtO0++dSZYnuSrJqyYdX5XklUm+CPxekiVJTpp0bp9m/5gkS5v9s5KcneSips3vJvm7ZvwLkswZzN2QJEmSJEmDZpJnx3kscF1VPaCqDgUuAJYAJ1fVYUxUTZ0+Tb+XVdUxwOHAbyY5fNK51VV1XFWd2yKOewJPAE4EzgE+24x/R3NckiRJkqTRM5bBbUPKJM+OsxI4IckbkzwcWAR8r6quac6fDTximn6/n+RS4DLg/sAhk86dtw1xfLqq1jXxzGIi2bQxvkXTdUhyWlNNtPy8D35gG4aUJEmSJEldc02eHaSqrklyNPB44PXARVvrk+QewEuAY6vqpiRLgLmTmvxiM13X88sE3dwp59Y08YwnWVdV1RwfZzMf76paDCwGuPrHN9R0bSRJkiRJGmpDvCDyoFjJs4MkOQC4varOAd4MPBRYlOReTZM/AD43pdseTCRybkmyP/C4GQ63Cji62X/q9sQtSZIkSZJGg5U8O85hwJuSjAPrmFh/Z0/gX5PMBpYB/29yh6q6IsllwFXAd4EvzXCsVwHvTXImcMkOil+SJEmSpN5KrGMxybODVNWFwIXTnDpymrbHT9o/dTPXWzTl9amT9r8A3GeaPmdNeb1gc+ckSZIkSdJoMckjSZIkSZL6b4ifejUo1jJJkiRJkiSNACt5JEmSJElS/41Zx+IdkCRJkiRJGgFW8kiSJEmSpN5LXJPHSh5JkiRJkqQRYCWPJEmSJEnqP9fksZJHkiRJkiRpFFjJo03su8eCrkNo5Y4167oOoZXZs/qXV82uu3YdQmtju/fr8ziz+/elOGv79X8PYMPNt3QdQiv7n/EXXYfQ2k/e8A9dh9DaovOWdB1CKxvGq+sQWltw481dh9DaHXst7DqEVtb//I6uQ2htHhu6DqGVNevWdx1Ca327xwDrfvTjrkNoZZcD7951CJrKNXms5JEkSZIkSRoFJnkkSZIkSZJGQP/mCEiSJEmSJE3ldC0reSRJkiRJkkaBlTySJEmSJKn3MmYlj5U8kiRJkiRJI8BKHkmSJEmS1H+xjsU7IEmSJEmSNAKs5JEkSZIkSf3n07Ws5OmrJE9Kckazf1aSlzT7S5Kc1G10kiRJkiRp0Kzk6YEks6tq/ZTX5wPndxiWJEmSJEnDw6drmeQZlCSLgAuAS4AjgWuAZwEvAX4HmAf8N/C8qqokS5vXDwPOT3IYcGPT99IkK4FjquoFWxjzldNde2e8P0mSJEmS1C2naw3WbwCLq+pw4OfAnwBvr6pjq+pQJpIxT5zUfmFV/WZV/X3z+j7ACVX1lzMcb0vXliRJkiRpZCRjA9uG1fBGNpquraovNfvnAMcBj0xySVOZ8yjg/pPanzel/79W1YYW423p2v8ryWlJlidZfvb73tvi8pIkSZIkaVg4XWuwpk6VKuCfmJh2dW2Ss4C5k87/Ykr7qa83K8ncrVz7l0FULQYWA9x4+2qnc0mSJEmS+sc1eazkGbC7J3lIs/904IvN/g1JFgA78qlYGxM6O+PakiRJkiRpyFjJM1jfAP4wybuAbwHvBO4CrARWAct21EBVdXOSd++Ma0uSJEmSNGzumLvrwMbafWAjtWOSZ7DGq+r5U469vNk2UVXHT3l96pTXS4Alzf5Z07WrqmmvLUmSJEmSRo/TtSRJkiRJkkaAlTwDUlWrgEO7jkOSJEmSJI0mK3kkSZIkSZJGgEkeSZIkSZKkEWCSR5IkSZIkaQSY5JEkSZIkSRoBJnkkSZIkSZJGgEkeSZIkSZKkEeAj1LWJa667vusQWtkwXl2H0Mrta9Z2HUJri449qusQWsvsnn1pG0vXEbSWWbO6DqG18Vtv6zqEVrLLnK5DaG3ReUu6DqG1VSef2nUIrfzapz/SdQitrdlrYdchjLxd5vTva/Lq9Ot79cL587oO4U5h/ND7dR1CK9d//yddh7BtDuo6AO1MVvJIkiRJkiSNAJM8kiRJkiRJI8AkjyRJkiRJ0ggwySNJkiRJkjQCTPJIkiRJkiSNAJM8kiRJkiRJI8AkjyRJkiRJ0ggwySNJkiRJkjQCTPJIkiRJkiSNAJM8HUlyfJKHdh2HJEmSJEkaDSZ5unM8MG2SJ8nsnTVoklk769qSJEmSJKk7Oy2ZMGqSfAI4CJgLvLWqFk/T5mjgH4AFwA3AqVX1oyQvAp4PrAe+DpzRvN6Q5JnAC4HnADcCRwKXJnkl8I/AYUx8nM6qqn9LcirwJGA34J7Ax6vq/zTjvxM4FpgHfKSq/qY5vgp4H/AY4O3AuTv05kiSJEmS1LF1s+Z0HULnTPLM3LOr6sYk84BlST5aVT/beDLJHCaSMidW1U+TnAy8Fng2E0mde1TVmiQLq+rmJP8PuK2q3tz0fw5wH+CEqtqQ5HXAZ6rq2UkWAl9N8l/NcEcwkQxaA1yd5B+r6lrgZU2Ms4CLkxxeVSuaPqur6ridfI8kSZIkSVJHnK41cy9KcgXwFSYqeu495fxvAIcC/5nkcuDlwIHNuRXAh5qqnfVbGONfq2pDs/8Y4IzmWkuZqCC6e3Pu4qq6papWM1EZdHBz/PeTXApcBtwfOGTStc/b3KBJTkuyPMnyT5z7z1sIT5IkSZKk4VQ1uG1YWckzA0mOB04AHlJVtydZykTSZZNmwFVV9ZBpLvEE4BFMTLN6RZL7b2aoX0y53lOr6uopsTyIiQqejTYAs5PcA3gJcGxV3ZRkyZQYJ197E83Us8UAX/n2D4b401WSJEmSJG2OlTwzsydwU5PguS/w4GnaXA3sm+QhMDF9K8n9k4wBB1XVZ4H/AyxkYs2eW4HdtzDmhcALk6S53pFbiXEPJhI5tyTZH3jczN+eJEmSJEn9Nl41sG1YmeSZmQuYqJZZAbyGiSlbm6iqtcBJwBubaV2XM/H0rFnAOUlWMjGN6i1VdTPwSeApSS5P8vBpxnwNMAdYkeTK5vVmVdUVzfWvYmKR5S9t0zuVJEmSJEm95HStGaiqNcygMqaqLmdiWtZUv7LgcVVdAxw+6dAXppy/A3jeNP2WAEsmvX7ipP1TNxPXoi3FLUmSJElS39UQV9gMipU8kiRJkiRJO1iSxya5Osm3k5wxzfldk5zXnL8kyaLtHdMkjyRJkiRJ6r2qGti2NUlmAe9gYlbQIcDTkxwypdlzmFj/917AW4A3bu89MMkjSZIkSZK0Yz0Q+HZVfbdZw/dc4MQpbU4Ezm72PwI8euPDl7aVa/JIkiRJkqTeG7KnXt0NuHbS6x8CD9pcm6pan+QWYG/ghm0d1EoeSZIkSZKkFpKclmT5pO20qU2m6TY1CzWTNq1YySNJkiRJknpvkIU8VbUYWLyFJj8EDpr0+kDgus20+WGS2cCewI3bE5eVPJIkSZIkSTvWMuDeSe6RZBfgacD5U9qcD/xhs38S8JnazufAW8kjSZIkSZJ6bzvzIztUs8bOC4ALgVnA+6rqqiSvBpZX1fnAe4EPJvk2ExU8T9vecTNMN0Hd++LVq3r1CTFkC2uNpPvebf+uQ2ht9qx+FSmuXru+6xBa232W//d2tnWz5nQdQmsbxvv3eTG3+vX/78ePO6nrEFq748Nnb73RkLnHwvldh9DKNT/7edchtPZre+7RdQit/GLt2q5DaG3hbvO6DqG1vv0Md9vqNV2HsE3uvtee2/X0pmH2PzfdOrAfRu52l92H8j7263+RJEmSJEmSpuV0LUmSJEmS1Hvj2/dgqpFgJY8kSZIkSdIIsJJHkiRJkiT1nmsOW8kjSZIkSZI0EqzkkSRJkiRJvefTl63kkSRJkiRJGglW8kiSJEmSpN4bH7eSx0oeSZIkSZKkEWCSp2eSnJXkJdMcX5TkGV3EJEmSJElS16oGtw0rkzyjYxFgkkeSJEmSpDspkzxDIMn8JJ9KckWSK5OcnGRVkn2a88ckWTqpywOSfCbJt5I8tzn2BuDhSS5P8uIks5K8KcmyJCuSPG/Q70uSJEmSpEGpqoFtw8qFl4fDY4HrquoJAEn2BN64hfaHAw8G5gOXJfkUcAbwkqp6YnON04BbqurYJLsCX0pyUVV9b2e+EUmSJEmS1A0reYbDSuCEJG9M8vCqumUr7f+tqu6oqhuAzwIPnKbNY4BnJbkcuATYG7j3dBdLclqS5UmWn3/eP2/H25AkSZIkqRvj1MC2YWUlzxCoqmuSHA08Hnh9kouA9fwyCTd3apetvAYI8MKqunAG4y8GFgN88epVw/vZKkmSJEmSNstKniGQ5ADg9qo6B3gzcBSwCji6afLUKV1OTDI3yd7A8cAy4FZg90ltLgROTzKnGeM+SebvtDchSZIkSVKHXJPHSp5hcRjwpiTjwDrgdGAe8N4kZzIx3WqyrwKfAu4OvKaqrkvyU2B9kiuAJcBbmXji1qVJAvwUePIA3oskSZIkSeqASZ4h0Eypmm5a1X2maXvWZq6xDnj0lMNnNpskSZIkSRpxJnkkSZIkSVLvDfM0qkFxTR5JkiRJkqQRYCWPJEmSJEnqvXELeazkkSRJkiRJGgVW8kiSJEmSpN5zTR4reSRJkiRJkkaClTySJEmSJKn3rOSxkkeSJEmSJGkkWMmjTTzgB9/rOoR2xvqXp8ysWV2H0Mrs9au7DqG12fvv23UIrcy/8eauQ2jtFwcd2HUIre1+001dh9DOHgu6jqC1BT38XF6z18KuQ2jljg+f3XUIrc17+h92HUJrc/+lX/d5wdxduw6htT169lvI9T9f03UIrR18c8++7wHjq/v1c+eCu/Tre8j/2mvPriPYacat5LGSRxqkviV4JEmSJEn90bMcuiRJkiRJ0q+yksdKHkmSJEmSpJFgJY8kSZIkSeo9n65lJY8kSZIkSdJIsJJHkiRJkiT1nmvyWMkjSZIkSZI0EkzySJIkSZIkjQCna0mSJEmSpN5ztpaVPEMpyaIkV3YdhyRJkiRJ6g8reUZQktlVtb7rOCRJkiRJGhQfoW4lz06T5FlJViS5IskHkxyc5OLm2P9n777jJavr+4+/3ixlF2miqIhSRMpPkCZGRSwosaPysyDBiCWSqEn8aewlAY29xa6oAbtYI5hoVEQRsVEWFhRFBSvWICyd3f38/jjnyuxlbhncveecm9fz8ZjHnTnnzMx77s7OnfnM5/v9npxk+/a4Wyf5THvcOUkOaG9iSZL3JDk/yReTLGuP3znJF5KcmeTrSXZvtx+f5I1JTgFek+Qvkpye5Oz2527d/CYkSZIkSdJCsJNnPUiyB/Bi4J5V9fskWwPvBz5QVe9P8mTgLcAj259fq6pDkywBNgNuDuwCHF5VT03yceBRwIeAY4G/q6oLk9wNeAdwv/audwUOrqrVSbYA7l1Vq5IcDLyyvQ1JkiRJkhYdl1C3k2d9uR/wyar6PUBV/Q9wD+Aj7f4PAgeOHPvO9rjVVXVZu/2iqlrenj8T2DHJZsABwCeSLAfeDWw7cr+fqKrV7fkt2+POA94E7DFT2CRHJTkjyRnH/efnbvKDliRJkiRJ3bGTZ/0IMFcJca79146cXw0soynK/bGq9pnhOleOnH85cErbIbQj8NUZg1QdS9MhxMovnWLpU5IkSZI0OM7JYyfP+nIy8NgktwBoh2udDjyu3X8EcNrIsU9rj1vSDrMaq6ouBy5K8pj2+CTZe4bDtwR+2Z5/4k1/KJIkSZIkaQgs8qwHVXU+8Arga0nOAd4I/CPwpCTnAn8NPLM9/JnAQUlW0AzLmnFYVesI4Cnt7Z4PPGKG414LvCrJN4Alf87jkSRJkiSp76oW7tRXDtdaT6rq/TSTLY+635jjfsP4Qs2eI8e8fuT8RcCDxtzOE6dd/ibNRMxTXjqf3JIkSZIkaZgs8kiSJEmSpMFzdS2Ha0mSJEmSJC0KdvJIkiRJkqTBc3UtO3kkSZIkSZIWBTt5JEmSJEnS4Dknj508kiRJkiRJi4JFHkmSJEmSpEXA4VqSJEmSJGnwHK5lJ48kSZIkSdKiEJcY06hf/fGKQT0hhvb8vX7N6q4jTOx2a1Z1HWFiVy/dpOsIE7maJV1H+F9hGcP6/7fsqmu6jjCxqzdd2nUE9dDSlVd2HWFiFz/2yK4jTOSpBx/SdYSJnfDsJ3UdYSIv+NCJXUeY2Hse85ddR5jY0N7DrVydriPcJLfdarNhBp+HU7734wX7gHjQnXbu5e/RTh5JkiRJkqRFwDl5JEmSJEnS4A1tpMf6YCePJEmSJEnSImAnjyRJkiRJGrw1NvLYySNJkiRJkrQY2MkjSZIkSZIGzzl57OSRJEmSJElaFOzkkSRJkiRJg2cnj508kiRJkiRJi4JFng4kuWKO/VslefrI5dsm+WR7fp8kD7kJ93l0kudMnlaSJEmSpP5bQy3Yqa8s8vTTVsCfijxV9auqenR7cR9g4iKPJEmSJEla3CzydCjJZklOTnJWkhVJHtHuejWwc5LlSV6XZMck5yXZGHgZcFi777DpHTrtcTu251+c5AdJvgzstsAPT5IkSZKkBVNVC3bqKyde7tY1wKFVdXmSWwLfSnIi8AJgz6raB2CqaFNV1yX5Z2D/qvr7dt/R4244yV2AxwH70vw7nwWcuV4fjSRJkiRJ6oydPN0K8Mok5wJfBrYDbr2ObvtewGeq6qqquhw4ccYQyVFJzkhyxoeO//d1dPeSJEmSJGkh2cnTrSOAbYC7VNX1SS4Glk54G6tYu1g3ev159ZBV1bHAsQC/+uMV/e07kyRJkiRpBmv8NGsnT8e2BH7bFngOAnZot68ENp/hOtP3XQzsB5BkP2CndvupwKFJliXZHDhkHWeXJEmSJEk9YidPtz4MnJTkDGA5cAFAVf0hyTeSnAd8Hnj7yHVOAV6QZDnwKuBTwBPay98FftjexllJTmhv96fA1xfoMUmSJEmStODW2MpjkacLVbVZ+/P3wD1mOOavpm3as93+P8Bdp+17wAy38QrgFX9WWEmSJEmSNAgWeSRJkiRJ0uD1eWnzheKcPJIkSZIkSYuAnTySJEmSJGnw7OSxk0eSJEmSJGlRsJNHkiRJkiQN3hrs5LGTR5IkSZIkaRGwk0eSJEmSJA2ec/LYySNJkiRJkrQo2Mmjtdzysku7jjCRWrWq6wgTyZIlXUeY2Hev7zrB5DZftrrrCBPZ8mbLuo4wseuuH9bvGODCP17edYSJbLzh8F4vVl1+ddcRJrbxRsP7PQ/NZks36TrCxP724EO6jjCR93z5pK4jTOzSvz2s6wgTefn5Z3YdYWIrHnqfriNMbNXKa7qOMJHdt9my6wiaxkYeO3kkSZIkSZIWBTt5JEmSJEnS4K2xlcdOHkmSJEmSpMXAIo8kSZIkSdIi4HAtSZIkSZI0eC6hbiePJEmSJEnSomAnjyRJkiRJGjw7eezkkSRJkiRJWhTs5JEkSZIkSYPnEup28qwXSa5YD7f58CQvaM8/MsmdbsJtfDXJ/us6myRJkiRJ6p6dPANRVScCJ7YXHwl8Dvhed4kkSZIkSeoPO3ns5Fmv0nhdkvOSrEhyWLv9vm1XzSeTXJDkw0nS7ntIu+20JG9J8rl2+xOTvC3JAcDDgdclWZ5k59EOnSS3THJxe35Zko8lOTfJCcCyLn4PkiRJkiRp/bOTZ/36v8A+wN7ALYHvJjm13bcvsAfwK+AbwD2TnAG8G7h3VV2U5KPTb7CqTk9yIvC5qvokQFsfGudpwFVVtVeSvYCz1t1DkyRJkiSpP1xdy06e9e1A4KNVtbqqfgN8Dbhru+87VfWLqloDLAd2BHYHflJVF7XH3KjIM6F7Ax8CqKpzgXPHHZTkqCRnJDnjvR/58J95l5IkSZIkqQt28qxfM7bYANeOnF9N828x2/GzWcUNBbul0/bNWcqsqmOBYwGu++nPLX1KkiRJkgZnjZ9m7eRZz04FDkuyJMk2NJ0135nl+AuAOyTZsb182AzHrQQ2H7l8MXCX9vyjp93/EQBJ9gT2miC7JEmSJEkaEIs869dnaIZInQN8BXheVf16poOr6mrg6cAXkpwG/Aa4bMyhHwOem+TsJDsDrweeluR0mrl/prwT2CzJucDzmL3AJEmSJEnSYFXVgp36yuFa60FVbdb+LOC57Wl0/1eBr45c/vuR3adU1e7taltvB85ojzkeOL49/w3gTtPudrRL5yXtcVcDj/szH44kSZIkSRoAizz989QkRwIbA2fTrLYlSZIkSZJm0ecOm4VikadnqupNwJu6ziFJkiRJkobFOXkkSZIkSZIWATt5JEmSJEnS4K1xuJadPJIkSZIkSYuBnTySJEmSJGnwbOSxk0eSJEmSJGlRsJNHkiRJkiQNnkuoW+TRNL/YdLOuI0xkzZph/SfeYIN0HWFiey4d3svEdRts1HWEiWR4Tws2XrK66wgT22vbrbuOMJGrWdJ1hIktY3jPi2syrNe4665f1XWEiW0xrF8xACc8+0ldR5jIpX97WNcRJrbkMY/vOsJEXvmkp3YdYWKv2XrzriMsepcP7yUZAJ8Zi5vDtSRJkiRJ0uCtqVqw058rydZJvpTkwvbnzWc5doskv0zytrlu1yKPJEmSJEnSwnoBcHJV7QKc3F6eycuBr83nRi3ySJIkSZKkwauqBTutA48A3t+efz/wyHEHJbkLcGvgi/O5UYs8kiRJkiRJC+vWVXUJQPvzVtMPSLIB8AbgufO90QFOhSdJkiRJkrS2dTFXznwlOQo4amTTsVV17LRjvgzcZszVXzzPu3k68F9V9fPMc7UWizySJEmSJEkTaAs6x85xzMEz7UvymyTbVtUlSbYFfjvmsHsA90rydGAzYOMkV1TVjPP3WOSRJEmSJEmDt5CdPOvAicCRwKvbn5+dfkBVHTF1PskTgf1nK/CAc/JIkiRJkiQttFcDf5nkQuAv28sk2T/Je2/qjdrJI0mSJEmSBm8drXq1IKrqD8D9x2w/A/ibMduPB46f63bt5JEkSZIkSVoEelXkSbI6yfIk5yQ5K8kB0/Y/K8k1SbYc2XbfJJclOTvJBUleP7LviUl+197mBUmeNbLv6CTPac8nycLMbqsAACAASURBVEuSXJjkh0lOSbLHHFkvTrKizfrFJLcZ2bdvkkrywGnXuWLM7Ryd5JdtxqnTVvN4XJXk/iPbDm23Pbq9vHGSf0vy4/ZxfTbJ7Wb/F5AkSZIkSUPVqyIPcHVV7VNVewMvBF41bf/hwHeBQ6dt/3pV7QvsCzwsyT1H9p1QVfsA9wRenOT2Y+73GcABwN5VtWt7vycmWTpH3oParGcAL5qW87T253y8qX3cU6c/zuNxrZh2+48Dzhm5/Epgc2DXqtoF+A/g05nvumuSJEmSJA1I1cKd+qpvRZ5RWwCXTl1IsjPNkmEvYYbiSVVdDSwHthuz7w/Aj4Btx1z1+cA/VNVV7bFfBE4Hjhhz7DinAndscwZ4NPBE4AHzKBTNaYbH9XXgL5JslGSz9v6Xtxk2BZ4EPKuqVre3cRxwLXC/PzePJEmSJEnqn74VeZZNDa0C3gu8fGTf4cBHaYobuyW51fQrJ7k5sAtN0WX6vu2BpcC507ZvAdysqn487SpnALMO2RrxMJrOGmg6hi5qb++rwEPmcf1njQzVOmVM9nGPq4AvAw8EHkGz/NqUOwI/q6rLp93U2MeU5KgkZyQ546MfOH4ecSVJkiRJ6pc1VQt26qu+FXmmhmvtDjwI+MDI8KLHAR+rqjXAp4HHjFzvXknOBX4NfK6qfj2y77Ak5wM/Ad5cVdfMM0toCimzOSXJcpquo6mhZYcDH2vPf4z5DdkaHa510Mj22R7X1O0/rj19dB7Zx26vqmOrav+q2v/wJzxxHnElSZIkSVLf9HYJ9ar6ZpJbAtu0kxrvAnyprflsTFO0eXt7+Ner6mFJdgVOS/KZqlre7juhqv4+yT2A/0zy+dFiSVVdnuTKJHeoqp+MRNgP+NocMQ+qqt9PXUiyBHgU8PAkL6YpqtwiyeZVtfIm/Bpme1xU1XeS7ElTHPvhyHQ7PwJ2GHO/+wEn3YQckiRJkiT12pCWUF9f+tbJ8ydJdgeWAH+g6YY5uqp2bE+3BbZLssPodarqhzQdNc+ffntV9U3gg8Azx9zd64C3JFnW3vfBwIHARyaMfTBwTlXdvs25A/Ap4JET3s5aZntcNBNUv2ja8VcC7wfe2BaeSPIEYFPgK39OFkmSJEmS1E996+RZ1g5/gqYL5siqWp3kccCDpx37GZphSt+etv1dwHOS7DTm9l8DnJXkldO2vxW4ObAiyWqa4VGPaCc8nsThba5RnwKeRlNg2jTJL0b2vbH9+awkjx/ZPq4oNPZxVdXnZ8jyQuD1wA+TrAEuAA4tS5uSJEmSpEXIj7sQfwka9ZPfXTqoJ8SaNYOKywYbDG8F+22W9q0WPLfrNtio6wgTyfCeFly/anXXESa2adZ0HWEiV7Ok6wgTW8bwnhfXZFivcdddv6rrCBPbYli/YgCuqt42u4916ZVXdR1hYkse8/i5D+qRNz3pqV1HmNhrHvvAriMsepcP7yUZgO1uvvkA333Oz5v+82sL9gHxWQ+9Ty9/jwP8sytJkiRJkrS2Pq96tVAs8swhybeBTaZt/uuqWjHueEmSJEmSpC5Y5JlDVd2t6wySJEmSJGl29vH0eHUtSZIkSZIkzZ+dPJIkSZIkafCck8dOHkmSJEmSpEXBTh5JkiRJkjR4ZSePRR6tbZulPiW0tgt+d1nXESa2+bLpC+L1282WDisvwJIMrxH0e3/4Y9cRJrLJRsN7Pb72+lVdR5jYVjdb1nWEiSTpOsLEfnv5tV1HmNhb/vNrXUeYyMvPP7PrCBN75ZOe2nWEiTzruPd0HWFiFz3gwK4jTGz1mjVdR5jIDtts3XUE6UaG9y5dkiRJkiRJNzK8rwklSZIkSZKmWbPG4Vp28kiSJEmSJC0CdvJIkiRJkqTBc+JlO3kkSZIkSZIWBTt5JEmSJEnS4K2xk8dOHkmSJEmSpMXATh5JkiRJkjR49vHYySNJkiRJkrQo2MkjSZIkSZIGz9W1OuzkSbI6yfIk5yQ5K8kB0/Y/K8k1SbYc2XbfJJclOTvJBUleP7LviUl+197mBUmeNbLv6CTPac8nyUuSXJjkh0lOSbLHHFkvTrIiyblJvpZkhzGPY+r0gnb7Rkle3d7PeUm+k+TB7b4tk3wgyY/b0wemHmeSHZOcNybD8UkuGrmf05M8aeTydW3G5UlePXK9zyb55vz/ZSRJkiRJ0hB12clzdVXtA5DkgcCrgPuM7D8c+C5wKHD8yPavV9XDkiwDzk7ymar6RrvvhKr6+yS3AH6Q5JNV9fNp9/sM4ABg76q6KskDgBOT7FFV18yS96Cq+n2SY4CXAE+d/jimeTmwLbBnVV2b5NYjj+99wHlV9YT28R8DvBd4zCz3D/DcqvrktG3Htbdx8VTGqR1JtgL2A65IslNVXTTH7UuSJEmSNEiurtWfOXm2AC6dupBkZ2AzmmLK4eOuUFVXA8uB7cbs+wPwI5oiy3TPB/6hqq5qj/0icDpwxDyzfnPcfY5KsilNEegfqura9n5+U1UfT3JH4C40RaApLwP2bx/3uvQo4CTgY8Dj1vFtS5IkSZKkHumyyLNsamgVTRfLaNHjcOCjwNeB3ZLcavqVk9wc2AU4dcy+7YGlwLnTtm8B3KyqfjztKmcAsw7ZGvEg4D/GPI6p02HAHYGfVdXlY65/J2B5Va2e2tCeXz6PDK8buZ8PzyPr1O/xo8xQLANIclSSM5Kccdxxx83jZiVJkiRJ6peqWrBTX/VluNY9gA8k2bOa39bjgEOrak2ST9MMY3p7e717JTkX2A14dVX9euQ2D0tyULvvqXMMvxoV5l5t7ZR2yNVvaTqMbvQ4/nRjyV434b7mk2HccK3xd9JkvSNwWlVVklXt7/dG8/1U1bHAsQArV67s77NVkiRJkiTNqBfDtarqm8AtgW3aAskuwJfaeWYex9pdKF+vqr2AOwNPSzJaYDmhqvYA7gW8Icltpt3P5cCVSe4wLcJ+wPfmiHkQsANwPs3wqtn8CNg+yeZj9p0P7JvkT7/79vzewPfnuN1JHAbcHLio/T3uiEO2JEmSJEmL1JqqBTv1VS+KPEl2B5YAf6Ap6BxdVTu2p9sC242uaAVQVT+kmaz5+dNvry0afRB45pi7ex3wlnbiZpIcDBwIfGSunO08QP8PeEKSrWc57iqayZXfkmTj9n62TfL4qvoRcDZrdwO9BDir3beuHA48aOr3SDMPkEUeSZIkSZIWqT7MybMcOAE4sp2b5nHAZ6Yd+xnGFyjeBdw7yU5j9r0GeNKYbpq30qzatSLJD4CXAo9oCzhzqqpLaOa4ecb0xzFt+fKXAL8Dvtcuif4f7WWApwC7JvlRkh8Du7bbpuyW5Bcjp6lVt1437b42HpcxyY7A9sC3RnJfBFye5G7zeZySJEmSJA1J1cKd+qqzOXmqaskM229UsKmqZ49c/OrI9qu5YaWrixhZar2qfgVMDdc6emR7Ace0p/lm3XHa5X8YOT/T47gOeF57mr7vUuDxM1zvYmCjMbs+Md+M7W2MW3Vsv9luQ5IkSZIkDVcvhmtJkiRJkiTpz9Pl6lq9k+TbwCbTNv91Va3oIo8kSZIkSZqfPi9tvlAs8oyoKuerkSRJkiRJg2SRR5IkSZIkDV6flzZfKM7JI0mSJEmStAjYySNJkiRJkgbPTh47eSRJkiRJkhaFOPu0Rq1cudInhLTArttgo64jTGzjNdd3HWHRu5olXUeY2DJWdx1h0Rvi82LLX/2q6wgTW7L1Vl1HmMiKq67rOsLE7rj15l1HmMhFf7yy6wgTW3b4kV1HmNj273t71xEmko2GOTBm4zvsmK4zrC/P+/BJC/Z59rVHHNLL36OdPJIkSZIkSYvAMEuPkiRJkiRJIxypZCePJEmSJEnSomAnjyRJkiRJGrw1NvLYySNJkiRJkrQY2MkjSZIkSZIGzzl57OSRJEmSJElaFOzkkSRJkiRJg2cnj508kiRJkiRJi4JFngWWZMck501w/PFJHr0+M0mSJEmSpOFzuJYkSZIkSRq8NQ7XspOnIxsmeX+Sc5N8MsmmSf45yXeTnJfk2CSZfqUkd01yepJzknwnyeZJliY5LsmKJGcnOag99olJPp3kC0kuTPLahX+YkiRJkiRpoVjk6cZuwLFVtRdwOfB04G1Vddeq2hNYBjxs9ApJNgZOAJ5ZVXsDBwNXA88AqKo7A4cD70+ytL3aPsBhwJ2Bw5Lcfr0/MkmSJEmSOlBVC3bqK4s83fh5VX2jPf8h4EDgoCTfTrICuB+wx7Tr7AZcUlXfBaiqy6tqVXvdD7bbLgB+CuzaXufkqrqsqq4BvgfsMC5MkqOSnJHkjOOOO27dPUpJkiRJkrRgnJOnG9PLfgW8A9i/qn6e5Ghg6bRjMuZ6U9tncu3I+dXM8O9dVccCxwKsXLmyvyVJSZIkSZJmsMZPs3bydGT7JPdozx8OnNae/32SzYBxq2ldANw2yV0B2vl4NgROBY5ot+0KbA/8YH2GlyRJkiRJ/WMnTze+DxyZ5N3AhcA7gZsDK4CLge9Ov0JVXZfkMOCtSZbRzMdzME0H0LvaYV6rgCdW1bVj5m2WJEmSJGnRWlNruo7QOYs8C6yqLgbuNGbXS9rT9OOfOHL+u8Ddx1z3idM3VNXxwPEjlx82/RhJkiRJkrR4WOSRJEmSJEmD1+NFrxaMc/JIkiRJkiQtAnbySJIkSZKkwStbeezkkSRJkiRJWgzs5JEkSZIkSYO3xk4eO3kkSZIkSZIWAzt5JEmSJEnS4Dknj508kiRJkiRJi4KdPFrL0suv6DrCRK7ZYrOuIyx6G178s64jTGzJ5pt3HWEiG65c2XWEiS3ZcsuuI0ysrr226wgT2WSjjbqOMLHrL/l11xEmtmbP/9N1hIlsuGR438+tueaariNM7Lqlm3QdYSKrVg7vdzw0O211M370P8P6e739+97edYSJ/ewpz+g6wkSWnvSJriPcJLfvOoDWK4s8kiRJkjSLoRV4pP+tHK7lcC1JkiRJkqRFwU4eSZIkSZI0eGts5LGTR5IkSZIkaTGwk0eSJEmSJA2ec/LYySNJkiRJkrQo2MkjSZIkSZIGbw128tjJI0mSJEmStAjYySNJkiRJkgbPOXns5JEkSZIkSVoU7ORZAEm2Av6qqt7RdRZJkiRJkhajNWvs5LGTZ2FsBTx9vgenscG0bUvWeSpJkiRJkrRo2MmzMF4N7JxkOfAl4LfAY4FNgM9U1b8k2RH4PHAKcA/gkUnOB94IPBD4pyT3Aw4BlgGnA38LbAv818h93Rm4A7AX8BJgY+APwBFV9Zv1+zAlSZIkSeqGc/LYybNQXgD8uKr2oSny7AL8BbAPcJck926P2w34QFXtW1U/BW4GnFdVd6uq04C3VdVdq2pPmkLPw6rqV1W1T3vb7wE+1V73NODuVbUv8DHgeQv4eCVJkiRJ0gKzyLPwHtCezgbOAnanKfoA/LSqvjVy7GrgUyOXD0ry7SQrgPsBe0ztSHJP4G+AJ7ebbgf8d3vsc0ePnS7JUUnOSHLGez/0oT/rwUmSJEmS1IU1tXCnvnK41sIL8KqqevdaG5vhWldOO/aaqlrd7l8KvAPYv6p+nuRoYGm7b1vgfcDDq+qK9rpvBd5YVScmuS9w9EyBqupY4FiA6395SY+frpIkSZIkaSZ28iyMlcDm7fn/Bp6cZDOAJNsludU8bmNp+/P37XUf3V5/I+DjwPOr6ocjx28J/LI9f+SfmV+SJEmSJPWcnTwLoKr+kOQbSc6jmVz5I8A3kwBcATyeZmjWbLfxxyTvAVYAFwPfbXcdANwVOCbJMe22h9B07nwiyS+BbwE7rcvHJEmSJElSnzjxskWeBVNVfzVt05vHHLbntOtsNu3yS2hWzJpu6Zhtn21PkiRJkiTpfwGLPJIkSZIkafAKO3mck0eSJEmSJGkRsJNHkiRJkiQN3hrn5LGTR5IkSZIkaTGwk0eSJEmSJA2eq2vZySNJkiRJkrQo2MkjSZIkSZIGb42NPHbySJIkSZIkLQZ28mgt1174464jTCRr1nQdYSKrLv1j1xEmdsG++3UdYWKrVw3rebHpVrfoOsLEfnvZFV1HmNgtt7hZ1xEmsmr1sJ7HABvfbvuuI0zstz/9TdcRJrLrbbfpOsLENrv5Vl1HmNilq9N1hInsvs2WXUeY2OWruk4wmR222brrCBPLr6/rOsLElp70ia4jTOSaQx7TdYSb5rT/7jrBeuOcPHbySJIkSZIkLQp28kiSJEmSpMGzk8dOHkmSJEmSpEXBTh5JkiRJkjR4a+zksZNHkiRJkiRpMbDII0mSJEmStAg4XEuSJEmSJA2ew7Xs5JEkSZIkSVoU7OSRJEmSJEmD5xLqdvKsM0muWM+3f3SS56zP+5AkSZIkSetfkq2TfCnJhe3Pm89w3GuTnJ/k+0nekiSz3a5FnkUqiV1akiRJkqT/NaoW7rQOvAA4uap2AU5uL68lyQHAPYG9gD2BuwL3me1GLfKsY0k2S3JykrOSrEjyiHb7a5I8feS4o5P800zHt8e8OMkPknwZ2G1k+85JvpDkzCRfT7J7u/34JG9McgrwmrYy+B9Jzk3yrSR7LdxvQpIkSZIkzeARwPvb8+8HHjnmmAKWAhsDmwAbAb+Z7Ubt9lj3rgEOrarLk9wS+FaSE4GPAf8GvKM97rHAg2Y5fj/gccC+NP9OZwFnttc9Fvi7qrowyd3a27xfu29X4OCqWp3krcDZVfXIJPcDPgDss14fvSRJkiRJHRjY6lq3rqpLAKrqkiS3mn5AVX2zbeK4BAjwtqr6/mw3apFn3QvwyiT3BtYA29H8452d5FZJbgtsA1xaVT9LstG444F7AZ+pqqsA2sIPSTYDDgA+MTIUb5OR+/9EVa1uzx8IPAqgqr6S5BZJtqyqy9YKnBwFHAXw5mc/lycf8vB1+fuQJEmSJGlRGf0c3Tq2qo6ddsyXgduMufqL53kfdwT+D3C7dtOXkty7qk6d6ToWeda9I2iKOHepquuTXEzTXgXwSeDRNP/IH5vH8ePKkBsAf6yqmTpyrhw5P25CphvdZvtEPBbgiq+eNqjSpyRJkiRJsLCra41+jp7lmINn2pfkN0m2bbt4tgV+O+awQ4FvVdUV7XU+D9wdmLHI45w8696WwG/bgs1BwA4j+z5GMwTr0TQFn9mOPxU4NMmyJJsDhwBU1eXARUkeA5DG3jNkOZWmiESS+wK/b68vSZIkSZK6cyJwZHv+SOCzY475GXCfJBu2o4DuAzhca4F9GDgpyRnAcuCCqR1VdX5bsPnl1Ni7mY6vqrOSnNBu+ynw9ZH7OAJ4Z5KX0Ey89DHgnDFZjgaOS3IucBU3PIEkSZIkSVpUBjYnz6uBjyd5Ck0xZ6qRY3+aOXj/hqY55H7ACppROV+oqpNmu1GLPOtIVW3W/vw9cI9ZjrvztMszHl9VrwBeMWb7RTSTNk/f/sRpl/+HZsZuSZIkSZLUE1X1B+D+Y7afAfxNe3418LeT3K5FHkmSJEmSNHgLOSdPXzknjyRJkiRJ0iJgJ48kSZIkSRo8G3ns5JEkSZIkSVoULPJIkiRJkiQtAg7XkiRJkiRJgzewJdTXCzt5JEmSJEmSFgE7eSRJkiRJ0uC5hDrEX4IWQpKjqurYrnNMYmiZh5YXzLwQhpYXzLwQhpYXhpd5aHnBzAthaHnBzAthaHnBzAthaHnVHw7X0kI5qusAN8HQMg8tL5h5IQwtL5h5IQwtLwwv89DygpkXwtDygpkXwtDygpkXwtDyqics8kiSJEmSJC0CFnkkSZIkSZIWAYs8WihDHE86tMxDywtmXghDywtmXghDywvDyzy0vGDmhTC0vGDmhTC0vGDmhTC0vOoJJ16WJEmSJElaBOzkkSRJkiRJWgQs8kiSJEmSJC0CFnkkSZL+DEk2SPLYrnNIkiQ5J4/WmyQbVdX107bdsqp+31Um9UOSmwO7AEuntlXVqd0lUteSfAr4d+DzVbWm6zzSpJKcWlX37jrHTZFkB2CXqvpykmXAhlW1sutcWnhJ9pttf1WdtVBZJpXkIGAPoIDvVdUpHUe6SZLctaq+23WOmSTZDtgB2HBqm+/h1r0kmwNVVVd0nUXDY5FH61z7R/aDwCbA2cBRVXVxu++sqpr1DURXkjwQuB1w8lTedvuTq+rfOws2gyTPBI4DVgLvBfYFXlBVX+w02ByS/A3wTJrf9XLg7sA3q+p+nQabQZLHAF+oqpVJXgLsB/xrz9/o3g54K3AgsAY4DXhmVf2i02CzSHIw8CSa58MngOOr6oJuU80syRLgocCOrP1G941dZZrLEDMDJHkozQe30aLwy7pLNF6SlwJXAycAV05tr6r/6SzUPCR5KnAUsHVV7ZxkF+BdVXX/jqON1eZ7FXAn1n5O3KGzUDNI8uzZ9vfx/16SqcLIUmB/4BwgwF7At6vqwK6yzaQtOnwauAY4kybvfsAy4NCq+mWH8eYlyZ2AxwGHA5dV1f4dRxoryWuAw4DvAavbzVVVD+8u1cySbAM8nxu/XvTyPSdAkjsDHwC2pnku/w44sqrO6zSYBsXhWlofXgs8sKq2oVn670tJ7t7uS3exZpbklcCLgTsDJyf5h5Hdf99Nqjk9uaouBx4AbEPzAfnV3Uaal2cCdwV+WlUH0RSnftdtpFm9tC3wHAg8EHg/8M6OM83lOOBEYFtgO+CkdltvVdWXq+oImjfmF9O8bpye5ElJNuo23VgnAU8EbgFsPnLqs8FlTvIumg8U/0Dz9+MxNN8g99GTgWcAp9J80DwTOKPTRPPzDOCewOUAVXUhcKtOE83uOJrX4FXAQTQfhj7YaaKZTf0f2x94Gs3r8XbA39F86Oydqjqo/dv8U2C/qtq/qu5C87f6R92mm9HbgHdW1X2q6tlV9ayquk+7/R0dZ5tRkh2SvCDJOTTP4acDf9nXAk/rkcBuVfWQqjqkPfWywNP6MPB9YCfgGJr3F73tkmq9G3h2Ve1QVdsD/4RLqWtCG859iDSxjavqfICq+mSS7wOfTvICmhbaPjoE2LeqViU5GvhIkjtU1bPoaWGKG3I9BDiuqs5J0teso66pqmuSkGSTqrogyW5dh5rF1DdVD6V5E/nZ9jnSZ9tU1WhR5/gk/6+zNPOU5BbA44G/pukC/DBNN9KRwH27SzbW7apqr65DTGiImQ+oqr2SnFtVxyR5A8039r1TVTt1neEmuraqrpv685FkQ/r7txpgWVWdnCRV9VPg6CRfB/6l62DTVdUxAEm+SFMwWdlePpqmY7HPdq+qFVMXquq8JPt0GWgWd6qqQ6dvrKoPJHlxF4HmkuR0YEvgY8Cjq+rCJBeNdpL31E+AjYBruw4yT7eoqvcleWZVfQ34WpKvdR1qDjcbHWpYVV9NcrMuA2l4LPJofbg+yW2q6tcAVXV+kvsDnwN27jbajDasqlUAVfXHJIcAxyb5BLBxt9FmdGb7xnEn4IXt2N0hzGXyiyRbAf9B061xKfCrjjPN5pdJ3g0cDLwmySb0vwvy90keD3y0vXw48IcO88wpyaeB3Wm+zTykqi5pd52QpI/dEJ9P8oC+D4+cZoiZr25/XpXktjTP494WU5LsyY2HBXygu0Tz8rUkLwKWJflLmm6CkzrONJtrkmwAXJjk74Ff0u/OI4DtgetGLl9HM2yyz76f5L3Ah2iKfo+n6YjooyXjNrbPk7H7euB3NMPWb03TjX0h/S6uTrkKWJ7kZEYKPVX1j91FmtXU3KCXtEN/f0Xze++zn7TDf6c6FB8PXNRhHg2Qc/JonWvn1vhdVZ0zbftWwDOq6hXdJJtZks8Br2ur/KPb/xV4UVX17kN9++ZlH+AnbWHqFsB2VXVux9HmLcl9aL7J+vz0Sbr7IsmmwIOAFe03bdsCd+7zB+Uk29O0qd+D5k3j6TRz8vy002AzaJ/LL+njPCszSXIozYefDWjeRIZmXoItOg02i4FmfinN/FL3B95O83x+b1W9tNNgYyT5F5qOszsB/wU8GDitqh7dZa65tP//nkIz9DfAf1fVe7pNNbMkd6UpNmwFvBzYgubv97c6DTaLtpvkscBnaJ7DhwIfr6pXdhpsFkmW0gwxm5pM/FSabtZruks1XpI3AZsB/6+qrmy33Qx4E033cC8LEEm2BB5F80XMHWme0w+squ90GmwWSY4ct72q3r/QWeYjycOArwO3p/lbsgVwTFWd2GmwWbSLkxxD08kMzf+9Y6rq0u5SaWgs8khAu5oIVXX1mH3b9XHSvnZo1hHAHarqZe0H+9v0+c0BQJIPVtVfz7WtT9r5eHapquPaSfw2qyq/VVmHknyzqu7RdY75SvITmrkJVtRA/pAOMfOototuaVVd1nWWcZKsAPYGzq6qvZPcmqYgdUjH0WbVDmN481zb+qCdPPzVVfXcrrNMKs2qVfdqL55aVWd3mWcxaedtexXNnGNTX2ZsTzOH3ouq6roZrtobSW5FM//Y4cDtq+r2HUeaUZKNgV3biz/o65d0AEluX1U/n7btT6MN+mbIr3HqF4s8Wm/a6vnLuWGZxd5/awyQZC9uvPpM7+aASPJOmuFZ96uq/9NW/r9YVXftONqsMm2FtfYP2oqq6uUklO238/vTTDS4aztk5BNVdc+Oo91IkudV1WuTvJUxbd99/TYTIMkxwLnAp4dQgEjy38CDa0DLvQ8pc5L/O9v+nr4mf6eq/iLJmTQTAq8EzquqPTqONqvpr8nttrOrat+uMs0myVeA+w/hdWJK+yXMjVTVzxY6y3wluYjxf0d6t4rZlPYLuzvSvN/8UVVd1XGkGSV5ZVW9aIZ9O/S48/a+NMWzi2l+z7enWfmpl0uoJ1lFM//VU6aeD+Ne8/okyVeqx6t/aRick0fr078B/5cBfWuc5N9plgk9nxvmtyn6OdHn3apqvyRnA1TVpe23K72U5IXA1LwPl3PDxNHX0e9VAw6lWVXkLICq+lU7/1EfTc2X0Mc5bObybOBmwKokc2PpvwAAIABJREFU19D/ovAlwFeTfJ615yXo3ZLII4aUebbul76+Jp/RDkt+D83KWlcAve2sTHI48FfATklGhy5sQb/n8Dob+Gw7Z97oUvV9fE5M+U9uKJgso5lX6gdAnwuAoys8LaVZ2W7rjrLMaoai8B3TTibe0+fGg2jeE91IXws8rTcAD6iqHwAk2ZVm/r+7dJpqZitohmt9Pcljq+rH9HdBlSlnt6/JQ3qNU89Y5NH69HOabzEHUeBp3b2vHSVjXN92wRRAO4yot9/QV9WrgFcleVVVvbDrPBO4rqoqydTvubcrHFTVSe3PP42Nb+fb2KyqLu8s2DxUVV8LZzO5qD1tTH8nZ59uMJmr6kldZ5hUVT29PfuuJF8Atuj5HGmn0xT+bknzwW3KSpquur7amqYINfpNd18LfwBU1Z1HL7dDt/62ozjzUlXTC33/luQ04J+7yDOHTwLL2xOs/SG+r8+NJW0H9tiCQ1X9zwLnma+Npgo8AFX1w3a4XF9VVb0jzTL1JyV5Pv2f4Hpwr3HqH4drab1pJ0d8OfA1+v+tMQBJ3ge8oaq+13WWuSQ5gmb89n40rbOPBl5aVR/vNNgc2qLDXwE7VdXLk9we2LavcwkleQ6wC/CXNGP+nwx8pKre2mmwWST5CPB3NMu/n0kzufUbq+p1nQYbo/2wM6OqOmuhsqg/kjx7tv19/TuSZDtuGKIMQF+HMYxKchvgL2g+SHy3r/NVLCYDGDIymm0Dms6ep1XV3h1FmlE7qfxhNEO1Pgt8tKp+1G2q2SW5lmZluHFFnurrsLi24724YeWnI2hWqO1lYX506Gm7cMYJwP5VtWm3yaT1yyKP1ps0y3tfQdMq+acOk6o6prNQc0hyb5qlY39NU5iaGjKyV6fBZpBkd5pVZwKcXFV9Xd70T4Y4l1CaZYVHV575UseRZpVkeVXt0xYC7wI8Hzizj8/jJKe0Z5fSfIg4h+b3vBfw7ao6cKbrdqnNPW6+it6Oox9S5nYurBn18e9IktfQfND8Hk2BFZq/Hw/vLtXckjwF+BfgKzT/9+4DvKyq/r3TYDNoh4e8E7h1Ve3ZzqP38Kr6146jzWha0XIDmi9nblFVD+wo0pxGXpsBVtF0Ab5htIujb9pO20fQ/D+8BfDimrZqal/0ed6r2bQT4D+DZuWn0Kz89I6qunbWK3YkybZVdcnI5Q2BA/pcfB/ia5z6x+FaWp+2rqoHdB1iQv8O/DXTClN9NLIi1QVjtvXZoOYSAmiLOr0u7EyzUds+/UjgbVV1/dRws76pqoMAknwMOKqqVrSX9wSe02W2OYxmW0qzDO6qjrLM12Ay97GIMw+PpJmgvZcfdmbxPGDfqeE5SW5BM5Srl0UemjmPngu8G6Cqzm27F/v8AWh0OOoqmjl6PtVRlvl6SlX9ZHRDkp26CjNP1wCXAZfTrK61tNs4i9KGwJunuinbaQM26TbSzKrqkiQPpZn/avT50NsiD8N8jVPPWOTR+vTlJA+oqi92HWQCP6uqE+c+rBfWmrCx/UPb14nvRg1iLqEkp1XVgUlWsnb3Q98nBIbmjcHFNF0xpybZgeZNb5/tPlXgAaiq85Ls02Wg2VTVmdM2fSNJL78xnjKkzANdKe4nwEaMDE8eiF/QzMMzZSXNnHp9tWlVfWdqUt1WL4uVI75XVZ8Y3ZDkMTQTq/bVJ2k6jqZv6937jCQH0Sw9/hfAl2mKEH1fgODNM+1IsmFV9fU5fTJwME2nPjQTiX8ROKCzRLNI8i5gU5oVD99LM7VBL6cHGDHE1zj1jEUerU/PAJ7Xjju+nmF8OL6grZafxNrzCPVmsrMBr1I15S3AZ4BbJXkFzR/cl3Qb6camhgkNcEJgquotNL/nKT9t3wT32feTvBf4EM2H+sdzw2phvZNkdJWZqfkqbtNRnHkZk/ku9DfzEFeKuwpYnuRk1v770ceC1OgQol8C307yWZr/e4+g3x+Cfp9kZ274ouDRNBNI99kLuXFBZ9y2zrXDwPcAtpy2atUW9Lcz5mSaycJPo+kqeUKSJ0zt7On/wb8BjoexXdjf4cYFtr5YWlVTBR6q6ookfZ7f5oCq2ivJuVV1TJI30P8JjIf4Gqeescij9WauD8dJ9qiq8xcqzzwto3lzPjrMrFcz2g94lSoAqurDSc7khrmEHtnnuYTGDYEbwrC4GdqTX9ZRnPl4EvA04Jnt5VNpxqT31Zk0rw2hKWJfDDyly0DzMJp5ao6NXmauqpPajr89q+q5XeeZpxPb01BM/Y3+cXua8tkOskziGTRfaOye5Jc0z+PHdxtpvCQPBh4CbJdktPC+Bf39Zn434GHAVsAhI9tXAk/tJNHcejnp7xxGV+rcY9q+Pi/xfWWS/aYWRUhyF+DqjjPN5pr251VJbkuzalXfhx0O5jVO/eXEy+pM31eWGCfJC9siSy8MaSWXaV0EN9LX5UKnP0/bSfvOrao7dRhrVjO1J1dVLz/QD1GSxwJfqKrLk7yU5lvXl7sa2LqV5Ct9nBh6JkmWAdv3eXLaxaKdZHeDqlo558EdSbI3sA9NgX106fGVwClVdWknweYhyT2q6ptd5/hzJdmhqn7adY7pRt9bjHmf0dv3x2lWzv0Y8Kt207bAYWOGA/dC+/f5rTRfLL6d5ouO91TVP896xR4Ywmuc+ssijzozxJUF+vSHN8mrgccxkJVcklzEDV0EU6Yu92650NFhcTTDMKDJeh1wbJ+7qNq25L1Gfm4GfLrPE6EnuSdwNDcuWvbqeTFl5Hd7IPBK4A3Ai6rqbh1Hu5Ek96uqr0wbevEnfRqOOl3bWr8LzbCWK6e29zFzkkOA1wMbV9VO7ZxSL+vra/KUIa26Bn9a3edRwI6s/VrR207Fns+xspaBzodFknsA2wGnVtVv2xWJXgDcq6pu3226G0vyE+CfaIbOvo4bJsYP8Nqq2rmrbHNpF3bYjSbrBVV1fceRxkqyAXD3qjq9vbwJzXCzy7pNNl7WXoXvRqYmu5bmw+Fa6tIQK4x9aqE9lAGt5FJVfW+PXcvAh8VNtU4PqT35fcCzaIYUrZ7j2D6YyvhQ4F1V9dkkR3eYZzb3oVke+5Ax+3o1HHWMrWmev6MFh75mPppm4tevAlTV8gGsRgQDWnWt9VmaFZTOpOeTXCf5eFU9Fjh73AqHVbVXB7HmMrj5sJK8jmaI2XLg+Uk+BzydpgD/5C6zzeJrwMNHzo++PveuI3umLwmAXZL0svBeVWvaLwru0V6+ln6/ZkwNod0NuCs3DP89hB4+J9RvFnmkyfSpMDWolVyS7F5VFyQZ2wnVt2EuU3mBT4zL3Le803wuyVY03w6eRfO8fW+3keZ0WVV9vusQE/hlknfTrDLymvYbwg06zjRWVf1L+43m56vq413nma92Tp5zq+pNXWeZp1VVddm0FVH69DdjrCGtuta6XVU9qOsQ8zQ1x9jDOk0xgao6qf35/q6zTOChwL5VdU2Sm9MMJdqrqi7sONeMqmrGeYSSPGohs8zTuC8JpvS18A7wxfb3+enq+fCVqjoGIMkXgf2mhmm1XyD1bpJ29ZvDtdSZJN+qqrt3nWMSfRpiluRTwN40q0oMYSWXY6vqqDFDA6aGa/VqaMC0vNP1Lu9M+t6ePKUdfriE5o3i6PO5l8W0djWRBwErqurCJNsCd66qL3YcbUZJTq2qe3edYxJJTqmqvq8MB0CS99G8Hr+AphvmH4GNqurvOg02hxlWintzVe3WUaRZJTkWeGtVreg6y3wleU1VPX+ubX2S5CRuXKS8jKbD591Vdc2Nr9WNJGdW1V1GLi+vqn26zPTnSPKzqtq+6xyLQZKVNJNcr6KZhLn3K/0muQDYe6pTv30fd05V7d5tMg2JRR6tV0OaGHg+kryoql7ZdQ6AJEeO2973b9/aiUmfDhxI8wby68A7+/SGcTFIcgA3nrPiA50FmsPQi2lD0E5AeTVwAmvPb9PLSc8BkrwC2JIbZ+5d8a8t/L2YG1Zn/G/gX/v+2jZtvrSpleJeVlWndZlruiQraHJuSDNP009oCsJTH9r6OPQJGD+f39S8Xl1lmkuSNwPbAB9tNx0G/JpmnrotqkcrTCb5I2sPZ7n36OW+z4s1XZKf93EeoSnjVu/s45xYadoqb19VP+s6yySSvBh4LPAZmte8Q4GP9+Xzh4bBIo/WmySvoXlTMIiJgQGSbEOzROiOrP3huJdjuoe4kkuSjwOXAx9uNx0ObNXOW9BLAyyYfBDYmWZ+gtH/e73s8tLCaD/MT9e7Sc9HDaX41w4te3UNZ7n3PxnKSnFJdphtf/VzBaWn0XypcQfWXqZ+c+AbVdXbZZHHdf5NbUtyflVNX/a7M0nuM9v+qurz8MMb6XMnTwa2euf0Lq+hSLM0/YHtxVOr6uwu82h4LPJovUnyA5ox0YOYMwYgyek0nSVrTf5aVZ/qLNQMBrySyzlVtfdc2/piiAWTJN8H7tT38eejkoxdzrSP3w5K42Rgy71PGdJKcQBJ7g6cPzJfxeY0r3ff7jbZjSXZErg58CqaYXxTVva5gw7+9HfkgVNdEEm2pykG3qlPQ9cBkmxRVZfPsG/7PnZyjHSm3WgXsGtVbbLAkeYlA1u9M8nbgeOr6rtdZ5lUkluxdrdU757H6i8nXtb6NKiJgVub9nmM/DRHM8yVXM5Ocveq+hZAkrsB3+g402z2Z2AFE+A84DbAJV0HmcCVI+eX0kxU+v0ZjtVNlGRP4E6s/caxt11pMJyhATSvbScygOXepxnSSnEA76TpNppy5ZhtvdDOhXYZTcfq6Ie2zZJs1vMPbf8EnJbkxzSFh52Apye5GdC3YeFfpf33T3JyVd1/ZN9/0MPnBgOajHuaoa3eeRDwd0kupnmtGMLwzofTFNtvC/wW2B64gObvoDQvFnm0Pl0FLE8yiImBW59L8pCq+q+ug8zDIFdyAe4GPCHJ1Jvb7YHvT32r1cM/vEMsmNwS+F6S77D2/73ednlV1RtGLyd5PTcsH6p1IMm/APelKfL8F/Bg4DSgt0WemYYGdBpqZkNa7n3UYFaKa2W06F7NMsm9fj/bdt6+kRs+tO1AU8Tu7Ye2qvqvJLsAu9N8ML5gZH6pf+su2Vijb4S2nmVfb0wNL2y/nNuD5rXi+1X1k06DzW1q9c7X0nS9Q79X73xw1wFugpcDdwe+XFX7JjmItlAszVev/yhq8E5keB/Sngm8KMm1NBNQ9nkW/vOS/BWwpH0j9o//v707j7arrs8//n6CzAYEIaIoY1FkklFBFAqan/pDFEQwiloV54GpDoiwFBS1VaiCXQi1tYpFHCqKrTIpBidAIGESrIjiTFCkRAQJ4ekf333g5HLPHeCefPc+eV5r3XX33ieBJ1k39+7z2d/v5wP8oHKmqejK6NuezhVMKKu8um4NSh+LmDkvpkzkW2D71ZIeQ7tvzgGe3rc14DhJJ9LeosmnbC+zKlHS7rXCTMNBlO/LH7V9ezMprs29hW6SdChl9Q6Unjdtf2P8Abr5pm0nHuhHt52ktq7884Dj8c5bQdJalO+/O1O2gwt4iqQrgEMGbT9rgY8CbwKeCfyQZnhG1UQTsH1zsxV1C9ufbnpvPrJ2rkkssf1HSbMkzbJ9UdPnNGLKUuSJoWn7lKfx2J5dO8M0vI0yyeWvlOkX51Gq/63WxuaYk3hf7QDT1Wsy2dxEduL7/Jj+BCtRprq0cUtOl93VrHq4t/naWET7C2ld2hpwCg/eFjLetVax/Rf6Cme2f0e7Vy6+ETgZOKY5vxB4fb04U9K5N22D+tHRzpV/cyQdSSmU9I5pztevF2tCJ1MGk8yzfR/cPw3qWOATwCsrZpvIZ4DFlPxQipWfpRSLW6dZwboz8CTg05Q2Ep8D2lyAv73pdXQx8B+SFlFGwEdMWSdu/qNbJH3R9kGDmsq1cDsOkra0fYOkcW/G2zZlBO6/MX9P8xFDYnt+M9VlC9sXqoxJXql2rolIej2l4HcXcB/NijTa/Ya+vz/BvcAttnNTM7Mub5bZ/wtlmf2fae/Wp57Wbw2QtBvwdGD9vjeXAGvR8u8VXWR7ETCvdo5p6uKbti71o/sXysSyscfQsu8XfXa3/ar+C83f9fGSflon0pQ8acygjIskXVUtzeT2B3YArgSw/dumWXubvZBy/3YEcDCwNnnoFdOUIk8Mw2HN5y41lTuS8iTwxHFeM8v2WKhK0sdsHy7p64xfRGvzNqLOkfQ6ytfGupSnmhsCnwSeNdHvq+wdwNa2/1A7yFT19SfoNSZ9XLM1oM2NSTvF9pubw09KOhdYy/bVNTNNQRe2BqxCWf7/CJZ9c3kHZYtczCBJj6eskNqd8jPwe8Bhtn9dNdjEXgjcTbfetHWmH53t4wa9Junw5ZllGlrZK2gKujY84x7blmSApnF4270e+FLzPa1zuyKiHTJCPaqR9EPbu9XOMR2S5tq+oHKGnWxfIWnP8V7vbdWJmSFpIWWK2aW9kbGSrrG9bd1kgzVv4F/UrPbqhHGmSWxMaULZ2sakXTFohWJPG1cq9kj6ImVrwOeaSy8FHmW7dVsDJG3cV6ycBTyyxX01OkvSBcCZwBnNpZcDB9ueWy/V6JF0EbA9ZbVfV/rRPYikX9reqHaOsSR9BvgZ8P7+1VKSjqWMUH9FtXDj6FudvzJl69Mvm/ONgR/b3qZivIEkvR3YApgLfAh4DXCm7VOqBptAs8XsIOA24Czgy7ZvqZsquiZFnqhG0oLem+aukHSl7db0V5C0CmXyhYGf2L6ncqSRI+lS20/rfb02U1yubOO2wx5JO1D2nl9KRybbNcu992ZMY1Lbbe+10XrNm7VBbLs1KxXHknTVmK0B415rA0lnUvrFLKVsLVsbOMn2R6oGGzGSFtrefrJrbSBpMeM3/m3zUAcARuVBkqRf2X5C7RxjNX3R/pXSs2sh5etkB2AB8Frbt1eM9yDNtvWB2tpvsel9dSHw/yj/7s4Dnm37XVWDTYGk7YCXAAcAv7b97MqRokOyXStq6mKFsTXLayXtQ9k29DNKrk0lvcH2N+smGznzJR0NrC5pLmWSy9crZ5rMacC3gWsoPXm6oHONSbvC9l61MzwMXdoasJXtOyQdTBlR/y5KsSdFnpn1B0kvpwwcgLK6648V8wzUsWEOy2j60T0G2KW5dFnTD6lrWnmv2azyO1DS5sBWlPu4d9n+Wd1k42trEWcK5jYFnftX4TdTGltf5KGsav495fvbnMpZomNS5ImYnjbdLJwI7GX7RoDmRuG/gRR5ZtZRwCGUgskbKG/e2trIsede20dO/stapYuNSTtF0sqU/jZ7NJe+A5xme0m1UJN7GvBKSb3eTBsB1/e2DrRsRd3Kzd/xfsAnbC/p9YGIGfUayvShf6L8TP4B8OqqiUaQpIMoBcrvUAoQp0h6h+0vVw02jklWTK2xnONMiaTnALObv8+f9V0/GFhUuzVA10l6E+Wh3GaS+nvPzaa9DwqA+7O/hDIZ7svA62z/uG6q6Jps14pqsl3r4ZF0se09+s4FzO+/FismSScAN1NWHPVv17qtWqhJNM0Q76bclPcak/6H7VY+oe8iSZ+i9FPoNXJ8BbDU9mvrpZpYl7YISDqU8nT4KmAfSkHqc7afWTXYiGl6mRxu+0/N+brAR22/pm6y0dJsoZ3bW70jaX3KdtrWbZXsIkmXAPvavnXM9Q2As7vWs7JtJK0NrEPpw3NU30uL23wvBCDpw8BZthfWzhLdlSJPVCNpG9vX1s4xHZK+YvtFlTP0/v9zKQ3vvkh5gnUgpS/P39fKNookPZ8yjnxjyurHLvRS+Pk4l227zSPUY8i61N9mVEh6hO2sSJtB4z0g6uJDo7YbO2CgaSZ+VZuHDvRrHhzsB7zM9j6184wl6epBKxEnei1WHH3TRgEybTSmJdu1YsZNtdFgmwo8fYWTcdn+SvO5aoGnsW/f8S1ArznirZSnFjGzPga8CLjGHamK2960doap6nJj0g5aKmnzXs8HSZtRmgTHDGj6l3wQeJzt50naCtiN0lw1Zs4sSeuMWcmT+9mZd66k83ig99FLKNuVW6sZRvH/gZcBzwX+k9K7sI1WG68I3Gz5XL1SpmgBSfsCJzFm2iiQaaMxZVnJEwFI+nRzOAd4OqVpLcBewHdaUtyJCprJRM+y3foGxpL2tv3tQUXLXrEyVkyS9gb+HbipubQJ8GrbE03fiimS9E3KVLv32H5KM4lvQVdWPnSFpFcC76b0qjBl1PAJts+Y8DfGtEk6ANidUnS/2PbZlSONqxmK8FLgOcBFwBeAU2xvUjPXRJotOY8B3mr7zubamsDJwB+6MP0phiPTRmMm5MlHDF0XlhvafjWApP+iTEj5XXP+WOCfa2YbRNKmwNsob9Tu/7ds+wW1Mo2odwLfkDSfZfvbnFQv0kB7UgqU+1Le/GjM5xR5VmyPBrahfM94IaWg/b81A42Y9Wx/UdK7AWzfKykrpWaY7c9KupzyJkjAi9KUdDhs/ydlNUzbnQd8F3iG7Z8DSPp43UiTOgb4AHCzpF5vsY0oK/+OrZYq2iDTRuNhS5EnhkbSCygToLq03HCTXoGncQvwxFphJvFVys3A1+nOmOwuOgH4M6VQuUrlLBOy/d7m8FoeKO7QHP+vpO3TyG+FdqztL0lai9LT60TgVMoEq3j47pT0aJrth5J2JUW0oWiKOinsDEFHt9DuBMwDLpR0E3AWsFLdSBNrtmkdJek44G+ayzfavqtirGiHTBuNhy3btWJourjcUNIngC0oe9BNuWm40fbbqgYbh6RLbefN2ZBJutz2zrVzTIekM4GdgXMoN+b7AD8CtgS+ZPsfK8aLSnrNaSV9iNJj6sw0rJ05knYETqGslrqWMv72xbavnvA3RsSMkbQ7ZevWAcBCyqSq0+umejBJ7+z9LJZ0oO0v9b32QdtH10sXNWXaaMyEFHliaHpvjptizw6275N0me2n1s42EUn7A70x5G3eg/4ySkHqfJbdRnRltVAjqNk3/23b59fOMlVNs8wDbP+5OX8kpX/F/sAVtreqmS/qaLaj/gZ4NuXJ913AZZmuNXOaPjxPotyc/8T2ksqRIlZIzTSwucC83pb8NpF0pe0dxx6Pdx4RMV3ZrhXD1NXlhlcCi21fKGkNSbNtL64dahzbAq+grJbqbddycx4z5y3AOyX9FVhCu5es92wE3NN3vgTY2PZdzZ8jVkwHUSbOfNT27U3PsXdUzjRSmi0Y19XOEbEiaXo/Hk3Z9nQN8CHbd1B69ZxXM9sENOB4vPNYAXR0q2S0VIo8MUwvpDwpPoIHlhseVzXRJCS9Dng9sC6wObAhZfzms2rmGmB/YDPb90z6K+Mhsz27GdG7BX0NxFvuTOASSV9rzvcFPt8sAU4fixWU7b/Q13y76T/2u8G/IyKiEz4LXEHZLvl8yoSqV9UMNAUecDzeeawAbM+unSFGR7ZrxdBI+oexIyDHu9YmkhYCTwUu7fWpkHRNG0fgSvoC8Dbbi2pnGWWSXgscBjyesr9/V+AHtttY+LufpJ2AZ1CeAH3P9uWVI0VERMw4SQttb9933vrtTs3kvTspP6NXB/7SewlYzfbKtbJFRPdlJU8M01xgbEHneeNca5O/2r5HKitlm/4Kba2EPga4QdKPeKAnj22/sGKmUXQYsAtwie29JG1Jy1ekAdi+gvJkMyKWE0nrMGbVn+2L6yWKWCGo+bfX2+a0Uv+57duqJRvAdqunf0VEt6XIEzNO0puANwObSeqfKjIb+H6dVFM2X9LRwOqS5lL+HF+vnGmQ9/Ydi7Jq46WVsoyyu23fLQlJq9q+QdKTaoeKiHYZsOrvh6RPWsSwrU15qNHfy6Y3hMLAZss90UMk6VHAW2yfUDtLRHRXijwxDGcC3wQ+BBzVd31xG5+mjHEUcAilcd8bgG8An6qaaADb8yVtD7yM0lD155T+QTGzft3cdH0VuEDSn4DfVs4UEe3TyVV/EV1ne5Op/DpJW9tuRWN0SU8AjgUeR7m/OBN4P/DK5jgi4iFLT54YKklPAZ7ZnH7X9lU180xE0krAZ2y/vHaWiUh6IjCPsmrnj8AXgLfb3rhqsBWApD0pTwzPTcPriOgn6Ue2d2l6uz3N9l/H9gqJiHra1KtH0kXAfMpqv+dSBnxcBxxh+/c1s0VE92UlTwyNpEMpk6p601w+J+l026dUjDWQ7aWS1pe0SsvfwN8AfBfY1/aNAJKOqBtpxWB7fu0MEdFaWfUX0W5tGk2+ru33NcfnSboF2MX2Xyf4PRERU5IiTwzTaylPM++EMlmL8sSilUWexi+A70s6hzL1AADbJ1VL9GAHUFbyXCTpXOAs2nXjEhGxwrG9f3P4vuYp/drAuRUjRcSyWrV9YUyz6N8Da0haE9rZLDoiuiNFnhgmAUv7zpfS/mLEb5uPWZRG0a1j+2zg7OZGYD/gCOAxkk4FzrZ9ftWAEREruKz6i4hJjEyz6Ihon/TkiaGRdCTwd8DZzaX9KD1v/qleqqmRtGZvBVIXSFoXOBB4ie1McomIiIjoI+kS27vWzjEdbWoWHRHdkSJPDJWkHSmjvQVcbHtB5UgTkrQb8K/AI21v1DSOfoPtN1eOFhERERHjkLQKcDCwNWUlzI+BM7ve46ZNzaIjojtm1Q4Qo0vSGbavtH2y7Y/bXiDpjNq5JvEx4DmUqVU008D2qJooIiIiIsYlaStKUedvgV8Cv26Or2te67K2tzmIiBZKT54Ypq37T5oR5TtVyjJltn8lLfMzdemgXxsRERERVZ0CvMn2Bf0XJT0b+GdgryqpZka2XETEtGUlT8w4Se+WtBjYTtIdzcdiYBHwtcrxJvMrSU8HLGkVSW8Hrq8dKiIiIiLGteHYAg+A7QuBDSrkiYioKkWemHG2P2R7NvAR22s1H7NtP9r2u3u/TtLWE/xnankj8BZgQ8py3+2b84iIiIhon1mSVh17UdJqdH/Xwj21A0RE96TxclTjDVL1AAALSElEQVTTxmZykta3fWvtHBERERExOUnHALsCb7X9i+baJsDJwOW2j68WbgKj2iw6IurLSp6oqY3N5H4g6XxJh0h6VO0wERERETGY7Q8A5wIXS/qDpD8C84ELWlzgGeVm0RFRWVbyRDVtXMkDIOmpwDxgP8oP4LNsf65uqoiIiIiYiKTZALYX184yEUnfAj48oFn0e2x3uVl0RFSWIk9U09YiT4+k9YCTgINtr1Q7T0REREQsS9KRE71u+6TllWWqJN1ge8sBr11v+8nLO1NEjI6uNyOLbmtdMzlJawH7U1bybA6cDTy1aqiIiIiIGGR27QAPwSxJq47tvzMizaIjorKs5ImhkSRKQ7nNbB8vaSNgA9uXVY42kKSfA18Fvmj7h7XzRERERMRDI2lN23fWzjFWV5tFR0Q3pMgTQyPpVOA+YG/bT5a0DnC+7V0qRxtIkmy72dNt23+unSkiIiIiBpO0IfBY4Grb90iaAxwOvMr24+qmG5+ktwLvBNagDCP5M/BR26dUDRYRnZfpWjFMT7P9FuBuANt/AlapG2lSW0taAFwL/FjSFZK2qR0qIiIiIh5M0uHAQuAU4BJJfwdcD6wO7FQz20Rsf8L2RsCmwCa2N06BJyJmQvZ8xjAtkbQSYABJ61NW9rTZ6cCRti8CkPS3zbWn1wwVEREREeN6PfAk27c1rQFuBPawfUnlXAON1yy6dDko2tgsOiK6I0WeGKaTKY2L50g6AXgxcEzdSJNas1fgAbD9HUlr1gwUEREREQPdbfs2ANu/lPQ/bS7wNLrYLDoiOiI9eWKoJG0JPIuy1/hbtq+vHGlCks4GrgTOaC69HNjZ9n71UkVERETEeCQtAs7quzSv/9z2ocs91MPQ1mbREdEdKfLE0EjaFbjO9uLmfDawle1L6yYbrGkOfRzwjObSxcBxTT+hiIiIiGiRpgfPQLY/s7yyTEcXm0VHRDekyBND0zQw3tHNF5mkWZSxkDvWTRYRERERo07SxrZvrp1jrKZZ9Hso/YNWBT4OnAR8FvhH27+rGC8iOi49eWKY5L4qou37JLX6a07SBcCBtm9vztcBzrL9nLrJIiIiImI8knYDNgQutr1I0nbAUcAzgSdUDTe+zjWLjojuyAj1GKabJB0qaeXm4zDgptqhJrFer8AD9499n1MxT0REREQMIOkjwL8BBwD/Lem9wAXApcAWNbNNYJlm0UAXmkVHREe0elVFdN4bKRO2jqGMUf8W5clFm90naaPmBy6SNqYZAR8RERERrbMPsIPtu5sV2L8FtrP908q5JvJ4SSf3nc/pP+9as+iIaJcUeWJobC+iTDjokvcA35M0vznfg/YXpiIiIiJWVHfZvhvKCmxJP2l5gQfgHWPOr6iSIiJGUhovx9BIWg04BNgaWK133fZrqoWaAknrAbtSxr7/0PYf+l7b2vZ11cJFRERExP0k3U6ZhtqzR/+57Rcs91APQ1ubRUdEd6TIE0Mj6UvADcDLgOOBg4HrbR9WNdjDIOnKTAeLiIiIaAdJe070uu35E71ey0TNom23sVl0RHREijwxNJIW2N5B0tW2t5O0MnCe7b1rZ3uoen+m2jkiIiIiYjBJTwDm2f5I7SxjNc2inw8sBP4G+C/gzcAHgdN6288iIh6K9OSJYVrSfL5d0jbA74FN6sWZEamKRkRERLRQs+X+QOCllFUyZ9dNNFAXm0VHREekyBPDdHrzg+sY4BzgkcCxdSNFRERExKiQNBvYn9Ie4ImUws5mth9fNdjEutgsOiI6IkWemHGSDrP9cUr/nT9Rmt9tVjnWTLmndoCIiIiIuN8i4DLKQ8Xv2bak/Stnmszmks7pO9+k/7xrzaIjol3SkydmnKSFtrfvYpNiSaI0iN7M9vGSNgI2sH1Z5WgRERERMYakI4B5wJrAmcAXgAtst/YBY1ebRUdEN6TIEzNO0ueB3YA5wI39LwG2vV2VYFMg6VTgPmBv209utpudb3uXytEiIiIiYgBJm1F68cwDtgDeC5xt+3+qBpuGNjeLjojuSJEnhkLSBsB5wIOWm9q+efknmpre6qP+KVqSrrL9lNrZIiIiImJykral9Og5yPbmtfNMZLxm0bbfXjdVRHRZevLEsNwKXNPmgs4ASyStRDNFS9L6lJU9EREREdENvwOOtv3u2kHG09Fm0RHREbNqB4jRZHspsJ6kVWpnmaaTKT9o50g6Afge8MG6kSIiIiJiPJJ2lfQdSV+RtIOka4FrgVskPbd2vgEWAYcAJwCb2/57MtwjImZItmvF0Eg6DdiRMj79zt512ydVCzUFkrYEnkXpIfQt29dXjhQRERER45B0OXA0sDZwOvA825c093Of722/b5MuNouOiO5IkSeGRtJ7x7tu+7jlnWWqJO0KXGd7cXM+G9jK9qV1k0VERETEWL2prs3x9baf3PfagjYWeXpGoVl0RLRPijwRfSQtAHZ08w9D0izg8q6Ngo+IiIhYEfSGZow9Hu+8zbrULDoi2i1FnhgaSRfRNDDuZ3vvCnGmpP9pUN+1q9s89j0iIiJiRSVpKaUtgIDVgb/0XgJWs71yrWzT0UzZ+qPz5iwiHqZM14ph6h//uBpwAHBvpSxTdZOkQ4FTm/M3AzdVzBMRERERA9heqXaG6WraA3wYuA14P3AGsB4wS9IrbZ9bM19EdFtW8sRyJWm+7T1r5xhE0hzKhK29KauQvgUcbntR1WARERERMRK62Cw6IrojK3liaCSt23c6C9gZ2KBSnClpijnzaueIiIiIiJH1CNvnA0g63vYlALZvkFQ3WUR0Xoo8MUxXUFbDCFgC/AI4pGagyUhajZJxa8oWMwBsv6ZaqIiIiIgYJff1Hd815rVss4iIh2VW7QAx0t4FbG97U8pe4zt5oBleW51BWW30HGA+8HhgcdVEERERETFKniLpDkmLge2a4975trXDRUS3pSdPDE1vKpWkZwAfBE4Ejrb9tMrRBpK0wPYOfdlXBs5r80SwiIiIiIiICMhKnhiupc3nfYBP2v4asErFPFOxpPl8u6RtKA3xNqkXJyIiIiIiImJqUuSJYfqNpNOAg4BvSFqV9n/NnS5pHeAY4Bzgx8A/1I0UERERERERMbls14qhkbQG8FzgGts/lfRYYNveNIE2kXSY7Y9L2t3292vniYiIiIiIiJiuFHkiAEkLbW8v6UrbO9bOExERERERETFdGaEeUVwv6RfAHElX910XYNvb1YkVERERERERMTVZyRPRkLQBcB7wgrGv2b55+SeKiIiIiIiImLqs5Il4wK2U/kEp6ERERERERETntH3SUcRyY3spsJ6kto95j4iIiIiIiHiQrOSJWNbNwPclnQPc2bto+6R6kSIiIiIiIiImlyJPxLJ+23zMAmZXzhIRERERERExZWm8HBERERERERExArKSJ6KPpIuAB1U+be9dIU5ERERERETElKXIE7Gst/cdrwYcANxbKUtERERERETElGW7VsQkJM23vWftHBERERERERETyUqeiD6S1u07nQXsDGxQKU5ERERERETElKXIE7GsKyg9eQQsAX4BHFIzUERERERERMRUzKodIKJl3gVsb3tT4AzgTuAvdSNFRERERERETC5FnohlHWP7DknPAOYC/w6cWjdSRERERERExORS5IlY1tLm8z7AJ21/DVilYp6IiIiIiIiIKUmRJ2JZv5F0GnAQ8A1Jq5J/JxEREREREdEBGaEe0UfSGsBzgWts/1TSY4FtbZ9fOVpERERERETEhFLkiYiIiIiIiIgYAdmGEhERERERERExAlLkiYiIiIiIiIgYASnyRERERERERESMgBR5IiIiIiIiIiJGQIo8EREREREREREj4P8AZlau/9doitoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_aux3 = data[[ 'surface_total_in_m2', 'surface_covered_in_m2' ,'Ambientes', 'pileta', 'amenities',\n",
    "       'gimnasio', 'laundry', 'sum', 'solarium', 'parrilla', 'a estrenar',\n",
    "       'subte', 'cochera', 'latitud', 'longitud', 'BARRIO_PALERMO', 'BARRIO_RECOLETA', 'balcon', 'terraza', 'lavadero']]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(data_aux3.corr(),\n",
    "            xticklabels=data_aux3.columns.values,\n",
    "            yticklabels=data_aux3.columns.values, cmap=sns.diverging_palette(220, 10, as_cmap=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux3_sq = PolynomialFeatures(2,include_bias=True,interaction_only=False).fit_transform(data_aux3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 231)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aux3_sq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399, 231) (2399,)\n",
      "(1029, 231) (1029,)\n"
     ]
    }
   ],
   "source": [
    "#Split train y test \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_aux3_sq, data.price_usd_per_m2, test_size=0.3, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NormalizaciÃ³n (para Ridge y Lasso)\n",
    "se = StandardScaler()\n",
    "X_train_s = se.fit_transform(X_train)\n",
    "X_test_s = se.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>19055.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>-6395.446939</td>\n",
       "      <td>-10810.413796</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-3560.708296</td>\n",
       "      <td>-6018.770924</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-172.849917</td>\n",
       "      <td>-292.173346</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.083756</td>\n",
       "      <td>2020.085546</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3414.610561</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6395.662676</td>\n",
       "      <td>-10808.309871</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6395.662676</td>\n",
       "      <td>-10808.309871</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-172.855748</td>\n",
       "      <td>-292.116483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.164385</td>\n",
       "      <td>2019.760527</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3413.281586</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2903.825861</td>\n",
       "      <td>-4908.402454</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2419.854884</td>\n",
       "      <td>-4090.335378</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.708066</td>\n",
       "      <td>-175.300088</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.040339</td>\n",
       "      <td>2020.003682</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3414.457858</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5929.0</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-2662.704044</td>\n",
       "      <td>-4499.882433</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4624.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-2351.478896</td>\n",
       "      <td>-3973.922149</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-138.322288</td>\n",
       "      <td>-233.760126</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.815960</td>\n",
       "      <td>2020.889720</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3415.237293</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2005.696730</td>\n",
       "      <td>-3388.879813</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2005.696730</td>\n",
       "      <td>-3388.879813</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.742934</td>\n",
       "      <td>-175.286887</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.844046</td>\n",
       "      <td>2020.530666</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3413.943635</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2    3    4    5    6    7    8    9    10   11   12   13   \\\n",
       "0  1.0  185.0  103.0  5.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1  1.0  185.0  185.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  1.0   84.0   70.0  3.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "3  1.0   77.0   68.0  4.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "4  1.0   58.0   58.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "         14         15   16   17       18       19     20     21    22   \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  34225.0  19055.0  925.0  185.0   0.0   \n",
       "1 -34.571150 -58.423297  1.0  0.0  34225.0  34225.0  925.0    0.0   0.0   \n",
       "2 -34.569355 -58.433363  1.0  0.0   7056.0   5880.0  252.0    0.0  84.0   \n",
       "3 -34.580572 -58.440032  1.0  0.0   5929.0   5236.0  308.0   77.0  77.0   \n",
       "4 -34.580978 -58.428962  1.0  0.0   3364.0   3364.0  174.0    0.0   0.0   \n",
       "\n",
       "     23     24     25     26     27    28    29     30           31   \\\n",
       "0  185.0  185.0  185.0  185.0  185.0   0.0   0.0  185.0 -6395.446939   \n",
       "1    0.0    0.0    0.0    0.0    0.0   0.0   0.0    0.0 -6395.662676   \n",
       "2   84.0    0.0    0.0    0.0   84.0  84.0   0.0    0.0 -2903.825861   \n",
       "3    0.0    0.0   77.0   77.0   77.0   0.0   0.0   77.0 -2662.704044   \n",
       "4    0.0    0.0    0.0    0.0    0.0   0.0  58.0    0.0 -2005.696730   \n",
       "\n",
       "            32     33   34       35     36     37    38     39     40     41   \\\n",
       "0 -10810.413796  185.0  0.0  10609.0  515.0  103.0   0.0  103.0  103.0  103.0   \n",
       "1 -10808.309871  185.0  0.0  34225.0  925.0    0.0   0.0    0.0    0.0    0.0   \n",
       "2  -4908.402454   84.0  0.0   4900.0  210.0    0.0  70.0   70.0    0.0    0.0   \n",
       "3  -4499.882433   77.0  0.0   4624.0  272.0   68.0  68.0    0.0    0.0   68.0   \n",
       "4  -3388.879813   58.0  0.0   3364.0  174.0    0.0   0.0    0.0    0.0    0.0   \n",
       "\n",
       "     42     43    44    45     46           47            48     49   50   \\\n",
       "0  103.0  103.0   0.0   0.0  103.0 -3560.708296  -6018.770924  103.0  0.0   \n",
       "1    0.0    0.0   0.0   0.0    0.0 -6395.662676 -10808.309871  185.0  0.0   \n",
       "2    0.0   70.0  70.0   0.0    0.0 -2419.854884  -4090.335378   70.0  0.0   \n",
       "3   68.0   68.0   0.0   0.0   68.0 -2351.478896  -3973.922149   68.0  0.0   \n",
       "4    0.0    0.0   0.0  58.0    0.0 -2005.696730  -3388.879813   58.0  0.0   \n",
       "\n",
       "    51   52   53   54   55   56   57   58   59   60   61          62   \\\n",
       "0  25.0  5.0  0.0  5.0  5.0  5.0  5.0  5.0  0.0  0.0  5.0 -172.849917   \n",
       "1  25.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -172.855748   \n",
       "2   9.0  0.0  3.0  3.0  0.0  0.0  0.0  3.0  3.0  0.0  0.0 -103.708066   \n",
       "3  16.0  4.0  4.0  0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0 -138.322288   \n",
       "4   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0 -103.742934   \n",
       "\n",
       "          63   64   65   66   67   68   69   70   71   72   73   74   75   \\\n",
       "0 -292.173346  5.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1 -292.116483  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -175.300088  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3 -233.760126  4.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "4 -175.286887  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         76         77   78   79   80   81   82   83   84   85   86   87   \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
       "3 -34.580572 -58.440032  1.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
       "4  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   88         89         90   91   92   93   94   95   96   97   98   99   \\\n",
       "0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0 -34.569355 -58.433363  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
       "3  1.0 -34.580572 -58.440032  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   100        101        102  103  104  105  106  107  108  109  110  111  \\\n",
       "0  1.0 -34.569983 -58.434669  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0 -34.569355 -58.433363  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         112        113  114  115  116  117  118  119  120  121        122  \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0 -34.569983   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "2  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "3  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0 -34.580572   \n",
       "4  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "\n",
       "         123  124  125  126  127  128  129  130        131        132  133  \\\n",
       "0 -58.434669  1.0  0.0  1.0  1.0  0.0  0.0  1.0 -34.569983 -58.434669  1.0   \n",
       "1  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "2  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "3 -58.440032  1.0  0.0  1.0  1.0  0.0  0.0  1.0 -34.580572 -58.440032  1.0   \n",
       "4  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "\n",
       "   134  135  136  137  138        139        140  141  142  143  144  145  \\\n",
       "0  0.0  1.0  0.0  0.0  1.0 -34.569983 -58.434669  1.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  1.0  0.0  0.0 -34.569355 -58.433363  1.0  0.0  1.0  0.0  0.0   \n",
       "3  0.0  1.0  0.0  0.0  1.0 -34.580572 -58.440032  1.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         146        147  148  149  150  151        152        153  154  155  \\\n",
       "0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "2 -34.569355 -58.433363  1.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "3  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "4  -0.000000  -0.000000  0.0  0.0  1.0  0.0 -34.580978 -58.428962  1.0  0.0   \n",
       "\n",
       "   156        157        158  159  160          161          162        163  \\\n",
       "0  1.0 -34.569983 -58.434669  1.0  0.0  1195.083756  2020.085546 -34.569983   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  1195.164385  2019.760527 -34.571150   \n",
       "2  0.0  -0.000000  -0.000000  0.0  0.0  1195.040339  2020.003682 -34.569355   \n",
       "3  1.0 -34.580572 -58.440032  1.0  0.0  1195.815960  2020.889720 -34.580572   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  1195.844046  2020.530666 -34.580978   \n",
       "\n",
       "   164          165        166  167  168  169  170  \n",
       "0 -0.0  3414.610561 -58.434669 -0.0  1.0  0.0  0.0  \n",
       "1 -0.0  3413.281586 -58.423297 -0.0  1.0  0.0  0.0  \n",
       "2 -0.0  3414.457858 -58.433363 -0.0  1.0  0.0  0.0  \n",
       "3 -0.0  3415.237293 -58.440032 -0.0  1.0  0.0  0.0  \n",
       "4 -0.0  3413.943635 -58.428962 -0.0  1.0  0.0  0.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = pd.DataFrame(data_aux_sq)\n",
    "prueba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1. RegresiÃ³n lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n MÃ­nimos Cuadrados Ordinarios\n",
      "Coeficientes: [-2.81545477e+01 -1.56250151e+04  9.61558959e+03  2.74999183e+05\n",
      " -3.05614078e+05  7.12603129e+05  2.76660028e+05  8.15881975e+04\n",
      "  3.44754347e+05 -2.63881971e+05 -1.27787096e+05  5.14673814e+05\n",
      " -3.89607134e+05  2.49855155e+05  4.59919622e+07  7.87223909e+07\n",
      "  1.03260500e+04 -1.32613769e+05  1.66116100e+05 -2.25178925e+04\n",
      "  6.55037893e+04  3.69393761e-02 -5.54460267e-02  1.13758550e+00\n",
      " -5.05278666e+00 -5.38462598e-01  6.13387630e-01 -3.73019349e+00\n",
      "  1.73625647e+00  2.13490378e+00  1.49012104e+00 -5.54667097e-01\n",
      " -2.96863586e+00 -4.68989306e+00 -2.22305110e+02 -1.35473083e+02\n",
      "  2.63607534e-01  2.23566290e+00  3.91208500e+00  3.98984447e+00\n",
      "  2.68043064e+00  1.20291095e-02 -7.42181713e-02  9.61844539e+00\n",
      " -3.71607673e-01 -3.86820405e+00  1.01153526e+01 -3.30091785e+00\n",
      " -4.39636528e+00 -6.35319612e+00  4.32392962e+00  3.54367972e-01\n",
      "  5.15105292e+00  1.32187533e+02  8.60303563e+01  2.11161893e+00\n",
      " -1.85747017e+00 -4.39515841e+00 -2.98569877e+00 -1.05752796e+00\n",
      " -3.48969250e+01 -1.86995513e+02  1.14209731e+02  1.75866104e+02\n",
      "  5.71667209e+00  5.86627423e+01  1.55446576e+02  7.28527860e+01\n",
      " -6.17146635e+00  2.54754145e+01 -2.47164802e+01  4.03964196e+03\n",
      "  2.31221253e+03 -6.92267957e+01 -9.89217687e+01 -2.86849939e+01\n",
      " -6.28864894e+01 -4.12717396e+01 -3.05614082e+05  2.98207042e+01\n",
      "  1.99145600e+02  5.92344684e+01 -1.46794882e+02 -1.84097972e+02\n",
      "  4.38952479e+01  3.58302366e+01 -6.69236418e+01  2.75609430e+02\n",
      " -7.84371535e+03 -5.82966801e+03 -1.24410886e+02  1.29555786e+02\n",
      " -2.45663364e+02 -7.75991099e+01  1.29086129e+02  7.12603114e+05\n",
      " -3.26406583e+02 -1.82427106e+01 -2.36887611e+02  3.47188683e+02\n",
      "  9.80141295e+01  2.50324304e+01 -1.57940189e+02 -1.03488327e+02\n",
      "  2.17099257e+04  1.15440923e+04 -1.93562288e+02  7.02503501e+01\n",
      "  2.36664264e+02 -1.97519742e+02 -5.21027178e+01  2.76660040e+05\n",
      "  2.87764711e+02  4.10671137e+02 -7.96075917e+01  2.45654856e-02\n",
      " -2.91734032e+02  2.56825936e+02 -4.24421004e+01 -8.77371217e+02\n",
      "  9.98988614e+03 -2.29375171e+02 -6.14860396e+02  5.09112927e+00\n",
      "  1.78784227e+02  4.72266281e+00  8.15881992e+04 -2.17796958e+02\n",
      " -8.89067087e+01  2.25521078e+02 -6.16756877e+01  1.32235320e+02\n",
      " -2.78269374e+02 -2.76705756e+03  4.43097607e+03 -1.30453094e+02\n",
      " -2.68804439e+02 -1.30933940e+02  2.19741294e+01 -1.10593441e+02\n",
      "  3.44754343e+05 -1.58121374e+02 -4.21288665e+01 -4.30535768e+01\n",
      "  9.99855872e+01  2.65846316e+01  9.90213277e+03  5.94398783e+03\n",
      "  1.74966055e+02  4.16543381e+01  2.76021690e+02  3.06417224e+01\n",
      " -6.04245678e+01 -2.63881973e+05 -1.28803191e+02 -2.84569823e+02\n",
      " -1.23285817e+02 -2.35509677e+02 -6.06682071e+03 -5.44292311e+03\n",
      "  5.24871272e+01 -5.89397072e+01  5.11856444e+01  2.26399833e+00\n",
      "  2.05484695e+02 -1.27787094e+05  2.24194433e+01  1.75296035e+02\n",
      "  2.82385743e+02 -8.17341202e+03  4.59742918e+02 -1.41109651e+02\n",
      " -1.69147549e+02 -1.95543707e+02  3.56261932e+01  1.44156582e+02\n",
      "  5.14673817e+05  1.14190078e+02 -7.32763959e+01  1.09483754e+04\n",
      "  1.11334027e+04  2.31524939e+01 -1.04630408e+02 -5.15795012e+01\n",
      " -2.99011958e+01 -3.39545168e+02 -3.89607133e+05 -6.72800274e+01\n",
      " -7.70737801e+03 -8.77076890e+03  7.04697189e+01  3.53245431e+02\n",
      "  2.48838023e+02 -1.15359927e+02  6.80891362e+01  2.49855154e+05\n",
      "  1.93264791e+03  7.39931128e+03 -1.79677579e+02 -2.91399269e+02\n",
      " -6.89431447e+01  2.95860794e+01  3.44300149e+01  3.37337908e+04\n",
      "  7.47125011e+05  1.29879686e+04  1.90914300e+04  4.66496949e+03\n",
      "  8.87580122e+03 -6.30424295e+03  4.52441934e+05 -7.33203627e+03\n",
      " -1.58420361e+04  2.92338677e+03 -6.01750968e+03  5.97269383e+03\n",
      "  1.03260472e+04  0.00000000e+00  2.73511232e+01  2.72239582e+02\n",
      " -3.62352834e+02 -1.32613771e+05  6.64714448e+01  6.41101031e+02\n",
      " -5.52217940e+02  1.66116097e+05  4.54889453e+01  6.96049746e+01\n",
      " -2.25178920e+04  1.08202620e+02  6.55037913e+04]\n",
      "Residual sum of squares: 286327.46\n",
      "Varianza explicada: 0.54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print ('RegresiÃ³n MÃ­nimos Cuadrados Ordinarios')\n",
    "#Coeficiente\n",
    "print('Coeficientes:',regr.coef_)\n",
    "# MSE \n",
    "print(\"Residual sum of squares: %.2f\"\n",
    " % np.mean((regr.predict(X_train) - y_train) ** 2))\n",
    "# Varianza explicada\n",
    "print('Varianza explicada: %.2f\\n' % regr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30875459 0.46591692 0.30074101 0.41087186 0.34738976]\n",
      "0.36673482870217866\n",
      "0.06304964603105218\n"
     ]
    }
   ],
   "source": [
    "# Un cross validation\n",
    "results = cross_val_score(regr,X_train,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr.predict(X_test)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2. RegresiÃ³n Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Lasso\n",
      "alpha: 3.18\n",
      "\n",
      "Coeficientes: [ 0.00000000e+00 -3.46894442e+02  1.67716236e+02  0.00000000e+00\n",
      "  1.93142674e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  9.10567213e-01  1.51916783e-02\n",
      " -7.52878170e+00  8.19989339e+01 -0.00000000e+00  8.90469066e+01\n",
      "  1.69964390e+01 -3.16244679e+01  1.20424875e+01 -0.00000000e+00\n",
      " -1.44448510e+01  6.04581488e+01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -2.92253414e+01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -8.76386532e+01 -0.00000000e+00  2.34193591e+02  4.00491809e+00\n",
      " -4.19069255e+01 -4.97820189e+01 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  6.68084043e+00  1.00889966e+00\n",
      "  0.00000000e+00 -0.00000000e+00  5.64950038e+01 -0.00000000e+00\n",
      " -4.74065866e+01 -8.91589920e+01  5.81632079e+01 -0.00000000e+00\n",
      "  7.28563637e+01 -2.33009827e+02 -0.00000000e+00  1.06498542e+02\n",
      " -0.00000000e+00  0.00000000e+00  1.26282403e+00  5.45339192e+01\n",
      "  0.00000000e+00  0.00000000e+00  7.78246425e+01  2.06427170e+01\n",
      "  4.96655591e+01  0.00000000e+00  9.61931257e+01  0.00000000e+00\n",
      "  4.83486701e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  4.98776438e+01  1.38543592e+01\n",
      "  6.51475226e+01  0.00000000e+00 -2.61997254e+01 -5.33108006e+00\n",
      "  0.00000000e+00  4.91007340e+00  0.00000000e+00  1.03587082e+02\n",
      " -2.75256393e+01 -0.00000000e+00 -8.57604195e+00  1.54736631e+01\n",
      " -4.22851184e+01 -4.48169379e+00  1.24452987e+01  0.00000000e+00\n",
      " -2.85340736e+01  0.00000000e+00 -5.10121340e+01  4.52592536e+01\n",
      "  4.60082480e+00 -0.00000000e+00 -3.73557690e+00 -3.15116953e+01\n",
      " -0.00000000e+00 -0.00000000e+00 -1.56563613e+01  3.63130071e+00\n",
      "  4.21267398e+01 -1.26777283e+01 -0.00000000e+00  0.00000000e+00\n",
      "  6.19616348e+01  6.45793730e+01 -2.62565881e+01  0.00000000e+00\n",
      " -6.38157549e+01  9.41607736e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  1.71932758e+01  3.84905193e+00  0.00000000e+00\n",
      "  6.05169354e+00  0.00000000e+00  0.00000000e+00 -1.87011487e+01\n",
      " -3.16896589e+01  2.56363355e+01 -0.00000000e+00  2.92427577e+00\n",
      " -6.18249242e+01 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.76098410e+00  0.00000000e+00 -5.97899302e+00\n",
      " -0.00000000e+00 -3.59194630e+01 -0.00000000e+00 -1.03686284e+01\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  3.09930613e+01  0.00000000e+00\n",
      "  2.01998967e+01  0.00000000e+00 -1.33443018e+01 -2.47795737e+01\n",
      " -4.56212267e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  4.66009467e-01  6.94667048e+00  0.00000000e+00  0.00000000e+00\n",
      "  2.00669313e+01  4.27615695e+00  2.60629991e+00  2.81822892e+01\n",
      "  4.26047549e+01 -5.67858814e-01 -0.00000000e+00  0.00000000e+00\n",
      "  2.09714197e+01 -4.34272112e-01 -0.00000000e+00  0.00000000e+00\n",
      "  3.97182975e-01  1.30706852e+01 -9.46691749e+00 -0.00000000e+00\n",
      " -0.00000000e+00  5.21314531e+01  3.37322753e+01 -0.00000000e+00\n",
      "  0.00000000e+00 -1.71789230e+01 -1.28518813e+01 -4.33584004e+00\n",
      "  0.00000000e+00  5.61991802e-01 -0.00000000e+00  1.14746950e+01\n",
      "  5.75156812e+01 -1.40801493e+01  1.04429233e+01  0.00000000e+00\n",
      " -1.19554708e-02 -0.00000000e+00  1.29974921e+01  1.76353077e+01\n",
      " -2.48833310e+00 -1.20491119e+01  5.24735700e+00  0.00000000e+00\n",
      " -1.82511056e+02 -2.39840987e+00  9.99924339e+00 -2.30120077e-04\n",
      "  4.05735072e+01  6.90189301e+01 -1.54181530e+01 -0.00000000e+00\n",
      "  3.55286892e-01 -0.00000000e+00  4.99257282e-01  5.58289350e+00\n",
      "  0.00000000e+00  0.00000000e+00  2.61753443e+01 -2.24897245e+01\n",
      " -3.36659891e+01 -0.00000000e+00  1.54818195e+01  0.00000000e+00\n",
      " -9.73597903e+00  1.49301047e-04  1.06411473e+01  5.68296923e+00\n",
      " -8.58836830e-01  3.33121818e+01 -4.40109523e+00]\n",
      "\n",
      "Residual sum of squares: 323069.51\n",
      "\n",
      "Varianza explicada: 0.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr2=linear_model.LassoCV(cv=5).fit(X_train_s, y_train)\n",
    "\n",
    "print ('RegresiÃ³n Lasso' )\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr2.alpha_)\n",
    "# Coeficiente\n",
    "print ('Coeficientes:', regr2.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr2.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr2.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39391073 0.46382384 0.37754854 0.42620613 0.39982551]\n",
      "0.41226294964874627\n",
      "0.030164621997500897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(regr2,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr2.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3. RegresiÃ³n Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Ridge\n",
      "alpha: 50.00\n",
      "\n",
      "Coeficientes: [ 0.00000000e+00 -1.75262428e+02  1.03561918e+02  3.11983791e+00\n",
      "  3.70272274e+01  7.16621609e+00 -6.78057380e+00 -1.03705923e+01\n",
      " -9.26044748e+00  4.34753140e+00  4.62757187e+00  5.38763127e+00\n",
      " -1.28820765e+01  3.04255953e+01  1.16694333e+01  7.84165766e+01\n",
      " -1.61495088e-01 -1.84317129e+01  8.40189951e+00 -1.93724588e+01\n",
      " -2.81046522e+01  4.44511781e+01  1.73306051e+01  2.88846727e+01\n",
      " -7.84687636e+00 -7.41320527e+01 -3.59674428e+01 -4.34584363e+01\n",
      " -1.45573827e+01 -1.59056968e+00 -4.03900873e+01 -1.25006463e+01\n",
      " -7.39412389e+01 -4.41929209e+01  1.75085456e+02  1.75572549e+02\n",
      " -1.02374087e+02 -6.10967635e+01 -1.67532123e+01  3.96789761e+01\n",
      "  2.60551055e+01 -2.68920997e+01  6.60022916e+01  6.23725942e+01\n",
      "  4.88302679e+01 -1.10062564e+01  1.15562446e+02 -1.54102878e+01\n",
      " -6.61761084e+01 -8.47329048e+01  7.34987615e+01 -3.89794385e+01\n",
      "  8.04326655e+01 -1.03734131e+02 -1.03253575e+02  1.47774706e+02\n",
      "  9.70070026e+00  6.59609084e+00  2.01618348e+01  6.92863066e+01\n",
      " -2.53937507e+01 -4.98377960e+01  8.89054566e+01  6.83613142e+01\n",
      "  5.92576920e+01  1.58226169e+01  1.13414243e+02  1.04906444e+01\n",
      "  1.27809935e+01  3.12110996e+01 -6.45478759e+00 -3.25851125e+00\n",
      " -2.76833097e+00  1.84774346e+01 -1.04642483e+01 -2.00404931e+01\n",
      " -3.54774177e+01 -2.90349344e+01  3.70272274e+01  3.84902514e+01\n",
      "  5.92216503e+01  1.81235710e+01 -4.14552925e+01 -2.96133747e+01\n",
      "  4.71369127e+00  2.81824157e+01  2.56007438e+00  1.07205980e+02\n",
      " -3.70655480e+01 -3.69990020e+01 -5.52995907e+01 -3.94454070e-01\n",
      " -6.64172695e+01 -2.46047227e+01  2.58781757e+01  7.16621609e+00\n",
      " -5.86347040e+01  6.12667646e+00 -7.57032705e+01  5.68074767e+01\n",
      "  9.67018834e+00 -5.46435228e+00 -2.93806914e+01 -3.89924254e+01\n",
      " -7.02000120e+00 -7.09887860e+00 -4.12176910e+01 -4.28639628e+00\n",
      "  5.49317707e+01 -3.45873700e+01 -1.93742798e+00 -6.78057380e+00\n",
      "  6.97807987e+01  9.27047885e+01 -3.32347738e+01 -1.46857551e+00\n",
      " -6.72679442e+01  2.84046123e+01 -1.79902095e+00  6.72713871e+00\n",
      "  7.01095877e+00  2.25793112e+01  1.00347314e+01 -7.81493539e+00\n",
      "  2.98629135e+01  2.92604858e+00 -1.03705923e+01 -3.44636103e+01\n",
      " -4.51132510e+01  3.40449167e+01 -8.06256999e+00  1.79602098e+01\n",
      " -6.26938300e+01  1.03318791e+01  1.04484055e+01  9.39392895e+00\n",
      "  4.61732068e-01 -1.99770425e+01  1.25685986e+01 -1.78763287e+01\n",
      " -9.26044748e+00 -3.14007730e+01 -7.49087861e+00 -2.64642063e+01\n",
      "  1.14423442e+01  1.18251097e+01  9.21912813e+00  9.37553725e+00\n",
      "  3.18164570e+01  1.14062753e+01  6.02275042e+01  1.05960229e+01\n",
      "  1.43214456e+01  4.34753140e+00 -2.24304370e+01 -3.24021073e+01\n",
      " -1.59549321e+01 -2.01618312e+01 -4.45394040e+00 -4.34598027e+00\n",
      "  1.14829913e+01  1.24084191e+01  9.83830713e+00  1.48353386e+01\n",
      "  2.77545664e+01  4.62757187e+00  8.47828956e+00  3.77172493e+01\n",
      "  5.49976627e+01 -4.79166327e+00 -4.60620418e+00  8.95136724e+00\n",
      "  2.14527380e+01 -2.93078019e+01  9.17958706e+00  8.10143946e+00\n",
      "  5.38763127e+00  2.36539347e+01 -2.63897532e+01 -5.25546350e+00\n",
      " -5.26718013e+00  4.49150983e+01  3.19744526e+01 -1.94723198e+01\n",
      "  5.80419997e+00 -2.53291689e+01 -1.28820765e+01 -1.04673994e+01\n",
      "  1.28494771e+01  1.27951835e+01  2.39190511e+00  2.34315369e+01\n",
      "  6.33136563e+01 -1.53219914e+01  2.52174576e+01  3.04255953e+01\n",
      " -3.05259285e+01 -3.01069973e+01  2.42805380e+01  2.78878799e+01\n",
      " -2.24761738e+01 -2.35540602e+01  9.87840516e+00 -1.21246106e+01\n",
      " -1.64622355e+02  1.94240547e-01  1.87305282e+01 -8.37944118e+00\n",
      "  1.95126915e+01  2.78574878e+01 -7.81723084e+01  3.66155632e-01\n",
      "  1.85112718e+01 -8.23070476e+00  1.92804202e+01  2.83965446e+01\n",
      " -1.61495088e-01  0.00000000e+00  3.09393918e+01 -2.86264342e+01\n",
      " -3.94269854e+01 -1.84317129e+01  2.52395316e+01 -2.34237358e+00\n",
      " -1.16858339e+01  8.40189951e+00  4.14960810e+01  2.17138494e+01\n",
      " -1.93724588e+01  3.58603188e+01 -2.81046522e+01]\n",
      "\n",
      "Residual sum of squares: 315369.78\n",
      "\n",
      "Varianza explicada: 0.49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr3=linear_model.RidgeCV(alphas=[0.1,0.2,0.5,0.7,1.38,1.39,1.5,1.6,3.0,5.0,7.0,10.0, 18.9, 19.0, 50.0])\n",
    "regr3.fit(X_train_s,y_train)\n",
    "\n",
    "print ('RegresiÃ³n Ridge')\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr3.alpha_)\n",
    "# Coeficientes\n",
    "print('Coeficientes:', regr3.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr3.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr3.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37593558 0.46644322 0.35984814 0.44168607 0.36086809]\n",
      "0.4009562202037202\n",
      "0.044430693054203566\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(regr3,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr3.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MejorÃ© un punto! La Lasso y la Ridge dieron mejor, y la Lasso ademÃ¡s eliminÃ³ varias variables, nos quedarÃ­amos con esa. Ya se veÃ­a que habÃ­a overfitting en el cross validation de la regresiÃ³n comÃºn y silvestre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Una locura: Polynomial features de grado 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Preparando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux3_cu = PolynomialFeatures(3,include_bias=True,interaction_only=False).fit_transform(data_aux3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 1771)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aux3_cu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399, 1771) (2399,)\n",
      "(1029, 1771) (1029,)\n"
     ]
    }
   ],
   "source": [
    "#Split train y test \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_aux3_cu, data.price_usd_per_m2, test_size=0.3, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NormalizaciÃ³n (para Ridge y Lasso)\n",
    "se = StandardScaler()\n",
    "X_train_s = se.fit_transform(X_train)\n",
    "X_test_s = se.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>19055.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>-6395.446939</td>\n",
       "      <td>-10810.413796</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-3560.708296</td>\n",
       "      <td>-6018.770924</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-172.849917</td>\n",
       "      <td>-292.173346</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.083756</td>\n",
       "      <td>2020.085546</td>\n",
       "      <td>-34.569983</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3414.610561</td>\n",
       "      <td>-58.434669</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6395.662676</td>\n",
       "      <td>-10808.309871</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34225.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6395.662676</td>\n",
       "      <td>-10808.309871</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-172.855748</td>\n",
       "      <td>-292.116483</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.164385</td>\n",
       "      <td>2019.760527</td>\n",
       "      <td>-34.571150</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3413.281586</td>\n",
       "      <td>-58.423297</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2903.825861</td>\n",
       "      <td>-4908.402454</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2419.854884</td>\n",
       "      <td>-4090.335378</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.708066</td>\n",
       "      <td>-175.300088</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.040339</td>\n",
       "      <td>2020.003682</td>\n",
       "      <td>-34.569355</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3414.457858</td>\n",
       "      <td>-58.433363</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5929.0</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-2662.704044</td>\n",
       "      <td>-4499.882433</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4624.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-2351.478896</td>\n",
       "      <td>-3973.922149</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-138.322288</td>\n",
       "      <td>-233.760126</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.815960</td>\n",
       "      <td>2020.889720</td>\n",
       "      <td>-34.580572</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3415.237293</td>\n",
       "      <td>-58.440032</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2005.696730</td>\n",
       "      <td>-3388.879813</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2005.696730</td>\n",
       "      <td>-3388.879813</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.742934</td>\n",
       "      <td>-175.286887</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1195.844046</td>\n",
       "      <td>2020.530666</td>\n",
       "      <td>-34.580978</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3413.943635</td>\n",
       "      <td>-58.428962</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2    3    4    5    6    7    8    9    10   11   12   13   \\\n",
       "0  1.0  185.0  103.0  5.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1  1.0  185.0  185.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  1.0   84.0   70.0  3.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "3  1.0   77.0   68.0  4.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "4  1.0   58.0   58.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "         14         15   16   17       18       19     20     21    22   \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  34225.0  19055.0  925.0  185.0   0.0   \n",
       "1 -34.571150 -58.423297  1.0  0.0  34225.0  34225.0  925.0    0.0   0.0   \n",
       "2 -34.569355 -58.433363  1.0  0.0   7056.0   5880.0  252.0    0.0  84.0   \n",
       "3 -34.580572 -58.440032  1.0  0.0   5929.0   5236.0  308.0   77.0  77.0   \n",
       "4 -34.580978 -58.428962  1.0  0.0   3364.0   3364.0  174.0    0.0   0.0   \n",
       "\n",
       "     23     24     25     26     27    28    29     30           31   \\\n",
       "0  185.0  185.0  185.0  185.0  185.0   0.0   0.0  185.0 -6395.446939   \n",
       "1    0.0    0.0    0.0    0.0    0.0   0.0   0.0    0.0 -6395.662676   \n",
       "2   84.0    0.0    0.0    0.0   84.0  84.0   0.0    0.0 -2903.825861   \n",
       "3    0.0    0.0   77.0   77.0   77.0   0.0   0.0   77.0 -2662.704044   \n",
       "4    0.0    0.0    0.0    0.0    0.0   0.0  58.0    0.0 -2005.696730   \n",
       "\n",
       "            32     33   34       35     36     37    38     39     40     41   \\\n",
       "0 -10810.413796  185.0  0.0  10609.0  515.0  103.0   0.0  103.0  103.0  103.0   \n",
       "1 -10808.309871  185.0  0.0  34225.0  925.0    0.0   0.0    0.0    0.0    0.0   \n",
       "2  -4908.402454   84.0  0.0   4900.0  210.0    0.0  70.0   70.0    0.0    0.0   \n",
       "3  -4499.882433   77.0  0.0   4624.0  272.0   68.0  68.0    0.0    0.0   68.0   \n",
       "4  -3388.879813   58.0  0.0   3364.0  174.0    0.0   0.0    0.0    0.0    0.0   \n",
       "\n",
       "     42     43    44    45     46           47            48     49   50   \\\n",
       "0  103.0  103.0   0.0   0.0  103.0 -3560.708296  -6018.770924  103.0  0.0   \n",
       "1    0.0    0.0   0.0   0.0    0.0 -6395.662676 -10808.309871  185.0  0.0   \n",
       "2    0.0   70.0  70.0   0.0    0.0 -2419.854884  -4090.335378   70.0  0.0   \n",
       "3   68.0   68.0   0.0   0.0   68.0 -2351.478896  -3973.922149   68.0  0.0   \n",
       "4    0.0    0.0   0.0  58.0    0.0 -2005.696730  -3388.879813   58.0  0.0   \n",
       "\n",
       "    51   52   53   54   55   56   57   58   59   60   61          62   \\\n",
       "0  25.0  5.0  0.0  5.0  5.0  5.0  5.0  5.0  0.0  0.0  5.0 -172.849917   \n",
       "1  25.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -172.855748   \n",
       "2   9.0  0.0  3.0  3.0  0.0  0.0  0.0  3.0  3.0  0.0  0.0 -103.708066   \n",
       "3  16.0  4.0  4.0  0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0 -138.322288   \n",
       "4   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0 -103.742934   \n",
       "\n",
       "          63   64   65   66   67   68   69   70   71   72   73   74   75   \\\n",
       "0 -292.173346  5.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1 -292.116483  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -175.300088  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3 -233.760126  4.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "4 -175.286887  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         76         77   78   79   80   81   82   83   84   85   86   87   \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  -0.000000  -0.000000  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
       "3 -34.580572 -58.440032  1.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0   \n",
       "4  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   88         89         90   91   92   93   94   95   96   97   98   99   \\\n",
       "0  0.0  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0 -34.569355 -58.433363  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
       "3  1.0 -34.580572 -58.440032  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   100        101        102  103  104  105  106  107  108  109  110  111  \\\n",
       "0  1.0 -34.569983 -58.434669  1.0  0.0  1.0  1.0  1.0  1.0  0.0  0.0  1.0   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0 -34.569355 -58.433363  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         112        113  114  115  116  117  118  119  120  121        122  \\\n",
       "0 -34.569983 -58.434669  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0 -34.569983   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "2  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "3  -0.000000  -0.000000  0.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0 -34.580572   \n",
       "4  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000   \n",
       "\n",
       "         123  124  125  126  127  128  129  130        131        132  133  \\\n",
       "0 -58.434669  1.0  0.0  1.0  1.0  0.0  0.0  1.0 -34.569983 -58.434669  1.0   \n",
       "1  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "2  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "3 -58.440032  1.0  0.0  1.0  1.0  0.0  0.0  1.0 -34.580572 -58.440032  1.0   \n",
       "4  -0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0   \n",
       "\n",
       "   134  135  136  137  138        139        140  141  142  143  144  145  \\\n",
       "0  0.0  1.0  0.0  0.0  1.0 -34.569983 -58.434669  1.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  1.0  0.0  0.0 -34.569355 -58.433363  1.0  0.0  1.0  0.0  0.0   \n",
       "3  0.0  1.0  0.0  0.0  1.0 -34.580572 -58.440032  1.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "         146        147  148  149  150  151        152        153  154  155  \\\n",
       "0  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "1  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "2 -34.569355 -58.433363  1.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "3  -0.000000  -0.000000  0.0  0.0  0.0  0.0  -0.000000  -0.000000  0.0  0.0   \n",
       "4  -0.000000  -0.000000  0.0  0.0  1.0  0.0 -34.580978 -58.428962  1.0  0.0   \n",
       "\n",
       "   156        157        158  159  160          161          162        163  \\\n",
       "0  1.0 -34.569983 -58.434669  1.0  0.0  1195.083756  2020.085546 -34.569983   \n",
       "1  0.0  -0.000000  -0.000000  0.0  0.0  1195.164385  2019.760527 -34.571150   \n",
       "2  0.0  -0.000000  -0.000000  0.0  0.0  1195.040339  2020.003682 -34.569355   \n",
       "3  1.0 -34.580572 -58.440032  1.0  0.0  1195.815960  2020.889720 -34.580572   \n",
       "4  0.0  -0.000000  -0.000000  0.0  0.0  1195.844046  2020.530666 -34.580978   \n",
       "\n",
       "   164          165        166  167  168  169  170  \n",
       "0 -0.0  3414.610561 -58.434669 -0.0  1.0  0.0  0.0  \n",
       "1 -0.0  3413.281586 -58.423297 -0.0  1.0  0.0  0.0  \n",
       "2 -0.0  3414.457858 -58.433363 -0.0  1.0  0.0  0.0  \n",
       "3 -0.0  3415.237293 -58.440032 -0.0  1.0  0.0  0.0  \n",
       "4 -0.0  3413.943635 -58.428962 -0.0  1.0  0.0  0.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = pd.DataFrame(data_aux_sq)\n",
    "prueba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1. RegresiÃ³n Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n MÃ­nimos Cuadrados Ordinarios\n",
      "Coeficientes: [ 9.03496544e+02 -1.31564837e+08  1.79444664e+08 ... -7.56027512e+04\n",
      " -7.56027488e+04  6.75610976e+05]\n",
      "Residual sum of squares: 128581.68\n",
      "Varianza explicada: 0.79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print ('RegresiÃ³n MÃ­nimos Cuadrados Ordinarios')\n",
    "#Coeficiente\n",
    "print('Coeficientes:',regr.coef_)\n",
    "# MSE \n",
    "print(\"Residual sum of squares: %.2f\"\n",
    " % np.mean((regr.predict(X_train) - y_train) ** 2))\n",
    "# Varianza explicada\n",
    "print('Varianza explicada: %.2f\\n' % regr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.36506132e+07 -1.07509023e+04 -3.37104494e+05 -4.34729146e+04\n",
      " -1.83179648e+05]\n",
      "-2845024.231417031\n",
      "5404028.608203273\n"
     ]
    }
   ],
   "source": [
    "# Un cross validation\n",
    "results = cross_val_score(regr,X_train,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): -153309.59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr.predict(X_test)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting in extremus! Veamos si con Lasso se corriege o explota:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.2. RegresiÃ³n Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Lasso\n",
      "alpha: 5.96\n",
      "\n",
      "Coeficientes: [   0.         -161.59017392   78.97953644 ...    0.            0.\n",
      "   -0.        ]\n",
      "\n",
      "Residual sum of squares: 302022.99\n",
      "\n",
      "Varianza explicada: 0.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr2=linear_model.LassoCV(cv=5).fit(X_train_s, y_train)\n",
    "\n",
    "print ('RegresiÃ³n Lasso' )\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr2.alpha_)\n",
    "# Coeficiente\n",
    "print ('Coeficientes:', regr2.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr2.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr2.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39391073 0.46382384 0.37754854 0.42620613 0.39982551]\n",
      "0.41226294964874627\n",
      "0.030164621997500897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(regr2,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr2.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.3. RegresiÃ³n Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Ridge\n",
      "alpha: 50.00\n",
      "\n",
      "Coeficientes: [  0.         -89.77451789  56.2179769  ...  10.23830451  10.23830451\n",
      "  -6.92606984]\n",
      "\n",
      "Residual sum of squares: 222350.10\n",
      "\n",
      "Varianza explicada: 0.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr3=linear_model.RidgeCV(alphas=[0.1,0.2,0.5,0.7,1.38,1.39,1.5,1.6,3.0,5.0,7.0,10.0, 18.9, 19.0, 50.0])\n",
    "regr3.fit(X_train_s,y_train)\n",
    "\n",
    "print ('RegresiÃ³n Ridge')\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr3.alpha_)\n",
    "# Coeficientes\n",
    "print('Coeficientes:', regr3.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr3.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr3.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33597855 0.41873889 0.27115219 0.35205225 0.31334043]\n",
      "0.3382524605497097\n",
      "0.048573089847588076\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(regr3,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr3.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explota todo y termina dando peor. Afuera!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. AnÃ¡lisis de la muestra de 100 casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. La que elegimos fue la segunda regresiÃ³n Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_aux3 = data[[ 'surface_total_in_m2', 'surface_covered_in_m2' ,'Ambientes', 'pileta', 'amenities',\n",
    "       'gimnasio', 'laundry', 'sum', 'solarium', 'parrilla', 'a estrenar',\n",
    "       'subte', 'cochera', 'latitud', 'longitud', 'BARRIO_PALERMO', 'BARRIO_RECOLETA', 'balcon', 'terraza', 'lavadero']]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(data_aux3.corr(),\n",
    "            xticklabels=data_aux3.columns.values,\n",
    "            yticklabels=data_aux3.columns.values, cmap=sns.diverging_palette(220, 10, as_cmap=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux3_sq = PolynomialFeatures(2,include_bias=True,interaction_only=False).fit_transform(data_aux3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3428, 231)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aux3_sq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399, 231) (2399,)\n",
      "(1029, 231) (1029,)\n"
     ]
    }
   ],
   "source": [
    "#Split train y test \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_aux3_sq, data.price_usd_per_m2, test_size=0.3, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NormalizaciÃ³n (para Ridge y Lasso)\n",
    "se = StandardScaler()\n",
    "X_train_s = se.fit_transform(X_train)\n",
    "X_test_s = se.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegresiÃ³n Lasso\n",
      "alpha: 3.18\n",
      "\n",
      "Coeficientes: [ 0.00000000e+00 -3.46894442e+02  1.67716236e+02  0.00000000e+00\n",
      "  1.93142674e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  9.10567213e-01  1.51916783e-02\n",
      " -7.52878170e+00  8.19989339e+01 -0.00000000e+00  8.90469066e+01\n",
      "  1.69964390e+01 -3.16244679e+01  1.20424875e+01 -0.00000000e+00\n",
      " -1.44448510e+01  6.04581488e+01  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -2.92253414e+01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -8.76386532e+01 -0.00000000e+00  2.34193591e+02  4.00491809e+00\n",
      " -4.19069255e+01 -4.97820189e+01 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  6.68084043e+00  1.00889966e+00\n",
      "  0.00000000e+00 -0.00000000e+00  5.64950038e+01 -0.00000000e+00\n",
      " -4.74065866e+01 -8.91589920e+01  5.81632079e+01 -0.00000000e+00\n",
      "  7.28563637e+01 -2.33009827e+02 -0.00000000e+00  1.06498542e+02\n",
      " -0.00000000e+00  0.00000000e+00  1.26282403e+00  5.45339192e+01\n",
      "  0.00000000e+00  0.00000000e+00  7.78246425e+01  2.06427170e+01\n",
      "  4.96655591e+01  0.00000000e+00  9.61931257e+01  0.00000000e+00\n",
      "  4.83486701e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  4.98776438e+01  1.38543592e+01\n",
      "  6.51475226e+01  0.00000000e+00 -2.61997254e+01 -5.33108006e+00\n",
      "  0.00000000e+00  4.91007340e+00  0.00000000e+00  1.03587082e+02\n",
      " -2.75256393e+01 -0.00000000e+00 -8.57604195e+00  1.54736631e+01\n",
      " -4.22851184e+01 -4.48169379e+00  1.24452987e+01  0.00000000e+00\n",
      " -2.85340736e+01  0.00000000e+00 -5.10121340e+01  4.52592536e+01\n",
      "  4.60082480e+00 -0.00000000e+00 -3.73557690e+00 -3.15116953e+01\n",
      " -0.00000000e+00 -0.00000000e+00 -1.56563613e+01  3.63130071e+00\n",
      "  4.21267398e+01 -1.26777283e+01 -0.00000000e+00  0.00000000e+00\n",
      "  6.19616348e+01  6.45793730e+01 -2.62565881e+01  0.00000000e+00\n",
      " -6.38157549e+01  9.41607736e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  1.71932758e+01  3.84905193e+00  0.00000000e+00\n",
      "  6.05169354e+00  0.00000000e+00  0.00000000e+00 -1.87011487e+01\n",
      " -3.16896589e+01  2.56363355e+01 -0.00000000e+00  2.92427577e+00\n",
      " -6.18249242e+01 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.76098410e+00  0.00000000e+00 -5.97899302e+00\n",
      " -0.00000000e+00 -3.59194630e+01 -0.00000000e+00 -1.03686284e+01\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  3.09930613e+01  0.00000000e+00\n",
      "  2.01998967e+01  0.00000000e+00 -1.33443018e+01 -2.47795737e+01\n",
      " -4.56212267e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  4.66009467e-01  6.94667048e+00  0.00000000e+00  0.00000000e+00\n",
      "  2.00669313e+01  4.27615695e+00  2.60629991e+00  2.81822892e+01\n",
      "  4.26047549e+01 -5.67858814e-01 -0.00000000e+00  0.00000000e+00\n",
      "  2.09714197e+01 -4.34272112e-01 -0.00000000e+00  0.00000000e+00\n",
      "  3.97182975e-01  1.30706852e+01 -9.46691749e+00 -0.00000000e+00\n",
      " -0.00000000e+00  5.21314531e+01  3.37322753e+01 -0.00000000e+00\n",
      "  0.00000000e+00 -1.71789230e+01 -1.28518813e+01 -4.33584004e+00\n",
      "  0.00000000e+00  5.61991802e-01 -0.00000000e+00  1.14746950e+01\n",
      "  5.75156812e+01 -1.40801493e+01  1.04429233e+01  0.00000000e+00\n",
      " -1.19554708e-02 -0.00000000e+00  1.29974921e+01  1.76353077e+01\n",
      " -2.48833310e+00 -1.20491119e+01  5.24735700e+00  0.00000000e+00\n",
      " -1.82511056e+02 -2.39840987e+00  9.99924339e+00 -2.30120077e-04\n",
      "  4.05735072e+01  6.90189301e+01 -1.54181530e+01 -0.00000000e+00\n",
      "  3.55286892e-01 -0.00000000e+00  4.99257282e-01  5.58289350e+00\n",
      "  0.00000000e+00  0.00000000e+00  2.61753443e+01 -2.24897245e+01\n",
      " -3.36659891e+01 -0.00000000e+00  1.54818195e+01  0.00000000e+00\n",
      " -9.73597903e+00  1.49301047e-04  1.06411473e+01  5.68296923e+00\n",
      " -8.58836830e-01  3.33121818e+01 -4.40109523e+00]\n",
      "\n",
      "Residual sum of squares: 323069.51\n",
      "\n",
      "Varianza explicada: 0.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regr2=linear_model.LassoCV(cv=5).fit(X_train_s, y_train)\n",
    "\n",
    "print ('RegresiÃ³n Lasso' )\n",
    "# Alpha\n",
    "print('alpha: %.2f\\n' % regr2.alpha_)\n",
    "# Coeficiente\n",
    "print ('Coeficientes:', regr2.coef_)\n",
    "# MSE\n",
    "print(\"\\nResidual sum of squares: %.2f\"\n",
    " % np.mean((regr2.predict(X_train_s) - y_train) ** 2))\n",
    "# Varianza Explicada\n",
    "print('\\nVarianza explicada: %.2f\\n' % regr2.score(X_train_s, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39391073 0.46382384 0.37754854 0.42620613 0.39982551]\n",
      "0.41226294964874627\n",
      "0.030164621997500897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\juan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(regr2,X_train_s,y_train,cv=5)\n",
    "print(results)\n",
    "print(np.mean(results))\n",
    "print(np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (test): 0.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y probando en el test:\n",
    "pred_test = regr2.predict(X_test_s)\n",
    "print('R2 (test): %.2f\\n' % r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Tomamos la muestra, la pasamos por el modelo y la graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precio_x_m2_real</th>\n",
       "      <th>precio_x_m2_predicho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>3250.000000</td>\n",
       "      <td>2846.438843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>4500.000000</td>\n",
       "      <td>3791.545843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2547.222222</td>\n",
       "      <td>2584.659616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>2966.666667</td>\n",
       "      <td>2600.587566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>3277.310924</td>\n",
       "      <td>3240.860387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precio_x_m2_real  precio_x_m2_predicho\n",
       "1185       3250.000000           2846.438843\n",
       "244        4500.000000           3791.545843\n",
       "2014       2547.222222           2584.659616\n",
       "2159       2966.666667           2600.587566\n",
       "1121       3277.310924           3240.860387"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestra = pd.DataFrame(dict(precio_x_m2_real = y_test, precio_x_m2_predicho = pred_test)).sample(100)\n",
    "muestra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rojo = Vender\n",
      "Azul = Comprar\n"
     ]
    }
   ],
   "source": [
    "# Graficamos los resultados\n",
    "plt.plot(muestra.precio_x_m2_real, muestra.precio_x_m2_real, '-.', c='grey')\n",
    "plt.scatter(muestra.precio_x_m2_predicho[muestra.precio_x_m2_predicho > muestra.precio_x_m2_real]\n",
    "            , muestra.precio_x_m2_real[muestra.precio_x_m2_predicho > muestra.precio_x_m2_real]\n",
    "            , s=30, c='b', marker='+', zorder=10)\n",
    "plt.scatter(muestra.precio_x_m2_predicho[muestra.precio_x_m2_predicho < muestra.precio_x_m2_real]\n",
    "            , muestra.precio_x_m2_real[muestra.precio_x_m2_predicho < muestra.precio_x_m2_real]\n",
    "            , s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Precio x m2 predicho\")\n",
    "plt.ylabel(\"Precio x m2 real\")\n",
    "plt.show()\n",
    "\n",
    "print('Rojo = Vender\\nAzul = Comprar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
