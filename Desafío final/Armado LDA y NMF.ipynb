{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo paquetes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.load_npz(\"./Data/X_train_Tf-idf.npz\")\n",
    "X_test = sparse.load_npz(\"./Data/X_test_Tf-idf.npz\")\n",
    "y_train = pd.read_csv(\"./Data/y_train.csv\", header=None)\n",
    "y_test = pd.read_csv(\"./Data/y_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 6 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 7 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 8 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "# train a LDA Model\n",
    "lda_model = LDA(n_components=200, max_iter=10, verbose=5)\n",
    "X_train_LDA = lda_model.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   40.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   40.9s finished\n"
     ]
    }
   ],
   "source": [
    "X_test_LDA = lda_model.transform(X_test)\n",
    "topic_word = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00075615, 0.66504679, 0.00075615, ..., 0.00075615, 0.00075615,\n",
       "        0.00075615],\n",
       "       [0.00146126, 0.00146126, 0.00146126, ..., 0.00146126, 0.00146126,\n",
       "        0.00146126],\n",
       "       [0.00128515, 0.00128515, 0.00128515, ..., 0.00128515, 0.00128515,\n",
       "        0.00128515],\n",
       "       ...,\n",
       "       [0.00207155, 0.00207155, 0.00207155, ..., 0.00207155, 0.00207155,\n",
       "        0.00207155],\n",
       "       [0.00184636, 0.00184636, 0.00184636, ..., 0.00184636, 0.00184636,\n",
       "        0.00184636],\n",
       "       [0.00125027, 0.00125027, 0.00125027, ..., 0.00125027, 0.00125027,\n",
       "        0.00125027]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00000000e-03, 5.00000000e-03, 5.00000000e-03, ...,\n",
       "        5.00000000e-03, 5.00000000e-03, 5.00000000e-03],\n",
       "       [5.00000000e-03, 5.00000000e-03, 5.00000000e-03, ...,\n",
       "        5.00000000e-03, 5.00000000e-03, 5.00000000e-03],\n",
       "       [9.29407589e+00, 5.00000000e-03, 1.02466727e+01, ...,\n",
       "        5.00000000e-03, 5.00000000e-03, 5.00000000e-03],\n",
       "       ...,\n",
       "       [5.00000000e-03, 5.00000000e-03, 5.00000000e-03, ...,\n",
       "        5.00000000e-03, 5.00000000e-03, 5.00000000e-03],\n",
       "       [5.00000000e-03, 5.00000000e-03, 5.00000000e-03, ...,\n",
       "        5.00000000e-03, 5.00000000e-03, 5.00000000e-03],\n",
       "       [5.00000000e-03, 5.00000000e-03, 5.00000000e-03, ...,\n",
       "        5.00000000e-03, 5.00000000e-03, 5.00000000e-03]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda = pd.DataFrame(X_train_LDA)\n",
    "X_test_lda = pd.DataFrame(X_test_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda.to_csv(\"./Data/X_train_LDA.csv\", index=False )\n",
    "X_test_lda.to_csv(\"./Data/X_test_LDA.csv\", index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.09650842740112399\n",
      "violation: 0.03809096084104863\n",
      "violation: 0.026642340371176073\n",
      "violation: 0.02084609256243121\n",
      "violation: 0.011216446975074259\n",
      "violation: 0.007103333142906282\n",
      "violation: 0.005421083016663972\n",
      "violation: 0.0044097189837288145\n",
      "violation: 0.0037037849246204734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"n_top_words = 10\\ntopic_summaries = []\\nfor i, topic_dist in enumerate(topic_word):\\n    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\\n    topic_summaries.append(' '.join(topic_words))\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a NFD Model\n",
    "nmf_model = NMF(n_components=200, max_iter=10, verbose=5)\n",
    "X_train_NMF = nmf_model.fit_transform(X_train, y_train)\n",
    "\n",
    "# view the topic models\n",
    "'''n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.022921538461794774\n",
      "violation: 0.0006274693787449077\n",
      "violation: 3.72828142736053e-05\n",
      "Converged at iteration 4\n"
     ]
    }
   ],
   "source": [
    "X_test_NMF = nmf_model.transform(X_test)\n",
    "topic_word = nmf_model.components_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 3.41045292e-07, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 3.90596414e-07, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.40060302e-07, 4.62128737e-07, 4.75285425e-07, ...,\n",
       "        3.82253529e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.63117648e-07, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nmf = pd.DataFrame(X_train_NMF)\n",
    "X_test_nmf = pd.DataFrame(X_test_NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nmf.to_csv(\"./Data/X_train_NMF.csv\", index=False )\n",
    "X_test_nmf.to_csv(\"./Data/X_test_NMF.csv\", index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
