{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo paquetes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.load_npz(\"./Data/X_train_Tf-idf.npz\")\n",
    "X_test = sparse.load_npz(\"./Data/X_test_Tf-idf.npz\")\n",
    "y_train = pd.read_csv(\"./Data/y_train.csv\", header=None)\n",
    "y_test = pd.read_csv(\"./Data/y_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LDA(n_components=6, max_iter=5, verbose=5)\n",
    "nmf_model = NMF(n_components=10, max_iter=10, verbose=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 6 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 7 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 8 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 of max_iter: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   52.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   52.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   56.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   56.9s finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0206d942a7c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlda_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train_LDA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_test_LDA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtopic_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# train a LDA Model\n",
    "lda_model = LDA(n_components=10, max_iter=10, verbose=5)\n",
    "X_train_LDA = lda_model.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.2s finished\n"
     ]
    }
   ],
   "source": [
    "X_test_LDA = lda_model.transform(X_test)\n",
    "topic_word = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01512354, 0.01512328, 0.86387883, ..., 0.01512322, 0.01512445,\n",
       "        0.0151235 ],\n",
       "       [0.02922721, 0.73686297, 0.02922969, ..., 0.02922967, 0.02924127,\n",
       "        0.02928272],\n",
       "       [0.0257056 , 0.02570557, 0.02570428, ..., 0.0257288 , 0.28480319,\n",
       "        0.02570393],\n",
       "       ...,\n",
       "       [0.04143262, 0.04143875, 0.0414343 , ..., 0.04143361, 0.04145208,\n",
       "        0.04143097],\n",
       "       [0.03693076, 0.66758091, 0.03692876, ..., 0.03692848, 0.03694035,\n",
       "        0.03692716],\n",
       "       [0.02500811, 0.10806087, 0.0250074 , ..., 0.02500811, 0.19263691,\n",
       "        0.23738484]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.13568325,  5.30741598,  0.10000234, ..., 11.7507594 ,\n",
       "         0.10000829,  0.1       ],\n",
       "       [ 0.10001184,  0.1000025 ,  0.1       , ...,  0.1       ,\n",
       "         0.1       ,  0.10000051],\n",
       "       [14.5266005 ,  0.23060819,  0.1       , ...,  0.10000109,\n",
       "         0.1       ,  0.1       ],\n",
       "       ...,\n",
       "       [17.66624602,  0.10000463, 18.18807109, ...,  0.1       ,\n",
       "         0.1       ,  0.1       ],\n",
       "       [54.27730461,  0.10002596,  0.1       , ...,  0.10000277,\n",
       "        14.20644085, 14.16152315],\n",
       "       [ 0.10000142,  0.10000028,  0.10000003, ...,  0.10000067,\n",
       "         0.1       ,  0.10000011]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda = pd.DataFrame(X_train_LDA)\n",
    "X_test_lda = pd.DataFrame(X_test_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda.to_csv(\"./Data/X_train_LDA.csv\", index=False )\n",
    "X_test_lda.to_csv(\"./Data/X_test_LDA.csv\", index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.07144838951380783\n",
      "violation: 0.016124225567820793\n",
      "violation: 0.008061802390952097\n",
      "violation: 0.004769969869043397\n",
      "violation: 0.0030315973238454904\n",
      "violation: 0.002020569964912353\n",
      "violation: 0.0013952113111662344\n",
      "violation: 0.0009876929690949133\n",
      "violation: 0.000710498714985069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"n_top_words = 10\\ntopic_summaries = []\\nfor i, topic_dist in enumerate(topic_word):\\n    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\\n    topic_summaries.append(' '.join(topic_words))\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a NFD Model\n",
    "nmf_model = NMF(n_components=10, max_iter=10, verbose=5)\n",
    "X_train_NMF = nmf_model.fit_transform(X_train, y_train)\n",
    "\n",
    "# view the topic models\n",
    "'''n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.0008544384754688434\n",
      "violation: 1.2973705087951626e-06\n",
      "Converged at iteration 3\n"
     ]
    }
   ],
   "source": [
    "X_test_NMF = nmf_model.transform(X_test)\n",
    "topic_word = nmf_model.components_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.02886633e-06, 3.22114672e-06, 5.54931862e-06, ...,\n",
       "        4.27455147e-04, 1.27847003e-03, 2.75179071e-04],\n",
       "       [4.13391374e-06, 1.15960027e-05, 1.08139516e-05, ...,\n",
       "        1.12094741e-04, 3.99712509e-04, 5.43445395e-05],\n",
       "       [5.18900470e-07, 2.87781056e-06, 4.03957056e-06, ...,\n",
       "        6.12724740e-04, 3.33763051e-03, 8.99652019e-05],\n",
       "       ...,\n",
       "       [1.09308105e-07, 0.00000000e+00, 2.36938775e-07, ...,\n",
       "        1.63890039e-05, 1.79347393e-05, 1.22861913e-05],\n",
       "       [5.65106375e-07, 1.37620358e-06, 1.57602193e-06, ...,\n",
       "        2.54979280e-05, 9.38879361e-05, 9.49712497e-06],\n",
       "       [2.21511039e-06, 2.10267237e-06, 9.24313429e-06, ...,\n",
       "        4.80176598e-04, 1.72005784e-03, 2.03651010e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nmf = pd.DataFrame(X_train_NMF)\n",
    "X_test_nmf = pd.DataFrame(X_test_NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nmf.to_csv(\"./Data/X_train_NMF.csv\", index=False )\n",
    "X_test_nmf.to_csv(\"./Data/X_test_NMF.csv\", index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
